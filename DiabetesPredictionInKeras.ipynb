{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "410a8f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense  , Dropout\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,roc_curve, accuracy_score, classification_report\n",
    "from sklearn import metrics\n",
    "import warnings as ws\n",
    "ws.filterwarnings(\"ignore\")\n",
    "dataset = pd.read_csv('diabetes-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f8454d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e613d0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 9)\n",
      "0    1316\n",
      "1     684\n",
      "Name: Outcome, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "dataset[\"Outcome\"].value_counts()\n",
    "print(dataset[\"Outcome\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65cf705d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Outcome', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"Outcome\", data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea17780e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0730a7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.70350</td>\n",
       "      <td>3.306063</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>121.18250</td>\n",
       "      <td>32.068636</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>117.000</td>\n",
       "      <td>141.000</td>\n",
       "      <td>199.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>69.14550</td>\n",
       "      <td>19.188315</td>\n",
       "      <td>0.000</td>\n",
       "      <td>63.500</td>\n",
       "      <td>72.000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>122.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>20.93500</td>\n",
       "      <td>16.103243</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>110.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>80.25400</td>\n",
       "      <td>111.180534</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>130.000</td>\n",
       "      <td>744.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>32.19300</td>\n",
       "      <td>8.149901</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.375</td>\n",
       "      <td>32.300</td>\n",
       "      <td>36.800</td>\n",
       "      <td>80.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.47093</td>\n",
       "      <td>0.323553</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.624</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>33.09050</td>\n",
       "      <td>11.786423</td>\n",
       "      <td>21.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.34200</td>\n",
       "      <td>0.474498</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count       mean         std     min     25%  \\\n",
       "Pregnancies               2000.0    3.70350    3.306063   0.000   1.000   \n",
       "Glucose                   2000.0  121.18250   32.068636   0.000  99.000   \n",
       "BloodPressure             2000.0   69.14550   19.188315   0.000  63.500   \n",
       "SkinThickness             2000.0   20.93500   16.103243   0.000   0.000   \n",
       "Insulin                   2000.0   80.25400  111.180534   0.000   0.000   \n",
       "BMI                       2000.0   32.19300    8.149901   0.000  27.375   \n",
       "DiabetesPedigreeFunction  2000.0    0.47093    0.323553   0.078   0.244   \n",
       "Age                       2000.0   33.09050   11.786423  21.000  24.000   \n",
       "Outcome                   2000.0    0.34200    0.474498   0.000   0.000   \n",
       "\n",
       "                              50%      75%     max  \n",
       "Pregnancies                 3.000    6.000   17.00  \n",
       "Glucose                   117.000  141.000  199.00  \n",
       "BloodPressure              72.000   80.000  122.00  \n",
       "SkinThickness              23.000   32.000  110.00  \n",
       "Insulin                    40.000  130.000  744.00  \n",
       "BMI                        32.300   36.800   80.60  \n",
       "DiabetesPedigreeFunction    0.376    0.624    2.42  \n",
       "Age                        29.000   40.000   81.00  \n",
       "Outcome                     0.000    1.000    1.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb7c855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.127</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>125</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>250</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>62</td>\n",
       "      <td>41</td>\n",
       "      <td>480</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.536</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            2      138             62             35        0  33.6   \n",
       "1            0       84             82             31      125  38.2   \n",
       "2            0      145              0              0        0  44.2   \n",
       "3            0      135             68             42      250  42.3   \n",
       "4            1      139             62             41      480  40.7   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.127   47        1  \n",
       "1                     0.233   23        0  \n",
       "2                     0.630   31        1  \n",
       "3                     0.365   24        1  \n",
       "4                     0.536   21        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332ffbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c65be4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030be2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for debuging\n",
    "dataset_dups=dataset[dataset.duplicated(subset=None, keep='first')]\n",
    "array_indexes=dataset_dups.loc[dataset[\"Outcome\"] == 0].index\n",
    "new_indexx= []\n",
    "cnt=0\n",
    "for i in array_indexes :\n",
    "    if cnt<632 :\n",
    "        new_indexx.append(i)\n",
    "        cnt+=1\n",
    "dataset = dataset.drop(new_indexx)\n",
    "#for debuging\n",
    "dataset_dups=dataset[dataset.duplicated(subset=None, keep='first')]\n",
    "healthy_dups = dataset_dups.loc[dataset[\"Outcome\"] == 0].index\n",
    "dataset = dataset.drop(healthy_dups)\n",
    "\n",
    "dataset_dups=dataset[dataset.duplicated(subset=None, keep='first')]\n",
    "healthy_dups = dataset_dups.loc[dataset[\"Outcome\"] ==1].index    \n",
    "dataset = dataset.drop(healthy_dups)\n",
    "\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce04f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for replace every 0 with mean\n",
    "variables = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']\n",
    "for i in variables:\n",
    "    dataset[i].replace(0,dataset[i].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "370f70d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138.0</td>\n",
       "      <td>62.0000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>80.254</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.127</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>82.0000</td>\n",
       "      <td>31.000</td>\n",
       "      <td>125.000</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>69.1455</td>\n",
       "      <td>20.935</td>\n",
       "      <td>80.254</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>68.0000</td>\n",
       "      <td>42.000</td>\n",
       "      <td>250.000</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139.0</td>\n",
       "      <td>62.0000</td>\n",
       "      <td>41.000</td>\n",
       "      <td>480.000</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.536</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            2    138.0        62.0000         35.000   80.254  33.6   \n",
       "1            0     84.0        82.0000         31.000  125.000  38.2   \n",
       "2            0    145.0        69.1455         20.935   80.254  44.2   \n",
       "3            0    135.0        68.0000         42.000  250.000  42.3   \n",
       "4            1    139.0        62.0000         41.000  480.000  40.7   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.127   47        1  \n",
       "1                     0.233   23        0  \n",
       "2                     0.630   31        1  \n",
       "3                     0.365   24        1  \n",
       "4                     0.536   21        0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd45a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z score normalization\n",
    "variables = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']\n",
    "maxx =[dataset['Pregnancies'].max(),dataset['Glucose'].max(),dataset['BloodPressure'].max(),dataset['SkinThickness'].max(),dataset['Insulin'].max(),dataset['BMI'].max(),dataset['DiabetesPedigreeFunction'].max(),dataset['Age'].max()]\n",
    "stdd =[dataset['Pregnancies'].std(),dataset['Glucose'].std(),dataset['BloodPressure'].std(),dataset['SkinThickness'].std(),dataset['Insulin'].std(),dataset['BMI'].std(),dataset['DiabetesPedigreeFunction'].std(),dataset['Age'].std()]\n",
    "meann =[dataset['Pregnancies'].mean(),dataset['Glucose'].mean(),dataset['BloodPressure'].mean(),dataset['SkinThickness'].mean(),dataset['Insulin'].mean(),dataset['BMI'].mean(),dataset['DiabetesPedigreeFunction'].mean(),dataset['Age'].mean()]\n",
    "cnt=0\n",
    "for i in variables:\n",
    "    dataset[i]= (dataset[i]-meann[cnt])/stdd[cnt]\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcdf8a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score (example):\n",
    "    cnt=-1\n",
    "    for i in range(0,8):\n",
    "        cnt+=1\n",
    "        if example[i]==0 :\n",
    "            continue\n",
    "        example[i]= (example[i]-meann[cnt])/stdd[cnt]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3eb228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2718fb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.515265</td>\n",
       "      <td>0.524997</td>\n",
       "      <td>-0.856995</td>\n",
       "      <td>0.816180</td>\n",
       "      <td>-0.434119</td>\n",
       "      <td>0.132998</td>\n",
       "      <td>-1.062980</td>\n",
       "      <td>1.180129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.120215</td>\n",
       "      <td>-1.243571</td>\n",
       "      <td>0.814042</td>\n",
       "      <td>0.411485</td>\n",
       "      <td>0.072251</td>\n",
       "      <td>0.772745</td>\n",
       "      <td>-0.735367</td>\n",
       "      <td>-0.856112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.120215</td>\n",
       "      <td>0.754255</td>\n",
       "      <td>-0.259976</td>\n",
       "      <td>-0.606827</td>\n",
       "      <td>-0.434119</td>\n",
       "      <td>1.607198</td>\n",
       "      <td>0.491636</td>\n",
       "      <td>-0.177365</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.120215</td>\n",
       "      <td>0.426743</td>\n",
       "      <td>-0.355684</td>\n",
       "      <td>1.524395</td>\n",
       "      <td>1.486820</td>\n",
       "      <td>1.342955</td>\n",
       "      <td>-0.327397</td>\n",
       "      <td>-0.771269</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.817740</td>\n",
       "      <td>0.557748</td>\n",
       "      <td>-0.856995</td>\n",
       "      <td>1.423221</td>\n",
       "      <td>4.089626</td>\n",
       "      <td>1.120434</td>\n",
       "      <td>0.201111</td>\n",
       "      <td>-1.025799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0    -0.515265  0.524997      -0.856995       0.816180 -0.434119  0.132998   \n",
       "1    -1.120215 -1.243571       0.814042       0.411485  0.072251  0.772745   \n",
       "2    -1.120215  0.754255      -0.259976      -0.606827 -0.434119  1.607198   \n",
       "3    -1.120215  0.426743      -0.355684       1.524395  1.486820  1.342955   \n",
       "4    -0.817740  0.557748      -0.856995       1.423221  4.089626  1.120434   \n",
       "\n",
       "   DiabetesPedigreeFunction       Age  Outcome  \n",
       "0                 -1.062980  1.180129        1  \n",
       "1                 -0.735367 -0.856112        0  \n",
       "2                  0.491636 -0.177365        1  \n",
       "3                 -0.327397 -0.771269        1  \n",
       "4                  0.201111 -1.025799        0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dec27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efbf46a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7oAAANVCAYAAABWFoI6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzf0lEQVR4nO3de5SVdb348c8wwMwAAyRXERRcppFGhKSCqVwUBUWEygumgro6etQi9ZeVKXgp8HbCJD11QrBUkDLQ5FKUoOYtwBurOp40DAtvmcRFGGBm//7wMMcRUEBkw2der7VmLfaz9372Z+/Zjvu9nu88U1IoFAoBAAAASTQo9gAAAACwIwldAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQC2yuTJk6OkpKT2q2HDhtGxY8cYOXJk/P3vfy/2eLuszp07x4gRI3b6Y777e1VeXh777bdfXHzxxfGPf/xjp86yJRvfTy+99NI233fWrFkxZsyYHT4TAHk0LPYAAOxeJk2aFJ/4xCdizZo18fDDD8fYsWPjoYceisWLF0fTpk2LPd4uZ/r06dG8efOd/riHH3543HjjjRERsWbNmli4cGGMGTMmHn744Vi4cOFOn2dHmjVrVvzgBz8QuwBskdAFYJscdNBB0bNnz4iI6Nu3b1RXV8c111wTM2bMiNNPP32z93n77bejSZMmO3PMXcZnPvOZojxuy5Yt47DDDqu93Ldv31i5cmVcc8018T//8z+x//77F2UuANgZLF0G4EPZGFN//etfIyJixIgR0axZs1i8eHEMGDAgKisro3///hERsW7durj22mvjE5/4RJSVlUWbNm1i5MiR8cYbb9TZZ1VVVVxyySXRvn37aNKkSRx55JGxaNGiTZYBb1z+Om/evDj//POjdevW0apVqxg2bFgsW7aszj7vueeeGDBgQOy5555RUVERXbt2jW984xuxevXqOrfbOP8LL7wQgwYNimbNmkWnTp3ikksuiaqqqk3mvPrqq6Nr165RXl4erVq1ir59+8Zjjz1We5vNLV1esWJFXHrppdGlS5do3Lhx7LXXXjFq1KhNZvnZz34Whx56aLRo0SKaNGkS++67b5x99tlb+Z3ZVIsWLSIiolGjRnW233///dGrV69o0qRJVFZWxjHHHBOPP/547fVTp06NkpKSmDBhQp37jR49OkpLS2Pu3LkREfHSSy9FSUlJXH/99fGd73wn9t577ygvL4+ePXvGb3/7262a8fbbb49Pf/rTUV5eHnvssUcMHTo0/vSnP9VeP2LEiPjBD34QEVFnefb2LIEGIC+hC8CH8sILL0RERJs2bWq3rVu3Lk488cTo169f3HfffXHVVVdFTU1NDBkyJMaNGxfDhw+PmTNnxrhx42Lu3LnRp0+fWLNmTe39R44cGePHj4+RI0fGfffdF5///Odj6NChsXz58s3OcO6550ajRo3i7rvvjuuvvz7mz58fX/rSl+rc5s9//nMMGjQoJk6cGHPmzIlRo0bFtGnTYvDgwZvsb/369XHiiSdG//7947777ouzzz47vve978V1111Xe5sNGzbEwIED45prrokTTjghpk+fHpMnT47evXvH0qVLt/h6vf3223HUUUfFHXfcEV/5yldi9uzZcdlll8XkyZPjxBNPjEKhEBERjz/+eJxyyimx7777xtSpU2PmzJlx5ZVXxoYNGz74mxIRhUIhNmzYEBs2bIhVq1bFvHnzYvz48XH44YdHly5dam939913x5AhQ6J58+YxZcqUmDhxYrz11lvRp0+f+N3vfhcREaeeemqcd955cckll9Que37wwQfj2muvjW9961txzDHH1HnsCRMmxJw5c2L8+PFx5513RoMGDWLgwIF14nlzxo4dG+ecc04ceOCB8Ytf/CJuvvnmeO6556JXr17x5z//OSIirrjiivjCF75Q+xpt/Npzzz236nUBoJ4oAMBWmDRpUiEiCk888URh/fr1hZUrVxYeeOCBQps2bQqVlZWFV199tVAoFApnnXVWISIKt99+e537T5kypRARhXvvvbfO9gULFhQionDrrbcWCoVC4Q9/+EMhIgqXXXbZZu9/1llnbTLTv//7v9e57fXXX1+IiMIrr7yy2edSU1NTWL9+feGhhx4qRETh2Wefrb1u4/zTpk2rc59BgwYVDjjggNrLP/nJTwoRUfiv//qv93vZCvvss0+dmceOHVto0KBBYcGCBXVu9/Of/7wQEYVZs2YVCoVC4cYbbyxERGH58uXvu/8tPWZEbPJ1yCGH1HlNqqurCx06dCh86lOfKlRXV9duX7lyZaFt27aF3r17125bu3Zt4TOf+UyhS5cuhT/+8Y+Fdu3aFY466qjChg0bam+zZMmSQkQUOnToUFizZk3t9hUrVhT22GOPwtFHH127beP3bsmSJYVCoVB46623ChUVFYVBgwbVeS5Lly4tlJWVFYYPH1677YILLij4CAPA+3FEF4Btcthhh0WjRo2isrIyTjjhhGjfvn3Mnj072rVrV+d2n//85+tcfuCBB6Jly5YxePDg2iONGzZsiO7du0f79u1j/vz5ERHx0EMPRUTEySefXOf+X/jCF6Jhw82fWuLEE0+sc7lbt24R8X/LqSMi/vKXv8Tw4cOjffv2UVpaGo0aNYqjjjoqIqLO0tiId5bEvvdIb7du3ersb/bs2VFeXr7NS4kfeOCBOOigg6J79+51Xodjjz02SkpKal+Hz372sxHxzuswbdq0bT6z9ec+97lYsGBBLFiwIB599NGYOHFivPHGG9GvX7/aMy8///zzsWzZsjjjjDOiQYP/+0jQrFmz+PznPx9PPPFEvP322xERUVZWFtOmTYs333wzevToEYVCIaZMmRKlpaWbPPawYcOivLy89nJlZWUMHjw4Hn744aiurt7svI8//nisWbNmk2XenTp1in79+m310mcAiHAyKgC20U9+8pPo2rVrNGzYMNq1a7fZJaNNmjTZ5EzDr732WixfvjwaN2682f1ujK8333wzImKTcG7YsGG0atVqs/d97/aysrKIiNrl0KtWrYojjjgiysvL49prr439998/mjRpEi+//HIMGzaszrLpjfO/O9Q27nPt2rW1l994443o0KFDnUDcGq+99lq88MILm/ye7EYbX4cjjzwyZsyYEd///vfjzDPPjKqqqjjwwAPj8ssvj9NOO+0DH6dFixa1Jw2LiOjdu3d88pOfjF69esVNN90UY8eOrX2tN/c97NChQ9TU1MRbb71VeyKx/fbbL4444oiYOXNmnH/++VtcLty+ffvNblu3bl2sWrWq9neF3+2DZtn4e8AAsDWELgDbpGvXrnUCanNKSko22bbxRFFz5szZ7H0qKysj4v+i9bXXXou99tqr9voNGzbUxtC2evDBB2PZsmUxf/782qO4EbHF3/ndGm3atInf/e53UVNTs02x27p166ioqIjbb799i9dvNGTIkBgyZEhUVVXFE088EWPHjo3hw4dH586do1evXts888Yj3c8++2xE/N9r/corr2xy22XLlkWDBg3iYx/7WO22H//4xzFz5sw45JBDYsKECXHKKafEoYceusl9X3311c1ua9y4cTRr1myzs33QLO9+XQDgg1i6DMBOccIJJ8Sbb74Z1dXV0bNnz02+DjjggIh450hmxDtnSX63n//851t9Iqb32hjeG4/0bvTDH/5wu/YXETFw4MBYu3ZtTJ48eZvud8IJJ8SLL74YrVq12uzr0Llz503uU1ZWFkcddVTtybCefvrp7Zr5mWeeiYiItm3bRkTEAQccEHvttVfcfffdtSfBiohYvXp13HvvvbVnYo6IWLx4cXzlK1+JM888Mx555JHo1q1bnHLKKfHWW29t8ji/+MUv6hz9XrlyZfzyl7+MI444YrNLnSMievXqFRUVFXHnnXfW2f63v/0tHnzwwdozd0dsesQeAN7LEV0AdopTTz017rrrrhg0aFB89atfjUMOOSQaNWoUf/vb32LevHkxZMiQGDp0aBx44IFx2mmnxU033RSlpaXRr1+/+MMf/hA33XRTtGjRYpuXCke8s2z3Yx/7WJx33nkxevToaNSoUdx11121Rza3x2mnnRaTJk2K8847L55//vno27dv1NTUxJNPPhldu3aNU089dbP3GzVqVNx7771x5JFHxte+9rXo1q1b1NTUxNKlS+PXv/51XHLJJXHooYfGlVdeGX/729+if//+0bFjx1i+fHncfPPNdX63+P0sX748nnjiiYh45yzSf/rTn+K73/1ulJWVxQUXXBAREQ0aNIjrr78+Tj/99DjhhBPi3/7t36KqqipuuOGGWL58eYwbNy4i3gnfk08+Obp06RK33nprNG7cOKZNmxY9evSIkSNHxowZM+o8dmlpaRxzzDFx8cUXR01NTVx33XWxYsWKuOqqq7Y4b8uWLeOKK66Ib33rW3HmmWfGaaedFm+++WZcddVVUV5eHqNHj6697ac+9amIiLjuuuti4MCBUVpaGt26ddvisngA6h+hC8BOUVpaGvfff3/cfPPN8dOf/jTGjh0bDRs2jI4dO8ZRRx1VGy8REZMmTYo999wzJk6cGN/73veie/fuMW3atDjuuOOiZcuW2/zYrVq1ipkzZ8Yll1wSX/rSl6Jp06YxZMiQuOeee6JHjx7b9XwaNmwYs2bNirFjx8aUKVNi/PjxUVlZGZ/+9KfjuOOO2+L9mjZtGo888kiMGzcufvSjH8WSJUuioqIi9t577zj66KNrj+geeuihsXDhwrjsssvijTfeiJYtW0bPnj3jwQcfjAMPPPAD53v00UdrlzeXlpbGXnvtFYccckhcfvnl0b1799rbDR8+PJo2bRpjx46NU045JUpLS+Owww6LefPmRe/evSMi4rzzzoulS5fGggULomnTphERse+++8aPf/zj+OIXvxjjx4+PUaNG1e7zwgsvjLVr18ZXvvKVeP311+PAAw+MmTNnxuGHH/6+M3/zm9+Mtm3bxve///245557oqKiIvr06RPf/e534+Mf/3idmR999NG49dZb4+qrr45CoRBLlizZ7NFwAOqnksK71yoBwC7qsccei8MPPzzuuuuuGD58eLHHYTNeeuml6NKlS9xwww1x6aWXFnscAOoxR3QB2OXMnTs3Hn/88Tj44IOjoqIinn322Rg3blx8/OMfj2HDhhV7PABgFyd0AdjlNG/ePH7961/H+PHjY+XKldG6desYOHBgjB07dpM/+wMA8F6WLgMAAJCKPy8EAABAKkIXAACAVIQuAAAAqWz3yahqampi2bJlUVlZGSUlJTtyJgAAANhEoVCIlStXRocOHaJBgy0ft93u0F22bFl06tRpe+8OAAAA2+Xll1+Ojh07bvH67Q7dysrK2gdo3rz59u4GAAAAtsqKFSuiU6dOtT26JdsduhuXKzdv3lzoAgAAsNN80K/POhkVAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVBoWewA+WKFQiLVr1xZ7DOKd70VVVVVERJSVlUVJSUmRJyKb8vJy7ysAgA9J6O4G1q5dGwMHDiz2GMBOMHv27KioqCj2GAAAuzVLlwEAAEjFEd3dzKrup0WhgW9b0VSvj8pnp0ZExMpPnxpR2qjIA5FBSc2GaPbMlGKPAQCQhmLazRQaNBRXu4rSRr4X7BCFYg8AAJCMpcsAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKg2LPcBHqVAoxNq1ayMiory8PEpKSoo8EQAAxeKzIdQfqY/orl27NgYOHBgDBw6s/aEGAED95LMh1B+pQxcAAID6R+gCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAADsRgYPHhx9+vSJwYMHF3uUD2XixInRr1+/mDhxYrFHISLGjBkTffr0iTFjxhR7lB1C6AIAwG7iqaeeipUrV0ZExMqVK+Opp54q8kTbZ/ny5XHXXXdFTU1N3HXXXbF8+fJij1SvvfbaazF//vyIiJg/f3689tprxR1oBxC6AACwm7j44ovf9/Lu4oorroiampqIiKipqYkrr7yyyBPVbxdeeGGdyxdddFGRJtlxGhZ7gI9SoVCo/ffatWuLOMmHU2f2dz0nIIkkP6sAdnXv/hlb2A0/U21pSemYMWN2q+WmCxcujMWLF9fZ9txzz8XChQujZ8+eRZqq/pozZ0688cYbdba9/vrrMWfOnDjuuOOKNNWHt9WhW1VVFVVVVbWXV6xY8ZEMtCO9e96hQ4cWcZIdqGZDRDQu9hTAjlSzofafaX5WAeziqqqqokmTJsUeY6tVVVXVLi19r/nz50dVVVWUlZXt3KG2Q01NTVx99dWbve7qq6+OGTNmRIMGFp3uLNXV1XHDDTds9robbrghjjnmmCgtLd3JU+0YW/0uGjt2bLRo0aL2q1OnTh/lXAAAwP+64oorPtT1u4onn3xyiwfMVqxYEU8++eROnqh+e+CBB6K6unqz11VXV8cDDzywkyfacUoKW7luY3NHdDt16hT/+te/onnz5h/ZgB/G22+/HYMGDYqIiOnTp0d5eXmRJ9o+a9eurT3Ks/IzX4po6Ihu0VSvj8qnfhoRESt7nBFR2qjIA5HChnVR+fSdEbF7/6wC2NW9+zPVrFmzdrsjuscee+wWr//Vr3612xzRPemkkzYbuy1atIjp06c7orsTVVdXx4ABAzYbuw0bNoxf/epXu9wR3RUrVkSLFi0+sEO3eulyWVnZbvEfz7uVlJTU/ru8vDwqKiqKOM0O8q7nBCSR8WcVwC6uZDf7TFVWVhZ9+vTZ7PLlfv367Taf0xs0aBBXXnllXHrppZtcN3r0aJG7k5WWlsb/+3//L8aNG7fJdV//+td3ucjdFt5JAACwG9jSCad2tzMW9+zZMz71qU/V2datW7fo0aNHkSaq34477rho06ZNnW1t27aNAQMGFGmiHUPoAgDAbuI//uM/3vfy7uKaa66pPXrboEGDLZ6gip1jwoQJdS7fcsstRZpkxxG6AACwm+jRo0dUVlZGRERlZeVuexS0ZcuWcfrpp0eDBg3i9NNPj5YtWxZ7pHqtXbt20adPn4iI6NOnT7Rr1664A+0Aqf+OLgAAZPPLX/6y2CPsEOecc06cc845xR6D/7U7/S3mreGILgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEilYbEH+CiVl5fH7Nmza/8NAED95bMh1B+pQ7ekpCQqKiqKPQYAALsAnw2h/rB0GQAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEilYbEHYNuU1GyIQrGHqM+q12/+3/AhlNRsKPYIAACpCN3dTLNnphR7BP5X5bNTiz0CAACwGZYuAwAAkIojuruB8vLymD17drHHICIKhUJUVVVFRERZWVmUlJQUeSKyKS8vL/YIAAC7PaG7GygpKYmKiopij8H/atKkSbFHAAAA3oelywAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKTScHvvWCgUIiJixYoVO2wYAAAA2JKN/bmxR7dku0N35cqVERHRqVOn7d0FAAAAbLOVK1dGixYttnh9SeGDUngLampqYtmyZVFZWRklJSXbPeDuZsWKFdGpU6d4+eWXo3nz5sUeh3rO+5FdjfckuxLvR3Y13pPsSnbX92OhUIiVK1dGhw4dokGDLf8m7nYf0W3QoEF07Nhxe+++22vevPlu9YYgN+9HdjXek+xKvB/Z1XhPsivZHd+P73ckdyMnowIAACAVoQsAAEAqQncblZWVxejRo6OsrKzYo4D3I7sc70l2Jd6P7Gq8J9mVZH8/bvfJqAAAAGBX5IguAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXofgjf+c53onfv3tGkSZNo2bJlscehHrr11lujS5cuUV5eHgcffHA88sgjxR6Jeurhhx+OwYMHR4cOHaKkpCRmzJhR7JGox8aOHRuf/exno7KyMtq2bRsnnXRSPP/888Uei3rqtttui27dukXz5s2jefPm0atXr5g9e3axx4KIeOfnZUlJSYwaNarYo+xwQvdDWLduXXzxi1+M888/v9ijUA/dc889MWrUqLj88svj6aefjiOOOCIGDhwYS5cuLfZo1EOrV6+OT3/60zFhwoRijwLx0EMPxQUXXBBPPPFEzJ07NzZs2BADBgyI1atXF3s06qGOHTvGuHHjYuHChbFw4cLo169fDBkyJP7whz8UezTquQULFsSPfvSj6NatW7FH+Uj480I7wOTJk2PUqFGxfPnyYo9CPXLooYdGjx494rbbbqvd1rVr1zjppJNi7NixRZyM+q6kpCSmT58eJ510UrFHgYiIeOONN6Jt27bx0EMPxZFHHlnscSD22GOPuOGGG+Kcc84p9ijUU6tWrYoePXrErbfeGtdee2107949xo8fX+yxdihHdGE3tG7duli0aFEMGDCgzvYBAwbEY489VqSpAHZN//rXvyLinbiAYqquro6pU6fG6tWro1evXsUeh3rsggsuiOOPPz6OPvroYo/ykWlY7AGAbfePf/wjqquro127dnW2t2vXLl599dUiTQWw6ykUCnHxxRfH5z73uTjooIOKPQ711OLFi6NXr16xdu3aaNasWUyfPj0++clPFnss6qmpU6fGU089FQsWLCj2KB8pR3TfY8yYMVFSUvK+XwsXLiz2mBAR7ywRfbdCobDJNoD67MILL4znnnsupkyZUuxRqMcOOOCAeOaZZ+KJJ56I888/P84666z44x//WOyxqIdefvnl+OpXvxp33nlnlJeXF3ucj5Qjuu9x4YUXxqmnnvq+t+ncufPOGQa2oHXr1lFaWrrJ0dvXX399k6O8APXVRRddFPfff388/PDD0bFjx2KPQz3WuHHj2G+//SIiomfPnrFgwYK4+eab44c//GGRJ6O+WbRoUbz++utx8MEH126rrq6Ohx9+OCZMmBBVVVVRWlpaxAl3HKH7Hq1bt47WrVsXewx4X40bN46DDz445s6dG0OHDq3dPnfu3BgyZEgRJwMovkKhEBdddFFMnz495s+fH126dCn2SFBHoVCIqqqqYo9BPdS/f/9YvHhxnW0jR46MT3ziE3HZZZelidwIofuhLF26NP75z3/G0qVLo7q6Op555pmIiNhvv/2iWbNmxR2O9C6++OI444wzomfPntGrV6/40Y9+FEuXLo3zzjuv2KNRD61atSpeeOGF2stLliyJZ555JvbYY4/Ye++9izgZ9dEFF1wQd999d9x3331RWVlZu/qlRYsWUVFRUeTpqG++9a1vxcCBA6NTp06xcuXKmDp1asyfPz/mzJlT7NGohyorKzc5X0HTpk2jVatW6c5jIHQ/hCuvvDLuuOOO2suf+cxnIiJi3rx50adPnyJNRX1xyimnxJtvvhlXX311vPLKK3HQQQfFrFmzYp999in2aNRDCxcujL59+9ZevvjiiyMi4qyzzorJkycXaSrqq41/du29/y+eNGlSjBgxYucPRL322muvxRlnnBGvvPJKtGjRIrp16xZz5syJY445ptijQWr+ji4AAACpOOsyAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAk07lz5xg/fnyxxwCAohG6AKQzYsSIKCkpiZKSkmjUqFHsu+++cemll8bq1auLPdpOsWDBgvjyl79c7DEAoGgaFnsAAPgoHHfccTFp0qRYv359PPLII3HuuefG6tWr47bbbqtzu/Xr10ejRo2KNOVHo02bNsUeAQCKyhFdAFIqKyuL9u3bR6dOnWL48OFx+umnx4wZM2LMmDHRvXv3uP3222PfffeNsrKyKBQK8a9//Su+/OUvR9u2baN58+bRr1+/ePbZZ+vs89prr422bdtGZWVlnHvuufGNb3wjunfvXnv9iBEj4qSTToobb7wx9txzz2jVqlVccMEFsX79+trb3HnnndGzZ8+orKyM9u3bx/Dhw+P111+vvX7+/PlRUlISv/3tb6Nnz57RpEmT6N27dzz//PN1Zrn//vujZ8+eUV5eHq1bt45hw4bVXvfepcsf9NyeffbZ6Nu3b1RWVkbz5s3j4IMPjoULF37YbwEAFI3QBaBeqKioqA3OF154IaZNmxb33ntvPPPMMxERcfzxx8err74as2bNikWLFkWPHj2if//+8c9//jMiIu666674zne+E9ddd10sWrQo9t57702ODkdEzJs3L1588cWYN29e3HHHHTF58uSYPHly7fXr1q2La665Jp599tmYMWNGLFmyJEaMGLHJfi6//PK46aabYuHChdGwYcM4++yza6+bOXNmDBs2LI4//vh4+umna6N4cwqFwgc+t9NPPz06duwYCxYsiEWLFsU3vvGNdEe5AahfSgqFQqHYQwDAjjRixIhYvnx5zJgxIyIifv/738egQYOif//+0bVr1/jud78bf//732uX+D744IMxdOjQeP3116OsrKx2P/vtt198/etfjy9/+ctx2GGHRc+ePWPChAm113/uc5+LVatW1cbyiBEjYv78+fHiiy9GaWlpREScfPLJ0aBBg5g6depmZ12wYEEccsghsXLlymjWrFnMnz8/+vbtG7/5zW+if//+ERExa9asOP7442PNmjVRXl4evXv3jn333TfuvPPOze6zc+fOMWrUqBg1atRWPbfmzZvHLbfcEmedddb2veAAsItxRBeAlB544IFo1qxZlJeXR69eveLII4+MW265JSIi9tlnnzq/x7po0aJYtWpVtGrVKpo1a1b7tWTJknjxxRcjIuL555+PQw45pM5jvPdyRMSBBx5YG7kREXvuuWedpclPP/10DBkyJPbZZ5+orKyMPn36RETE0qVL6+ynW7dudfYREbX7eeaZZ2oj+INszXO7+OKL49xzz42jjz46xo0bV7sdAHZXTkYFQEp9+/aN2267LRo1ahQdOnSosxS3adOmdW5bU1MTe+65Z8yfP3+T/bRs2bL23yUlJXWu29yiqPcu+S0pKYmampqIiFi9enUMGDAgBgwYEHfeeWe0adMmli5dGscee2ysW7dui/vZ+Lgb91NRUbGlp72JrXluY8aMieHDh8fMmTNj9uzZMXr06Jg6dWoMHTp0qx8HAHYlQheAlJo2bRr77bffVt22R48e8eqrr0bDhg2jc+fOm73NAQccEL///e/jjDPOqN22rSds+u///u/4xz/+EePGjYtOnTpt1z4i3jna+9vf/jZGjhz5gbfdmucWEbH//vvH/vvvH1/72tfitNNOi0mTJgldAHZbli4DUO8dffTR0atXrzjppJPiV7/6Vbz00kvx2GOPxbe//e3aEL3oooti4sSJcccdd8Sf//znuPbaa+O5557b5Cjv+9l7772jcePGccstt8Rf/vKXuP/+++Oaa67Z5nlHjx4dU6ZMidGjR8ef/vSnWLx4cVx//fXb9dzWrFkTF154YcyfPz/++te/xqOPPhoLFiyIrl27bvNcALCrELoA1HslJSUxa9asOPLII+Pss8+O/fffP0499dR46aWXol27dhHxzpmJv/nNb8all14aPXr0qD1bcnl5+VY/Tps2bWLy5Mnxs5/9LD75yU/GuHHj4sYbb9zmefv06RM/+9nP4v7774/u3btHv3794sknn9yu51ZaWhpvvvlmnHnmmbH//vvHySefHAMHDoyrrrpqm+cCgF2Fsy4DwHY65phjon379vHTn/602KMAAO/id3QBYCu8/fbb8Z//+Z9x7LHHRmlpaUyZMiV+85vfxNy5c4s9GgDwHo7oAsBWWLNmTQwePDieeuqpqKqqigMOOCC+/e1vx7Bhw4o9GgDwHkIXAACAVJyMCgAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAq/x9REeM7Vq8azgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7oAAANVCAYAAABWFoI6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4KklEQVR4nO3deZxVBd348e+dYZkBRnADIUAhTQtBRdQURURQEXBFjdxJXNJcyHLpEZBSlDStlLRHHjEVyBLRUDRTySVScUlNUx+XXDAxfiIkS8Lc3x+8mMeJbQaQge+836/XvF7ce86553vvXC7z4Zx7p1AsFosBAAAASZTU9QAAAACwLgldAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQCqPPnkk3H44YdH+/bto3HjxtGqVavYc88947vf/W619bbZZpvo37//am+vUCjEiBEjajXDuHHjolAorPZrm222iYiIk046KZo1a1aj216TeaZNmxaFQiF++9vf1mq7Dd0222xT7fEsKyuLbbfdNoYOHRr//Oc/63q8iPi/58Lbb79d623vu+++Wn+vAcijQV0PAMCG4d57741DDjkkevbsGaNHj47WrVvHBx98EDNmzIiJEyfG1VdfXevbnD59erRt27ZW2/Tr1y+mT59e7bo999wzBg4cWC24GzduvF7myax79+5x1VVXRUTEggULYsaMGTFixIh49NFHY8aMGXU83dq577774vrrrxe7APWU0AUgIiJGjx4dHTp0iAceeCAaNPi/fx6+8Y1vxOjRo9foNr/+9a/Xepstt9wyttxyy+Wub9Wq1Rrd3trOk1mLFi2qPSb77bdfzJs3L374wx/Ga6+9Fl/5ylfqcDoAWHNOXQYgIiJmz54dW2yxRbXIXaakZPX/XIwZMyYaNGgQw4cPr7ruP08VXnYq6iOPPBJnnHFGbLHFFrH55pvHEUccETNnzlyr+f/3f/83Dj744GjWrFm0a9cuvvvd78aiRYuqrbOiU5fff//9OPXUU6Ndu3bRqFGjaNOmTQwcODA+/PDDle5r7ty5ceCBB0arVq3iqaeeioiIESNGRKFQiL/+9a8xaNCgaN68ebRq1SoGDx4cn3zySbXti8VijBkzJnbeeecoLy+PTTfdNAYOHBhvvvlmtfWee+656N+/f7Rs2TIaN24cbdq0iX79+sV7771Xtc5vfvOb2GOPPaJ58+bRpEmT6NixYwwePHhNHsKIiGjevHlERDRs2LDa9ffcc0/sueee0aRJk6ioqIg+ffpUO/I+ceLEKBQKcd1111Xbbvjw4VFaWhoPPvhgRES8/fbbUSgUYvTo0XHZZZdF+/bto6ysLLp16xYPPfRQjWb8n//5n9hpp52irKwsNttsszj88MPjlVdeqVp+0kknxfXXXx8RUe307DU5BRqAjZPQBSAilp4e/OSTT8bZZ58dTz75ZHz22Wc12q5YLMb5558f5557btx0001x6aWXrnabU045JRo2bBjjx4+P0aNHx7Rp0+K4445b49k/++yzOOSQQ2L//fePu+++OwYPHhzXXHNNXHnllavc7v3334/ddtst7rrrrhg6dGhMnTo1rr322mjevHl8/PHHK9zmvffei7333jv+/ve/x/Tp02P33XevtvzII4+Mr3zlK3HnnXfGhRdeGOPHj4/zzjuv2jqnnXZanHvuudG7d++YPHlyjBkzJv7617/GXnvtVRXYn376afTp0yc+/PDDuP766+PBBx+Ma6+9Ntq3bx/z5s2LiKWnYh9zzDHRsWPHmDhxYtx7770xbNiwWLx4cY0et2KxGIsXL47FixfHv/71r3jkkUfi2muvje7du0eHDh2q1hs/fnwceuihsckmm8SECRNi7Nix8fHHH0fPnj3j8ccfj4ilR/5PP/30+O53v1t12vPDDz8cP/rRj+Liiy+OPn36VNv3ddddF/fff39ce+21cdttt0VJSUn07dt3udPW/9OoUaPiW9/6VnTq1CkmTZoUP/3pT+OFF16IPffcM15//fWIiLjkkkti4MCBVY/Rsq/WrVvX6HEBIIEiABSLxX/+85/FvffeuxgRxYgoNmzYsLjXXnsVR40aVZw3b161dbfeeutiv379ivPnzy8eeeSRxebNmxf/8Ic/LHebEVEcPnx41eWbb765GBHFb3/729XWGz16dDEiih988MEKZ4uI4plnnrnCZSeeeGIxIop33HFHtesPPvjg4vbbb7/KeQYPHlxs2LBh8eWXX17hbReLxeIjjzxSjIjib37zm+Jzzz1XbNOmTXGfffYpzp49u9p6w4cPL0ZEcfTo0dWu//a3v10sKysrVlZWFovFYnH69OnFiCheffXV1dZ79913i+Xl5cXvf//7xWKxWJwxY0YxIoqTJ09e6WxXXXVVMSKKc+bMWek6K7P11ltXfa8//7X77rtX+z4sWbKk2KZNm2Lnzp2LS5Ysqbp+3rx5xZYtWxb32muvqusWLlxY3GWXXYodOnQovvzyy8VWrVoV99133+LixYur1nnrrbeKEVFs06ZNccGCBVXXz507t7jZZpsVe/fuXXXdsufLW2+9VSwWi8WPP/64WF5eXjz44IOr3Zd33nmn2Lhx4+I3v/nNquvOPPPMoh9zAOovR3QBiIiIzTffPB577LF4+umn44orrohDDz00Xnvttbjooouic+fOy30S7+zZs6NXr17x1FNPxeOPPx77779/jfd1yCGHVLvcpUuXiIj4+9//vkazFwqFGDBgwHK3ubrbmzp1auy3337x1a9+dbX7eOCBB2KfffaJHj16xIMPPhibbbbZCtdb0X1buHBhzJo1KyIipkyZEoVCIY477riqo6mLFy+OrbbaKnbaaaeYNm1aRERsu+22semmm8YFF1wQN9xwQ7z88svL7Wu33XaLiIijjz467rjjjnj//fdXez8+b++9946nn346nn766XjiiSdi7Nix8dFHH0WvXr2qvt+vvvpqzJw5M44//vhqp7A3a9YsjjzyyPjzn/8c8+fPj4ilHxB2xx13xOzZs6Nr165RLBZjwoQJUVpauty+jzjiiCgrK6u6XFFREQMGDIhHH300lixZssJ5p0+fHgsWLIiTTjqp2vXt2rWLXr161fjUZwDyE7oAVNOtW7e44IIL4je/+U3MnDkzzjvvvHj77beX+0Cq1157LZ588sno27dv7LjjjrXax+abb17t8rJPUF6wYMEazdykSZNq0bTsNhcuXLjK7T766KMafwrz5MmTY8GCBXHGGWes8hOfV3ffPvzwwygWi9GqVato2LBhta8///nPVYHZvHnz+OMf/xg777xzXHzxxdGpU6do06ZNDB8+vOq08h49esTkyZNj8eLFccIJJ0Tbtm1jxx13jAkTJtToPjVv3jy6desW3bp1i7322isGDx4c48ePj1deeaXqU7Znz54dEbHC037btGkTlZWV1U7z3nbbbWOfffaJhQsXxrHHHrvS04W32mqrFV7373//O/71r3+tcJvVzbJsOQAIXQBWqmHDhlUfLvXSSy9VW7bnnnvGzTffHGPHjo3TTjstKisr62LEtbLllltW+2CnVbnmmmuib9++0bdv3/j973+/xvvcYostolAoxOOPP151NPXzX5MnT65at3PnzjFx4sSYPXt2PP/883HMMcfEyJEjq/2qp0MPPTQeeuih+OSTT2LatGnRtm3b+OY3v7na97quzLKj63/5y18i4v/C/YMPPlhu3ZkzZ0ZJSUlsuummVdfddNNNce+998buu+8e1113XTz55JMr3M8//vGPFV7XqFGjlf5e5NXNssUWW6zqrgFQjwhdACJixfEQEVWfZtumTZvllp144okxceLEuPnmm+OEE05Y6SmnG6q+ffvGI488Eq+++upq1y0rK4tJkyZF//7945BDDom77757jfbZv3//KBaL8f7771cdTf38V+fOnZfbplAoxE477RTXXHNNtGjRIp599tnl1mncuHHsu+++VR/A9dxzz63RfM8//3xERLRs2TIiIrbffvv40pe+FOPHj49isVi13qeffhp33nln1ScxR0S8+OKLcfbZZ8cJJ5wQjz32WHTp0iWOOeaYFX6w16RJk6odcZ83b1787ne/i3322WeFpzpHLP3PlfLy8rjtttuqXf/ee+/Fww8/XO30+bU9SwCAjZvfowtAREQceOCB0bZt2xgwYEDssMMOUVlZGc8//3xcffXV0axZszjnnHNWuN3AgQOjSZMmMXDgwFiwYEFMmDAhGjVqtJ6nXzMjR46MqVOnRo8ePeLiiy+Ozp07x5w5c+L++++PoUOHxg477FBt/YYNG8aECRPilFNOiYEDB8avfvWrGDRoUK322b179zj11FPj5JNPjhkzZkSPHj2iadOm8cEHH8Tjjz8enTt3jjPOOCOmTJkSY8aMicMOOyw6duwYxWIxJk2aFHPmzKn6BONhw4bFe++9F/vvv3+0bds25syZEz/96U+jYcOGse+++652ljlz5sSf//zniFj6ydWvvPJKXH755dG4ceM488wzI2Lpr5YaPXp0HHvssdG/f/847bTTYtGiRfHjH/845syZE1dccUVELA3fo48+Ojp06BBjxoyJRo0axR133BFdu3aNk08+udqR6oiI0tLS6NOnTwwdOjQqKyvjyiuvjLlz567yU7tbtGgRl1xySVx88cVxwgknxKBBg2L27Nlx6aWXRllZWbVfbbXsPwyuvPLK6Nu3b5SWlkaXLl02mucmAGtH6AIQERH/9V//FXfffXdcc8018cEHH8SiRYuidevW0bt377joootW+YFNBx98cNx3330xYMCAOPTQQ2PSpElRXl6+HqdfM1/60pfiqaeeiuHDh8cVV1wRs2fPji233DL23nvvlX7YVElJSYwdOzYqKiriuOOOi08//TROOeWUWu33xhtvjK9//etx4403xpgxY6KysjLatGkT3bt3r/p1Rdttt120aNEiRo8eHTNnzoxGjRrF9ttvH+PGjYsTTzwxIiL22GOPmDFjRlxwwQXx0UcfRYsWLaJbt27x8MMPR6dOnVY7xxNPPBF77rlnRCwNzy996Uux++67xw9+8IPYeeedq9b75je/GU2bNo1Ro0bFMcccE6WlpfH1r389Hnnkkdhrr70iIuL000+Pd955J55++ulo2rRpRER07NgxbrrppjjqqKPi2muvjXPPPbfqNs8666xYuHBhnH322TFr1qzo1KlT3HvvvdG9e/dVznzRRRdFy5Yt42c/+1n8+te/jvLy8ujZs2dcfvnlsd1221Wb+YknnogxY8bEyJEjo1gsxltvvRXbbLPNah8XADZ+heLnz0MCAPgCvf3229GhQ4f48Y9/HOeff35djwNAUt6jCwAAQCpCFwAAgFScugwAAEAqjugCAACQitAFAAAgFaELAABAKmv8e3QrKytj5syZUVFREYVCYV3OBAAAAMspFosxb968aNOmTZSUrPy47RqH7syZM6Ndu3ZrujkAAACskXfffTfatm270uVrHLoVFRVVO9hkk03W9GYAAACgRubOnRvt2rWr6tGVWePQXXa68iabbCJ0AQAAWG9W9/ZZH0YFAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAglQZ1PQDURLFYjIULF67V9osWLYqIiMaNG0ehUFhXo6VVVlbmcQIAYKMkdNkoLFy4MPr27VvXY9QrU6dOjfLy8roeAwAAas2pywAAAKTiiC4bnX/tPCiKJbV86i75LCr+MjEiIubt9I2I0oZfwGQbv0Ll4mj2/IS6HgMAANaK0GWjUyxpsHahWtpQ6K5Esa4HAACAdcCpywAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqDep6gC9SsViMhQsXRkREWVlZFAqFOp4IYOPhNRQA2FilPqK7cOHC6Nu3b/Tt27fqhzUAasZrKACwsUodugAAANQ/QhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBWGO9evWKnj17Rq9evVa4fMCAAdGzZ88YMGDACpePGDEievbsGSNGjFjpPs4666zo2bNnnHXWWWs049puX5MZ19bYsWOjV69eMXbs2DVavi6sj/sJUFvr4/WPpbI91kIXgDUyderUqKysjIiIysrKmDp1arXlzz77bMybNy8iIubNmxfPPvtsteUffvhhTJs2LSIipk2bFh9++OFy+3jnnXfipZdeioiIl156Kd55551azbi229dkxrU1Z86cuP3226OysjJuv/32mDNnTq2Wrwvr434C1Nb6eP1jqYyPtdAFYI1ceeWVq7w8dOjQVV7+zyOs3/nOd5bbx+mnn77Ky6uzttvXZMa1dckll1T7D4Nhw4bVavm6sD7uJ0BtrY/XP5bK+Fg3qOsBvkjFYrHqzwsXLqzDSVhb1b5/n/u+so75O8PnfP45UPyPv3cnn3zyCrc5+eST4+abb17p6a8jRoyIESNGxP333x8fffRRtWWzZs2K+++/Pw466KCIiJgwYULMnz+/2jrz58+PCRMmxKBBg1Y7/9puX5MZ19aMGTPixRdfrHbdCy+8EDNmzIhu3bqtdvm6sD7uJ0BtrY/XP5bK+lgXiv/508tKLFq0KBYtWlR1ee7cudGuXbv45JNPYpNNNvnCBlwbH3/8cRx++OF1PQbr2LydvhHRqEntNlryWVQ8e+vS7bseH1Ha8AuYLIF/z4+Kv0ys6ynYAN11112x6aabRkTEp59+Gv369VvpupMmTYojjjhipcvvu+++GDBgQCxZsmS5ZaWlpfH73/8+isVi9O7de6W38Yc//CEaNFj5/9UuXrx4rbZfsmRJHHDAAaucsbS0dKXb10RlZWUcdthhMXfu3OWWbbLJJlWP48qWT548OUpK1u7ErPVxPwFqa3Wvj+vi9Y+lNsbHeu7cudG8efPVdmiNpx41alQ0b9686qtdu3brZFAANi5DhgxZ5fJjjjlmlcvPOOOMFYZVxNLwmjJlSvzqV79a5W180cunTJmy2hnX1pNPPrnCHywilv4j/qtf/WqVy5988sm1nmF93E+A2lrd6+O6eP1jqcyPdeojuvPnz4+DDz44IpYejSgrK6vjiVhTCxcurDo6P2+X4yIaNKrdDTiiWzOL/x0Vz90WEf7OUP3v3X333RdNmiw9k+KLPKLboEGDeOCBBzboI7rLZvwij+g2b9487rzzzpUe0W3evHncddddX+gR3XV1PwFqa3Wvj+vi9Y+lNsbHuqZHdGv8Ht3GjRtH48aN18lw60uhUKj6c1lZWZSXl9fhNKwzn/u+so75O8NKfP71tGnTptGhQ4d46623llvvy1/+cmy22WbRs2fPqk/x/bxevXpFkyZN4nvf+15cccUVyy3//ve/XxVWp512Wtx4443LrXPGGWesMlIjlkba2mxfWlpaoxnXRklJSQwbNizOP//85ZYNHz48GjRosMrl6+IHj/VxPwFqa3WvjxtaeG3MMj/WG+/kANSZm2++eYXXL/vdeyv7MKpln+J40EEHxZZbblltWcuWLeOAAw6oujxo0KCqo8jLNGnSZLWnRq+r7Wsy49rq1q1bdO7cudp1Xbp0ia5du9Zo+bqwPu4nQG2tj9c/lsr6WAtdANbIBRdcsMrLP/nJT1Z5+brrrqt2+ec///ly+7jhhhtWeXl11nb7msy4tn74wx9W/Y95SUlJjBw5slbL14X1cT8Bamt9vP6xVMbHWugCsEb69u1b7R/Fvn37VlvetWvXqKioiIiIioqK5f5nuFWrVtGzZ8+IiOjZs2e0atVquX20b98+dtxxx4iI2HHHHaN9+/a1mnFtt6/JjGurRYsWceyxx0ZJSUkce+yx0aJFi1otXxfWx/0EqK318frHUhkf6xp/GNV/qumbgOvSggULqn7wmjp1qvcbbsQ+/71cow+T8mFUNfO5x8nfGbyGAgAbmnX+64UAAABgYyB0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIJUGdT3AF6msrCymTp1a9WcAas5rKACwsUoduoVCIcrLy+t6DICNktdQAGBj5dRlAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIJUGdT0A1FahcnEUa7vRks9W/GeqKVQurusRAABgrQldNjrNnp+wVttX/GXiOpoEAADYEDl1GQAAgFQc0WWjUFZWFlOnTl3j7YvFYixatCgiIho3bhyFQmFdjZZWWVlZXY8AAABrROiyUSgUClFeXr5Wt9GkSZN1NA0AALAhc+oyAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBQAAIBWhCwAAQCpCFwAAgFSELgAAAKkIXQAAAFIRugAAAKQidAEAAEhF6AIAAJCK0AUAACAVoQsAAEAqQhcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqTRY0w2LxWJERMydO3edDQMAAAArs6w/l/Xoyqxx6M6bNy8iItq1a7emNwEAAAC1Nm/evGjevPlKlxeKq0vhlaisrIyZM2dGRUVFFAqFNR5wfZg7d260a9cu3n333dhkk03qehzqMc9FNgSeh2wIPA/ZUHgusiHwPKy5YrEY8+bNizZt2kRJycrfibvGR3RLSkqibdu2a7p5ndhkk008cdggeC6yIfA8ZEPgeciGwnORDYHnYc2s6kjuMj6MCgAAgFSELgAAAKnUi9Bt3LhxDB8+PBo3blzXo1DPeS6yIfA8ZEPgeciGwnORDYHn4bq3xh9GBQAAABuienFEFwAAgPpD6AIAAJCK0AUAACAVoQsAAEAq9S5033777fjWt74VHTp0iPLy8vjyl78cw4cPj3//+991PRrJjRkzJjp06BBlZWWx6667xmOPPVbXI1HPjBo1KnbbbbeoqKiIli1bxmGHHRavvvpqXY9FPTdq1KgoFApx7rnn1vUo1DPvv/9+HHfccbH55ptHkyZNYuedd45nnnmmrseiHlm8eHH813/9V1WXdOzYMUaOHBmVlZV1PVoKDep6gPXtb3/7W1RWVsaNN94Y2267bbz00ksxZMiQ+PTTT+Oqq66q6/FI6te//nWce+65MWbMmOjevXvceOON0bdv33j55Zejffv2dT0e9cQf//jHOPPMM2O33XaLxYsXxw9+8IM44IAD4uWXX46mTZvW9XjUQ08//XT88pe/jC5dutT1KNQzH3/8cXTv3j3222+/mDp1arRs2TLeeOONaNGiRV2PRj1y5ZVXxg033BC33HJLdOrUKWbMmBEnn3xyNG/ePM4555y6Hm+j59cLRcSPf/zj+MUvfhFvvvlmXY9CUnvssUd07do1fvGLX1Rd99WvfjUOO+ywGDVqVB1ORn320UcfRcuWLeOPf/xj9OjRo67HoZ7517/+FV27do0xY8bEj370o9h5553j2muvreuxqCcuvPDCeOKJJ5xdRZ3q379/tGrVKsaOHVt13ZFHHhlNmjSJW2+9tQ4ny6Henbq8Ip988klsttlmdT0GSf373/+OZ555Jg444IBq1x9wwAHxpz/9qY6mgqWvfRHh9Y86ceaZZ0a/fv2id+/edT0K9dA999wT3bp1i6OOOipatmwZu+yyS/z3f/93XY9FPbP33nvHQw89FK+99lpERPzlL3+Jxx9/PA4++OA6niyHenfq8n9644034uc//3lcffXVdT0KSf3zn/+MJUuWRKtWrapd36pVq/jHP/5RR1NR3xWLxRg6dGjsvffeseOOO9b1ONQzEydOjGeffTaefvrpuh6FeurNN9+MX/ziFzF06NC4+OKL46mnnoqzzz47GjduHCeccEJdj0c9ccEFF8Qnn3wSO+ywQ5SWlsaSJUvisssui0GDBtX1aCmkOaI7YsSIKBQKq/yaMWNGtW1mzpwZBx10UBx11FFxyimn1NHk1BeFQqHa5WKxuNx1sL6cddZZ8cILL8SECRPqehTqmXfffTfOOeecuO2226KsrKyux6GeqqysjK5du8bll18eu+yyS5x22mkxZMiQam8xgi/ar3/967jtttti/Pjx8eyzz8Ytt9wSV111Vdxyyy11PVoKaY7onnXWWfGNb3xjletss802VX+eOXNm7LfffrHnnnvGL3/5yy94OuqzLbbYIkpLS5c7ejtr1qzljvLC+vCd73wn7rnnnnj00Uejbdu2dT0O9cwzzzwTs2bNil133bXquiVLlsSjjz4a1113XSxatChKS0vrcELqg9atW8fXvva1atd99atfjTvvvLOOJqI++t73vhcXXnhhVcN07tw5/v73v8eoUaPixBNPrOPpNn5pQneLLbaILbbYokbrvv/++7HffvvFrrvuGjfffHOUlKQ5sM0GqFGjRrHrrrvGgw8+GIcffnjV9Q8++GAceuihdTgZ9U2xWIzvfOc7cdddd8W0adOiQ4cOdT0S9dD+++8fL774YrXrTj755Nhhhx3iggsuELmsF927d1/u16u99tprsfXWW9fRRNRH8+fPX65DSktL/XqhdSRN6NbUzJkzo2fPntG+ffu46qqr4qOPPqpattVWW9XhZGQ2dOjQOP7446Nbt25VZxG88847cfrpp9f1aNQjZ555ZowfPz7uvvvuqKioqDrLoHnz5lFeXl7H01FfVFRULPe+8KZNm8bmm2/u/eKsN+edd17stddecfnll8fRRx8dTz31VPzyl790lh/r1YABA+Kyyy6L9u3bR6dOneK5556Ln/zkJzF48OC6Hi2FevfrhcaNGxcnn3zyCpfVs4eC9WzMmDExevTo+OCDD2LHHXeMa665xq90Yb1a2XvCb7755jjppJPW7zDwOT179vTrhVjvpkyZEhdddFG8/vrr0aFDhxg6dGgMGTKkrseiHpk3b15ccsklcdddd8WsWbOiTZs2MWjQoBg2bFg0atSorsfb6NW70AUAACA3b04FAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUhG6AAAApCJ0AQAASEXoAgAAkIrQBSCtQqEQkydPXunybbbZJq699tp1us+TTjopDjvssFWuU5v9jhs3Llq0aLHWcwFAfSJ0AdhozZo1K0477bRo3759NG7cOLbaaqs48MADY/r06TXa/umnn45TTz21RuuOGDEiCoXCKr/efvvtdb5fAKD2GtT1AACwpo488sj47LPP4pZbbomOHTvGhx9+GA899FD8v//3/2q0/ZZbblnjfZ1//vlx+umnV13ebbfd4tRTT40hQ4bU+vZqs18AoPYc0QVgozRnzpx4/PHH48orr4z99tsvtt5669h9993joosuin79+q1wm5EjR0arVq3i+eefj4jlTyEuFApx0003xeGHHx5NmjSJ7bbbLu65556IiGjWrFlstdVWVV+lpaVRUVGx3HXLXHXVVdG6devYfPPN48wzz4zPPvusatl/7nfOnDlx6qmnRqtWraKsrCx23HHHmDJlygrvw+zZs2P33XePQw45JBYuXBjTpk2LQqEQDz30UHTr1i2aNGkSe+21V7z66qvVtvvd734Xu+66a5SVlUXHjh3j0ksvjcWLF1ctHzFiRNWR8TZt2sTZZ59dtWzMmDGx3XbbRVlZWbRq1SoGDhy46m8OANQxoQvARqlZs2bRrFmzmDx5cixatGiV6xaLxTjnnHNi7Nix8fjjj8fOO++80nUvvfTSOProo+OFF16Igw8+OI499tgaHyFe5pFHHok33ngjHnnkkbjlllti3LhxMW7cuBWuW1lZGX379o0//elPcdttt8XLL78cV1xxRbVoXua9996LffbZJ3bYYYeYNGlSlJWVVS37wQ9+EFdffXXMmDEjGjRoEIMHD65a9sADD8Rxxx0XZ599drz88stx4403xrhx4+Kyyy6LiIjf/va3cc0118SNN94Yr7/+ekyePDk6d+4cEREzZsyIs88+O0aOHBmvvvpq3H///dGjR49aPR4AsL45dRmAjVKDBg1i3LhxMWTIkLjhhhuia9euse+++8Y3vvGN6NKlS9V6ixcvjhNOOCFmzJgRTzzxRLRt23aVt3vSSSfFoEGDIiLi8ssvj5///Ofx1FNPxUEHHVTj2TbddNO47rrrorS0NHbYYYfo169fPPTQQ9VOc17mD3/4Qzz11FPxyiuvxFe+8pWIiOjYseNy67322mvRp0+fOPTQQ+OnP/1pFAqFassvu+yy2HfffSMi4sILL4x+/frFwoULo6ysLC677LK48MIL48QTT6y6/R/+8Ifx/e9/P4YPHx7vvPNObLXVVtG7d+9o2LBhtG/fPnbfffeIiHjnnXeiadOm0b9//6ioqIitt946dtlllxo/FgBQFxzRBWCjdeSRR8bMmTPjnnvuiQMPPDCmTZsWXbt2rXb09Lzzzovp06fHY489ttrIjYhqkdy0adOoqKiIWbNm1WquTp06VTsi27p165XexvPPPx9t27atitwVWbBgQey9995x2GGHxc9+9rPlIvc/527dunVERNU+n3nmmRg5cmTVUfBmzZrFkCFD4oMPPoj58+fHUUcdFQsWLIiOHTvGkCFD4q677qo6rblPnz6x9dZbR8eOHeP444+P22+/PebPn1+rxwMA1jehC8BGraysLPr06RPDhg2LP/3pT3HSSSfF8OHDq5b36dMn3n///XjggQdqdHsNGzasdrlQKERlZWWtZqrNbZSXl6/29ho3bhy9e/eOe++9N957773V7nNZCC/bZ2VlZVx66aXx/PPPV329+OKL8frrr0dZWVm0a9cuXn311bj++uujvLw8vv3tb0ePHj3is88+i4qKinj22WdjwoQJ0bp16xg2bFjstNNOMWfOnJo8FABQJ4QuAKl87Wtfi08//bTq8iGHHBLjx4+PU045JSZOnFiHk61Yly5d4r333ovXXnttpeuUlJTErbfeGrvuumv06tUrZs6cWat9dO3aNV599dXYdtttl/sqKVn6o0B5eXkccsgh8bOf/SymTZsW06dPjxdffDEilp4m3rt37xg9enS88MIL8fbbb8fDDz+85ncaAL5g3qMLwEZp9uzZcdRRR8XgwYOjS5cuUVFRETNmzIjRo0fHoYceWm3dww8/PG699dY4/vjjo0GDBhvUpwbvu+++0aNHjzjyyCPjJz/5SWy77bbxt7/9LQqFQrX3BZeWlsbtt98egwYNil69esW0adNiq622qtE+hg0bFv3794927drFUUcdFSUlJfHCCy/Eiy++GD/60Y9i3LhxsWTJkthjjz2iSZMmceutt0Z5eXlsvfXWMWXKlHjzzTejR48esemmm8Z9990XlZWVsf32239RDwkArDWhC8BGqVmzZrHHHnvENddcE2+88UZ89tln0a5duxgyZEhcfPHFy60/cODAqKysjOOPPz5KSkriiCOOqIOpV+zOO++M888/PwYNGhSffvppbLvttnHFFVcst16DBg1iwoQJccwxx1TFbk0ceOCBMWXKlBg5cmSMHj06GjZsGDvssEOccsopERHRokWLuOKKK2Lo0KGxZMmS6Ny5c/zud7+LzTffPFq0aBGTJk2KESNGxMKFC2O77baLCRMmRKdOndblQwAA61ShWCwW63oIAAAAWFe8RxcAAIBUhC4AAACpCF0AAABSEboAAACkInQBAABIRegCAACQitAFAAAgFaELAABAKkIXAACAVIQuAAAAqQhdAAAAUvn/0c+cjB9Jhf8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for column in dataset.columns[:-1]:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.title(f\"{column} Boxplot\")\n",
    "    sns.boxplot(data=dataset, x=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56ff5027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies: 12 outliers\n",
      "Glucose: 0 outliers\n",
      "BloodPressure: 37 outliers\n",
      "SkinThickness: 43 outliers\n",
      "Insulin: 220 outliers\n",
      "BMI: 30 outliers\n",
      "DiabetesPedigreeFunction: 68 outliers\n",
      "Age: 48 outliers\n"
     ]
    }
   ],
   "source": [
    "for column in dataset.columns[:-1]:\n",
    "    Q1 = dataset[column].quantile(0.25)\n",
    "    Q3 = dataset[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outlier_range = (dataset[column] < (Q1 - 1.5*IQR)) | (dataset[column] > (Q3 + 1.5 * IQR))\n",
    "    num_outliers = dataset[column][outlier_range].count()\n",
    "    \n",
    "    print(f\"{column}: {num_outliers} outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3067f388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5be3b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframeInNumpy = dataset.values\n",
    "inputVariables = dataframeInNumpy[:,:8]\n",
    "outputVariables = dataframeInNumpy[:,8:]\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputVariables, outputVariables, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde8870f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ade0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7159092d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 4s 17ms/step - loss: 0.4932 - accuracy: 0.7563 - val_loss: 0.4581 - val_accuracy: 0.7850\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4302 - accuracy: 0.7900 - val_loss: 0.4215 - val_accuracy: 0.8025\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.7981 - val_loss: 0.4358 - val_accuracy: 0.7750\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8037 - val_loss: 0.3852 - val_accuracy: 0.8225\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8156 - val_loss: 0.3978 - val_accuracy: 0.8000\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8213 - val_loss: 0.3509 - val_accuracy: 0.8325\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.8444 - val_loss: 0.3419 - val_accuracy: 0.8450\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3024 - accuracy: 0.8625 - val_loss: 0.3284 - val_accuracy: 0.8400\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2868 - accuracy: 0.8581 - val_loss: 0.3305 - val_accuracy: 0.8500\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2618 - accuracy: 0.8881 - val_loss: 0.3026 - val_accuracy: 0.8650\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2322 - accuracy: 0.9031 - val_loss: 0.3171 - val_accuracy: 0.8675\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2251 - accuracy: 0.9019 - val_loss: 0.2658 - val_accuracy: 0.8700\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1996 - accuracy: 0.9150 - val_loss: 0.2277 - val_accuracy: 0.8975\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1785 - accuracy: 0.9244 - val_loss: 0.2260 - val_accuracy: 0.8975\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1555 - accuracy: 0.9331 - val_loss: 0.1934 - val_accuracy: 0.9225\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1336 - accuracy: 0.9488 - val_loss: 0.2018 - val_accuracy: 0.9125\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 0.9606 - val_loss: 0.1725 - val_accuracy: 0.9325\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0820 - accuracy: 0.9756 - val_loss: 0.1370 - val_accuracy: 0.9600\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9787 - val_loss: 0.1502 - val_accuracy: 0.9550\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0879 - accuracy: 0.9719 - val_loss: 0.1549 - val_accuracy: 0.9500\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0911 - accuracy: 0.9694 - val_loss: 0.1523 - val_accuracy: 0.9550\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0750 - accuracy: 0.9781 - val_loss: 0.1301 - val_accuracy: 0.9700\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.9681 - val_loss: 0.1908 - val_accuracy: 0.9550\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0599 - accuracy: 0.9812 - val_loss: 0.1060 - val_accuracy: 0.9675\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9912 - val_loss: 0.0806 - val_accuracy: 0.9725\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0238 - accuracy: 0.9937 - val_loss: 0.0788 - val_accuracy: 0.9725\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.0831 - val_accuracy: 0.9750\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 0.9962 - val_loss: 0.0779 - val_accuracy: 0.9825\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0269 - accuracy: 0.9906 - val_loss: 0.1209 - val_accuracy: 0.9600\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0683 - accuracy: 0.9756 - val_loss: 0.1461 - val_accuracy: 0.9450\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.9719 - val_loss: 0.1463 - val_accuracy: 0.9525\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0604 - accuracy: 0.9781 - val_loss: 0.1361 - val_accuracy: 0.9450\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0265 - accuracy: 0.9950 - val_loss: 0.0838 - val_accuracy: 0.9850\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.0761 - val_accuracy: 0.9825\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.0689 - val_accuracy: 0.9825\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9987 - val_loss: 0.0733 - val_accuracy: 0.9825\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9825\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9825\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9825\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9825\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9825\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9825\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9825\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9825\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9825\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9825\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 9.2439e-04 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9825\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 8.3323e-04 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9825\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 7.9679e-04 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9825\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 6.8084e-04 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9825\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 7.0042e-04 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9825\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 8.3394e-04 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9825\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9825\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.9844 - val_loss: 0.3987 - val_accuracy: 0.9325\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2208 - accuracy: 0.9325 - val_loss: 0.4223 - val_accuracy: 0.8925\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.9669 - val_loss: 0.1663 - val_accuracy: 0.9550\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9881 - val_loss: 0.0822 - val_accuracy: 0.9725\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0260 - accuracy: 0.9937 - val_loss: 0.0987 - val_accuracy: 0.9650\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0171 - accuracy: 0.9962 - val_loss: 0.0786 - val_accuracy: 0.9750\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0152 - accuracy: 0.9962 - val_loss: 0.0714 - val_accuracy: 0.9775\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0698 - val_accuracy: 0.9800\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9800\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9800\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9800\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9800\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 0.9800\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 0.9800\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9800\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 8.4174e-04 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 0.9800\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 7.7837e-04 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9800\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 6.9836e-04 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9800\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 6.6177e-04 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9800\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.9599e-04 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9800\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 5.4357e-04 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9800\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.0392e-04 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9800\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.6639e-04 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9800\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.3145e-04 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9800\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.9754e-04 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9800\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.6374e-04 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9800\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.8073e-04 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9800\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.3112e-04 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9800\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.0912e-04 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9800\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.9515e-04 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9800\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.7034e-04 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9800\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.5184e-04 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9800\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.3844e-04 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9800\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.2682e-04 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9800\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.1449e-04 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9800\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.0363e-04 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9800\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.9788e-04 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9800\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.8471e-04 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9800\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.7318e-04 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9800\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.6731e-04 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9800\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.5881e-04 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9800\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.5229e-04 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9800\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.4189e-04 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9800\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.3792e-04 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9800\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.3107e-04 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9800\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.2408e-04 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9800\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1788e-04 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 0.9800\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9960\n",
      "\n",
      "accuracy: 99.60%\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "The new predection is: [[1.]]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "The new predection is: [[0.9481019]]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "The new predection is: [[0.00037893]]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "The new predection is: [[1.]]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "The new predection is: [[3.38094e-05]]\n",
      "train_accuracy: 1.0\n",
      "train_error: 0.0001107482603401877)\n",
      "test_accuracy: 0.9800000190734863\n",
      "test_error: 0.11034965515136719\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(320,input_dim=8, activation='relu'))\n",
    "model.add(Dense(160, activation='relu'))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "history=model.fit(x_train,y_train,epochs=100,batch_size=30,validation_data=(x_test,y_test))\n",
    "scores = model.evaluate(inputVariables,outputVariables)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1],scores[1]*100))\n",
    "print(\"The new predection is:\",model.predict(np.array([z_score([6,142,72,45,0,38.6,0.627,50])])))\n",
    "print(\"The new predection is:\",model.predict(np.array([z_score([1,109,30,38,83,53.3,0.193,33])])))\n",
    "print(\"The new predection is:\",model.predict(np.array([z_score([2,112,68,22,94,34.1,0.315,26])])))\n",
    "print(\"The new predection is:\",model.predict(np.array([z_score([2,197,70,45,543,30.5,0.158,53])])))\n",
    "print(\"The new predection is:\",model.predict(np.array([z_score([3,180,64,25,70,34,0.271,26])])))\n",
    "tr_eval_res = model.evaluate(x_train,y_train,verbose=0)\n",
    "eval_res= model.evaluate(x_test,y_test,verbose=0)\n",
    "print(f'train_accuracy: {tr_eval_res[1]}')\n",
    "print(f'train_error: {tr_eval_res[0]})')\n",
    "print(f'test_accuracy: {eval_res[1]}')\n",
    "print(f'test_error: {eval_res[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910cd33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90aa716b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.5774 - accuracy: 0.6956 - val_loss: 0.5064 - val_accuracy: 0.7650\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7800 - val_loss: 0.4682 - val_accuracy: 0.7750\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7831 - val_loss: 0.4516 - val_accuracy: 0.7725\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7850 - val_loss: 0.4438 - val_accuracy: 0.7900\n",
      "Epoch 5/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.7975 - val_loss: 0.4388 - val_accuracy: 0.7825\n",
      "Epoch 6/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.7969 - val_loss: 0.4365 - val_accuracy: 0.7825\n",
      "Epoch 7/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8037 - val_loss: 0.4234 - val_accuracy: 0.8100\n",
      "Epoch 8/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8056 - val_loss: 0.4220 - val_accuracy: 0.8025\n",
      "Epoch 9/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8112 - val_loss: 0.4128 - val_accuracy: 0.8150\n",
      "Epoch 10/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8100 - val_loss: 0.4087 - val_accuracy: 0.8150\n",
      "Epoch 11/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3825 - accuracy: 0.8219 - val_loss: 0.4041 - val_accuracy: 0.8150\n",
      "Epoch 12/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3750 - accuracy: 0.8219 - val_loss: 0.3974 - val_accuracy: 0.8225\n",
      "Epoch 13/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8275 - val_loss: 0.3885 - val_accuracy: 0.8225\n",
      "Epoch 14/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8306 - val_loss: 0.3899 - val_accuracy: 0.8350\n",
      "Epoch 15/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3587 - accuracy: 0.8338 - val_loss: 0.3860 - val_accuracy: 0.8275\n",
      "Epoch 16/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8369 - val_loss: 0.3878 - val_accuracy: 0.8250\n",
      "Epoch 17/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8338 - val_loss: 0.3756 - val_accuracy: 0.8350\n",
      "Epoch 18/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8381 - val_loss: 0.3700 - val_accuracy: 0.8375\n",
      "Epoch 19/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3392 - accuracy: 0.8475 - val_loss: 0.3726 - val_accuracy: 0.8325\n",
      "Epoch 20/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8506 - val_loss: 0.3635 - val_accuracy: 0.8325\n",
      "Epoch 21/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3280 - accuracy: 0.8500 - val_loss: 0.3598 - val_accuracy: 0.8375\n",
      "Epoch 22/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3241 - accuracy: 0.8512 - val_loss: 0.3588 - val_accuracy: 0.8375\n",
      "Epoch 23/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.8562 - val_loss: 0.3550 - val_accuracy: 0.8475\n",
      "Epoch 24/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3147 - accuracy: 0.8644 - val_loss: 0.3566 - val_accuracy: 0.8350\n",
      "Epoch 25/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8612 - val_loss: 0.3533 - val_accuracy: 0.8425\n",
      "Epoch 26/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3086 - accuracy: 0.8650 - val_loss: 0.3463 - val_accuracy: 0.8425\n",
      "Epoch 27/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3030 - accuracy: 0.8675 - val_loss: 0.3445 - val_accuracy: 0.8375\n",
      "Epoch 28/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2967 - accuracy: 0.8694 - val_loss: 0.3373 - val_accuracy: 0.8400\n",
      "Epoch 29/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2928 - accuracy: 0.8731 - val_loss: 0.3408 - val_accuracy: 0.8375\n",
      "Epoch 30/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2905 - accuracy: 0.8744 - val_loss: 0.3621 - val_accuracy: 0.8250\n",
      "Epoch 31/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2835 - accuracy: 0.8712 - val_loss: 0.3460 - val_accuracy: 0.8475\n",
      "Epoch 32/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2769 - accuracy: 0.8788 - val_loss: 0.3331 - val_accuracy: 0.8575\n",
      "Epoch 33/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2736 - accuracy: 0.8794 - val_loss: 0.3349 - val_accuracy: 0.8575\n",
      "Epoch 34/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2677 - accuracy: 0.8838 - val_loss: 0.3230 - val_accuracy: 0.8500\n",
      "Epoch 35/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2624 - accuracy: 0.8900 - val_loss: 0.3206 - val_accuracy: 0.8675\n",
      "Epoch 36/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2575 - accuracy: 0.8969 - val_loss: 0.3131 - val_accuracy: 0.8675\n",
      "Epoch 37/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2551 - accuracy: 0.8969 - val_loss: 0.3098 - val_accuracy: 0.8700\n",
      "Epoch 38/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2543 - accuracy: 0.8913 - val_loss: 0.3097 - val_accuracy: 0.8600\n",
      "Epoch 39/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2455 - accuracy: 0.9019 - val_loss: 0.3271 - val_accuracy: 0.8675\n",
      "Epoch 40/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2439 - accuracy: 0.9019 - val_loss: 0.3013 - val_accuracy: 0.8800\n",
      "Epoch 41/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2398 - accuracy: 0.9069 - val_loss: 0.3035 - val_accuracy: 0.8775\n",
      "Epoch 42/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2332 - accuracy: 0.9106 - val_loss: 0.2970 - val_accuracy: 0.8850\n",
      "Epoch 43/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2317 - accuracy: 0.9100 - val_loss: 0.3137 - val_accuracy: 0.8650\n",
      "Epoch 44/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2252 - accuracy: 0.9150 - val_loss: 0.2883 - val_accuracy: 0.8875\n",
      "Epoch 45/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2212 - accuracy: 0.9181 - val_loss: 0.2863 - val_accuracy: 0.8825\n",
      "Epoch 46/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2186 - accuracy: 0.9156 - val_loss: 0.2860 - val_accuracy: 0.8925\n",
      "Epoch 47/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2160 - accuracy: 0.9137 - val_loss: 0.2825 - val_accuracy: 0.8975\n",
      "Epoch 48/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2112 - accuracy: 0.9237 - val_loss: 0.2790 - val_accuracy: 0.9000\n",
      "Epoch 49/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2067 - accuracy: 0.9287 - val_loss: 0.2858 - val_accuracy: 0.8775\n",
      "Epoch 50/50\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2040 - accuracy: 0.9275 - val_loss: 0.2873 - val_accuracy: 0.8725\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.9215\n",
      "\n",
      "accuracy: 92.15%\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "The new predection is: [[0.87328947]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "The new predection is: [[0.02443473]]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "The new predection is: [[0.21831837]]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "The new predection is: [[0.9999913]]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "The new predection is: [[0.838728]]\n",
      "train_accuracy: 0.9337499737739563\n",
      "train_error: 0.19521911442279816)\n",
      "test_accuracy: 0.8725000023841858\n",
      "test_error: 0.28732964396476746\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(100,input_dim=8, activation='relu'))\n",
    "model2.add(Dense(20, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "history2=model2.fit(x_train,y_train,epochs=50,batch_size=30,validation_data=(x_test,y_test))\n",
    "scores = model2.evaluate(inputVariables,outputVariables)\n",
    "print(\"\\n%s: %.2f%%\" % (model2.metrics_names[1],scores[1]*100))\n",
    "print(\"The new predection is:\",model2.predict(np.array([z_score([6,142,72,45,0,38.6,0.627,50])])))\n",
    "print(\"The new predection is:\",model2.predict(np.array([z_score([1,109,30,38,83,53.3,0.193,33])])))\n",
    "print(\"The new predection is:\",model2.predict(np.array([z_score([2,112,68,22,94,34.1,0.315,26])])))\n",
    "print(\"The new predection is:\",model2.predict(np.array([z_score([2,197,70,45,543,30.5,0.158,53])])))\n",
    "print(\"The new predection is:\",model2.predict(np.array([z_score([3,180,64,25,70,34,0.271,26])])))\n",
    "tr_eval_res = model2.evaluate(x_train,y_train,verbose=0)\n",
    "eval_res= model2.evaluate(x_test,y_test,verbose=0)\n",
    "print(f'train_accuracy: {tr_eval_res[1]}')\n",
    "print(f'train_error: {tr_eval_res[0]})')\n",
    "print(f'test_accuracy: {eval_res[1]}')\n",
    "print(f'test_error: {eval_res[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3687a5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "54/54 [==============================] - 2s 10ms/step - loss: 0.6000 - accuracy: 0.7131 - val_loss: 0.5077 - val_accuracy: 0.7475\n",
      "Epoch 2/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7688 - val_loss: 0.4678 - val_accuracy: 0.7725\n",
      "Epoch 3/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.7812 - val_loss: 0.4505 - val_accuracy: 0.7800\n",
      "Epoch 4/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7806 - val_loss: 0.4482 - val_accuracy: 0.7750\n",
      "Epoch 5/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7881 - val_loss: 0.4324 - val_accuracy: 0.7875\n",
      "Epoch 6/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.7925 - val_loss: 0.4270 - val_accuracy: 0.7875\n",
      "Epoch 7/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7969 - val_loss: 0.4191 - val_accuracy: 0.7900\n",
      "Epoch 8/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8019 - val_loss: 0.4124 - val_accuracy: 0.7950\n",
      "Epoch 9/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8087 - val_loss: 0.4093 - val_accuracy: 0.8000\n",
      "Epoch 10/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8106 - val_loss: 0.4012 - val_accuracy: 0.8075\n",
      "Epoch 11/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8106 - val_loss: 0.3956 - val_accuracy: 0.8050\n",
      "Epoch 12/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3805 - accuracy: 0.8156 - val_loss: 0.3949 - val_accuracy: 0.8050\n",
      "Epoch 13/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3765 - accuracy: 0.8200 - val_loss: 0.3855 - val_accuracy: 0.8150\n",
      "Epoch 14/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8213 - val_loss: 0.3798 - val_accuracy: 0.8175\n",
      "Epoch 15/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3678 - accuracy: 0.8294 - val_loss: 0.3728 - val_accuracy: 0.8275\n",
      "Epoch 16/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8350 - val_loss: 0.3769 - val_accuracy: 0.8250\n",
      "Epoch 17/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.8356 - val_loss: 0.3745 - val_accuracy: 0.8275\n",
      "Epoch 18/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3530 - accuracy: 0.8394 - val_loss: 0.3689 - val_accuracy: 0.8300\n",
      "Epoch 19/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8469 - val_loss: 0.3558 - val_accuracy: 0.8375\n",
      "Epoch 20/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3435 - accuracy: 0.8419 - val_loss: 0.3605 - val_accuracy: 0.8350\n",
      "Epoch 21/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.8388 - val_loss: 0.3554 - val_accuracy: 0.8450\n",
      "Epoch 22/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 0.8450 - val_loss: 0.3497 - val_accuracy: 0.8475\n",
      "Epoch 23/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3310 - accuracy: 0.8506 - val_loss: 0.3499 - val_accuracy: 0.8350\n",
      "Epoch 24/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.8494 - val_loss: 0.3497 - val_accuracy: 0.8350\n",
      "Epoch 25/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.8569 - val_loss: 0.3419 - val_accuracy: 0.8425\n",
      "Epoch 26/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8569 - val_loss: 0.3283 - val_accuracy: 0.8600\n",
      "Epoch 27/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8537 - val_loss: 0.3337 - val_accuracy: 0.8400\n",
      "Epoch 28/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.3095 - accuracy: 0.8637 - val_loss: 0.3375 - val_accuracy: 0.8425\n",
      "Epoch 29/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3031 - accuracy: 0.8637 - val_loss: 0.3318 - val_accuracy: 0.8425\n",
      "Epoch 30/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3036 - accuracy: 0.8619 - val_loss: 0.3267 - val_accuracy: 0.8500\n",
      "Epoch 31/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 0.8644 - val_loss: 0.3171 - val_accuracy: 0.8625\n",
      "Epoch 32/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2920 - accuracy: 0.8681 - val_loss: 0.3174 - val_accuracy: 0.8675\n",
      "Epoch 33/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2861 - accuracy: 0.8656 - val_loss: 0.3195 - val_accuracy: 0.8600\n",
      "Epoch 34/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2838 - accuracy: 0.8719 - val_loss: 0.3024 - val_accuracy: 0.8700\n",
      "Epoch 35/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2798 - accuracy: 0.8694 - val_loss: 0.3052 - val_accuracy: 0.8775\n",
      "Epoch 36/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2770 - accuracy: 0.8737 - val_loss: 0.3036 - val_accuracy: 0.8775\n",
      "Epoch 37/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2703 - accuracy: 0.8794 - val_loss: 0.2994 - val_accuracy: 0.8600\n",
      "Epoch 38/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2678 - accuracy: 0.8769 - val_loss: 0.2933 - val_accuracy: 0.8800\n",
      "Epoch 39/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2627 - accuracy: 0.8838 - val_loss: 0.2828 - val_accuracy: 0.8775\n",
      "Epoch 40/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2598 - accuracy: 0.8856 - val_loss: 0.2810 - val_accuracy: 0.8925\n",
      "Epoch 41/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2553 - accuracy: 0.8881 - val_loss: 0.2808 - val_accuracy: 0.8875\n",
      "Epoch 42/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2498 - accuracy: 0.8931 - val_loss: 0.2887 - val_accuracy: 0.8700\n",
      "Epoch 43/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2453 - accuracy: 0.8944 - val_loss: 0.2868 - val_accuracy: 0.8675\n",
      "Epoch 44/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2439 - accuracy: 0.8906 - val_loss: 0.2743 - val_accuracy: 0.8825\n",
      "Epoch 45/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2402 - accuracy: 0.8956 - val_loss: 0.2800 - val_accuracy: 0.8825\n",
      "Epoch 46/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2331 - accuracy: 0.8963 - val_loss: 0.2636 - val_accuracy: 0.8925\n",
      "Epoch 47/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2303 - accuracy: 0.9019 - val_loss: 0.2636 - val_accuracy: 0.8875\n",
      "Epoch 48/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2307 - accuracy: 0.9050 - val_loss: 0.2757 - val_accuracy: 0.8850\n",
      "Epoch 49/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2253 - accuracy: 0.9062 - val_loss: 0.2536 - val_accuracy: 0.8925\n",
      "Epoch 50/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2181 - accuracy: 0.9044 - val_loss: 0.2763 - val_accuracy: 0.8775\n",
      "Epoch 51/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2195 - accuracy: 0.9081 - val_loss: 0.2696 - val_accuracy: 0.8800\n",
      "Epoch 52/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2120 - accuracy: 0.9100 - val_loss: 0.2550 - val_accuracy: 0.8925\n",
      "Epoch 53/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2089 - accuracy: 0.9150 - val_loss: 0.2528 - val_accuracy: 0.8900\n",
      "Epoch 54/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2091 - accuracy: 0.9131 - val_loss: 0.2488 - val_accuracy: 0.8900\n",
      "Epoch 55/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.2023 - accuracy: 0.9212 - val_loss: 0.2475 - val_accuracy: 0.8925\n",
      "Epoch 56/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1986 - accuracy: 0.9219 - val_loss: 0.2412 - val_accuracy: 0.8900\n",
      "Epoch 57/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1976 - accuracy: 0.9294 - val_loss: 0.2519 - val_accuracy: 0.8900\n",
      "Epoch 58/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1931 - accuracy: 0.9256 - val_loss: 0.2288 - val_accuracy: 0.8875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1904 - accuracy: 0.9362 - val_loss: 0.2384 - val_accuracy: 0.8950\n",
      "Epoch 60/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1869 - accuracy: 0.9331 - val_loss: 0.2425 - val_accuracy: 0.8900\n",
      "Epoch 61/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1817 - accuracy: 0.9362 - val_loss: 0.2275 - val_accuracy: 0.8975\n",
      "Epoch 62/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1787 - accuracy: 0.9337 - val_loss: 0.2221 - val_accuracy: 0.8925\n",
      "Epoch 63/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1744 - accuracy: 0.9413 - val_loss: 0.2372 - val_accuracy: 0.8925\n",
      "Epoch 64/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1711 - accuracy: 0.9394 - val_loss: 0.2337 - val_accuracy: 0.8925\n",
      "Epoch 65/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1717 - accuracy: 0.9394 - val_loss: 0.2118 - val_accuracy: 0.9075\n",
      "Epoch 66/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1658 - accuracy: 0.9450 - val_loss: 0.2283 - val_accuracy: 0.8950\n",
      "Epoch 67/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1630 - accuracy: 0.9419 - val_loss: 0.2228 - val_accuracy: 0.9025\n",
      "Epoch 68/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1578 - accuracy: 0.9475 - val_loss: 0.2153 - val_accuracy: 0.8975\n",
      "Epoch 69/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1558 - accuracy: 0.9494 - val_loss: 0.2270 - val_accuracy: 0.9200\n",
      "Epoch 70/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1528 - accuracy: 0.9494 - val_loss: 0.2124 - val_accuracy: 0.8975\n",
      "Epoch 71/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1491 - accuracy: 0.9513 - val_loss: 0.2060 - val_accuracy: 0.9025\n",
      "Epoch 72/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1465 - accuracy: 0.9569 - val_loss: 0.2047 - val_accuracy: 0.9000\n",
      "Epoch 73/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1434 - accuracy: 0.9538 - val_loss: 0.2042 - val_accuracy: 0.9125\n",
      "Epoch 74/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1396 - accuracy: 0.9569 - val_loss: 0.2029 - val_accuracy: 0.9100\n",
      "Epoch 75/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1353 - accuracy: 0.9550 - val_loss: 0.2076 - val_accuracy: 0.9225\n",
      "Epoch 76/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.9563 - val_loss: 0.1976 - val_accuracy: 0.9250\n",
      "Epoch 77/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1303 - accuracy: 0.9563 - val_loss: 0.2175 - val_accuracy: 0.9325\n",
      "Epoch 78/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1283 - accuracy: 0.9600 - val_loss: 0.1868 - val_accuracy: 0.9250\n",
      "Epoch 79/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1256 - accuracy: 0.9594 - val_loss: 0.1771 - val_accuracy: 0.9225\n",
      "Epoch 80/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1209 - accuracy: 0.9656 - val_loss: 0.1900 - val_accuracy: 0.9150\n",
      "Epoch 81/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1232 - accuracy: 0.9606 - val_loss: 0.1929 - val_accuracy: 0.9225\n",
      "Epoch 82/200\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.9644 - val_loss: 0.1921 - val_accuracy: 0.9325\n",
      "Epoch 83/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1167 - accuracy: 0.9675 - val_loss: 0.1700 - val_accuracy: 0.9225\n",
      "Epoch 84/200\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1138 - accuracy: 0.9656 - val_loss: 0.1896 - val_accuracy: 0.9275\n",
      "Epoch 85/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1097 - accuracy: 0.9663 - val_loss: 0.1808 - val_accuracy: 0.9300\n",
      "Epoch 86/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1087 - accuracy: 0.9688 - val_loss: 0.1584 - val_accuracy: 0.9450\n",
      "Epoch 87/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1063 - accuracy: 0.9681 - val_loss: 0.1586 - val_accuracy: 0.9425\n",
      "Epoch 88/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1028 - accuracy: 0.9694 - val_loss: 0.1832 - val_accuracy: 0.9250\n",
      "Epoch 89/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1003 - accuracy: 0.9725 - val_loss: 0.1927 - val_accuracy: 0.9375\n",
      "Epoch 90/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9694 - val_loss: 0.1695 - val_accuracy: 0.9375\n",
      "Epoch 91/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9737 - val_loss: 0.1569 - val_accuracy: 0.9375\n",
      "Epoch 92/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0953 - accuracy: 0.9700 - val_loss: 0.1608 - val_accuracy: 0.9325\n",
      "Epoch 93/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0941 - accuracy: 0.9737 - val_loss: 0.1490 - val_accuracy: 0.9375\n",
      "Epoch 94/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0932 - accuracy: 0.9737 - val_loss: 0.1523 - val_accuracy: 0.9350\n",
      "Epoch 95/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9769 - val_loss: 0.1417 - val_accuracy: 0.9400\n",
      "Epoch 96/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0878 - accuracy: 0.9737 - val_loss: 0.1434 - val_accuracy: 0.9425\n",
      "Epoch 97/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0844 - accuracy: 0.9769 - val_loss: 0.1535 - val_accuracy: 0.9450\n",
      "Epoch 98/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0846 - accuracy: 0.9769 - val_loss: 0.1366 - val_accuracy: 0.9475\n",
      "Epoch 99/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0833 - accuracy: 0.9775 - val_loss: 0.1306 - val_accuracy: 0.9400\n",
      "Epoch 100/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9756 - val_loss: 0.1444 - val_accuracy: 0.9450\n",
      "Epoch 101/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9781 - val_loss: 0.1288 - val_accuracy: 0.9525\n",
      "Epoch 102/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0762 - accuracy: 0.9781 - val_loss: 0.1350 - val_accuracy: 0.9450\n",
      "Epoch 103/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9812 - val_loss: 0.1348 - val_accuracy: 0.9400\n",
      "Epoch 104/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0756 - accuracy: 0.9812 - val_loss: 0.1282 - val_accuracy: 0.9400\n",
      "Epoch 105/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9850 - val_loss: 0.1240 - val_accuracy: 0.9675\n",
      "Epoch 106/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0701 - accuracy: 0.9825 - val_loss: 0.1176 - val_accuracy: 0.9650\n",
      "Epoch 107/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9844 - val_loss: 0.1243 - val_accuracy: 0.9625\n",
      "Epoch 108/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0701 - accuracy: 0.9819 - val_loss: 0.1274 - val_accuracy: 0.9500\n",
      "Epoch 109/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9844 - val_loss: 0.1166 - val_accuracy: 0.9600\n",
      "Epoch 110/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9825 - val_loss: 0.1140 - val_accuracy: 0.9575\n",
      "Epoch 111/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.9856 - val_loss: 0.1206 - val_accuracy: 0.9600\n",
      "Epoch 112/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9875 - val_loss: 0.1142 - val_accuracy: 0.9575\n",
      "Epoch 113/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9875 - val_loss: 0.1142 - val_accuracy: 0.9575\n",
      "Epoch 114/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9881 - val_loss: 0.1103 - val_accuracy: 0.9600\n",
      "Epoch 115/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9887 - val_loss: 0.1071 - val_accuracy: 0.9700\n",
      "Epoch 116/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9900 - val_loss: 0.1050 - val_accuracy: 0.9725\n",
      "Epoch 117/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9887 - val_loss: 0.1019 - val_accuracy: 0.9675\n",
      "Epoch 118/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0554 - accuracy: 0.9906 - val_loss: 0.1373 - val_accuracy: 0.9550\n",
      "Epoch 119/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9906 - val_loss: 0.1089 - val_accuracy: 0.9600\n",
      "Epoch 120/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9875 - val_loss: 0.0998 - val_accuracy: 0.9725\n",
      "Epoch 121/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9900 - val_loss: 0.0973 - val_accuracy: 0.9750\n",
      "Epoch 122/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9887 - val_loss: 0.0987 - val_accuracy: 0.9700\n",
      "Epoch 123/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0478 - accuracy: 0.9912 - val_loss: 0.0967 - val_accuracy: 0.9800\n",
      "Epoch 124/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9912 - val_loss: 0.0915 - val_accuracy: 0.9725\n",
      "Epoch 125/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.9919 - val_loss: 0.1070 - val_accuracy: 0.9675\n",
      "Epoch 126/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0480 - accuracy: 0.9881 - val_loss: 0.1141 - val_accuracy: 0.9725\n",
      "Epoch 127/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0456 - accuracy: 0.9919 - val_loss: 0.0908 - val_accuracy: 0.9800\n",
      "Epoch 128/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0444 - accuracy: 0.9906 - val_loss: 0.0850 - val_accuracy: 0.9800\n",
      "Epoch 129/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.9919 - val_loss: 0.0843 - val_accuracy: 0.9900\n",
      "Epoch 130/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9919 - val_loss: 0.0831 - val_accuracy: 0.9775\n",
      "Epoch 131/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9944 - val_loss: 0.0875 - val_accuracy: 0.9800\n",
      "Epoch 132/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9931 - val_loss: 0.0871 - val_accuracy: 0.9600\n",
      "Epoch 133/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9912 - val_loss: 0.0822 - val_accuracy: 0.9850\n",
      "Epoch 134/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0374 - accuracy: 0.9950 - val_loss: 0.0794 - val_accuracy: 0.9800\n",
      "Epoch 135/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.9944 - val_loss: 0.0796 - val_accuracy: 0.9825\n",
      "Epoch 136/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0367 - accuracy: 0.9962 - val_loss: 0.0783 - val_accuracy: 0.9825\n",
      "Epoch 137/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 0.9950 - val_loss: 0.0786 - val_accuracy: 0.9850\n",
      "Epoch 138/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9944 - val_loss: 0.0775 - val_accuracy: 0.9875\n",
      "Epoch 139/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 0.9944 - val_loss: 0.0720 - val_accuracy: 0.9750\n",
      "Epoch 140/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9969 - val_loss: 0.0701 - val_accuracy: 0.9850\n",
      "Epoch 141/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9950 - val_loss: 0.0720 - val_accuracy: 0.9875\n",
      "Epoch 142/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0341 - accuracy: 0.9944 - val_loss: 0.0701 - val_accuracy: 0.9900\n",
      "Epoch 143/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9950 - val_loss: 0.0679 - val_accuracy: 0.9850\n",
      "Epoch 144/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0314 - accuracy: 0.9950 - val_loss: 0.0667 - val_accuracy: 0.9875\n",
      "Epoch 145/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9962 - val_loss: 0.0665 - val_accuracy: 0.9850\n",
      "Epoch 146/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0326 - accuracy: 0.9925 - val_loss: 0.0678 - val_accuracy: 0.9825\n",
      "Epoch 147/200\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0276 - accuracy: 0.9969 - val_loss: 0.0656 - val_accuracy: 0.9825\n",
      "Epoch 148/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 0.9950 - val_loss: 0.0694 - val_accuracy: 0.9875\n",
      "Epoch 149/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.9969 - val_loss: 0.0631 - val_accuracy: 0.9900\n",
      "Epoch 150/200\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0261 - accuracy: 0.9956 - val_loss: 0.0602 - val_accuracy: 0.9875\n",
      "Epoch 151/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0267 - accuracy: 0.9962 - val_loss: 0.0672 - val_accuracy: 0.9900\n",
      "Epoch 152/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9975 - val_loss: 0.0668 - val_accuracy: 0.9900\n",
      "Epoch 153/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9969 - val_loss: 0.0591 - val_accuracy: 0.9875\n",
      "Epoch 154/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9975 - val_loss: 0.0573 - val_accuracy: 0.9875\n",
      "Epoch 155/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9975 - val_loss: 0.0610 - val_accuracy: 0.9850\n",
      "Epoch 156/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9975 - val_loss: 0.0581 - val_accuracy: 0.9900\n",
      "Epoch 157/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9981 - val_loss: 0.0585 - val_accuracy: 0.9875\n",
      "Epoch 158/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9969 - val_loss: 0.0560 - val_accuracy: 0.9900\n",
      "Epoch 159/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9987 - val_loss: 0.0579 - val_accuracy: 0.9900\n",
      "Epoch 160/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0205 - accuracy: 0.9969 - val_loss: 0.0567 - val_accuracy: 0.9900\n",
      "Epoch 161/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9975 - val_loss: 0.0569 - val_accuracy: 0.9900\n",
      "Epoch 162/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9981 - val_loss: 0.0543 - val_accuracy: 0.9900\n",
      "Epoch 163/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 0.9981 - val_loss: 0.0613 - val_accuracy: 0.9925\n",
      "Epoch 164/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.9969 - val_loss: 0.0549 - val_accuracy: 0.9925\n",
      "Epoch 165/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.9981 - val_loss: 0.0548 - val_accuracy: 0.9900\n",
      "Epoch 166/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 0.9975 - val_loss: 0.0642 - val_accuracy: 0.9925\n",
      "Epoch 167/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 0.9975 - val_loss: 0.0563 - val_accuracy: 0.9900\n",
      "Epoch 168/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9975 - val_loss: 0.0551 - val_accuracy: 0.9925\n",
      "Epoch 169/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9981 - val_loss: 0.0552 - val_accuracy: 0.9900\n",
      "Epoch 170/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9981 - val_loss: 0.0498 - val_accuracy: 0.9875\n",
      "Epoch 171/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0152 - accuracy: 0.9981 - val_loss: 0.0458 - val_accuracy: 0.9900\n",
      "Epoch 172/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9981 - val_loss: 0.0518 - val_accuracy: 0.9900\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9981 - val_loss: 0.0471 - val_accuracy: 0.9900\n",
      "Epoch 174/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9981 - val_loss: 0.0542 - val_accuracy: 0.9925\n",
      "Epoch 175/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9994 - val_loss: 0.0448 - val_accuracy: 0.9925\n",
      "Epoch 176/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9987 - val_loss: 0.0492 - val_accuracy: 0.9925\n",
      "Epoch 177/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9987 - val_loss: 0.0573 - val_accuracy: 0.9900\n",
      "Epoch 178/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9987 - val_loss: 0.0447 - val_accuracy: 0.9875\n",
      "Epoch 179/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9987 - val_loss: 0.0581 - val_accuracy: 0.9900\n",
      "Epoch 180/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.9862 - val_loss: 0.1103 - val_accuracy: 0.9725\n",
      "Epoch 181/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0382 - accuracy: 0.9900 - val_loss: 0.0660 - val_accuracy: 0.9900\n",
      "Epoch 182/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9975 - val_loss: 0.0562 - val_accuracy: 0.9900\n",
      "Epoch 183/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9981 - val_loss: 0.0509 - val_accuracy: 0.9925\n",
      "Epoch 184/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9987 - val_loss: 0.0523 - val_accuracy: 0.9925\n",
      "Epoch 185/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 0.9987 - val_loss: 0.0570 - val_accuracy: 0.9925\n",
      "Epoch 186/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9987 - val_loss: 0.0504 - val_accuracy: 0.9925\n",
      "Epoch 187/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9987 - val_loss: 0.0525 - val_accuracy: 0.9925\n",
      "Epoch 188/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9981 - val_loss: 0.0585 - val_accuracy: 0.9925\n",
      "Epoch 189/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9994 - val_loss: 0.0490 - val_accuracy: 0.9950\n",
      "Epoch 190/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9994 - val_loss: 0.0457 - val_accuracy: 0.9925\n",
      "Epoch 191/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9987 - val_loss: 0.0490 - val_accuracy: 0.9950\n",
      "Epoch 192/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9994 - val_loss: 0.0497 - val_accuracy: 0.9925\n",
      "Epoch 193/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9987 - val_loss: 0.0495 - val_accuracy: 0.9925\n",
      "Epoch 194/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9981 - val_loss: 0.0518 - val_accuracy: 0.9925\n",
      "Epoch 195/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9987 - val_loss: 0.0519 - val_accuracy: 0.9950\n",
      "Epoch 196/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9994 - val_loss: 0.0529 - val_accuracy: 0.9925\n",
      "Epoch 197/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9994 - val_loss: 0.0455 - val_accuracy: 0.9950\n",
      "Epoch 198/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9994 - val_loss: 0.0459 - val_accuracy: 0.9950\n",
      "Epoch 199/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9950\n",
      "Epoch 200/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 0.9987 - val_loss: 0.0468 - val_accuracy: 0.9925\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9975\n",
      "\n",
      "accuracy: 99.75%\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "The new predection is: [[0.9811615]]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "The new predection is: [[0.00767933]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "The new predection is: [[0.00597429]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "The new predection is: [[1.]]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "The new predection is: [[0.0233996]]\n",
      "train_accuracy: 0.9987499713897705\n",
      "train_error: 0.007867786101996899)\n",
      "test_accuracy: 0.9925000071525574\n",
      "test_error: 0.0467744916677475\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(100,input_dim=8, activation='relu'))\n",
    "model3.add(Dense(20, activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "history3=model3.fit(x_train,y_train,epochs=200,batch_size=30,validation_data=(x_test,y_test))\n",
    "scores = model3.evaluate(inputVariables,outputVariables)\n",
    "print(\"\\n%s: %.2f%%\" % (model3.metrics_names[1],scores[1]*100))\n",
    "print(\"The new predection is:\",model3.predict(np.array([z_score([6,142,72,45,0,38.6,0.627,50])])))\n",
    "print(\"The new predection is:\",model3.predict(np.array([z_score([1,109,30,38,83,53.3,0.193,33])])))\n",
    "print(\"The new predection is:\",model3.predict(np.array([z_score([2,112,68,22,94,34.1,0.315,26])])))\n",
    "print(\"The new predection is:\",model3.predict(np.array([z_score([2,197,70,45,543,30.5,0.158,53])])))\n",
    "print(\"The new predection is:\",model3.predict(np.array([z_score([3,180,64,25,70,34,0.271,26])])))\n",
    "tr_eval_res = model3.evaluate(x_train,y_train,verbose=0)\n",
    "eval_res= model3.evaluate(x_test,y_test,verbose=0)\n",
    "print(f'train_accuracy: {tr_eval_res[1]}')\n",
    "print(f'train_error: {tr_eval_res[0]})')\n",
    "print(f'test_accuracy: {eval_res[1]}')\n",
    "print(f'test_error: {eval_res[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae7181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7aa5f9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 1s 31ms/step - loss: 0.7704 - accuracy: 0.3350 - val_loss: 0.7446 - val_accuracy: 0.3750\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.7379 - accuracy: 0.3831 - val_loss: 0.7192 - val_accuracy: 0.4425\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.7112 - accuracy: 0.4487 - val_loss: 0.6978 - val_accuracy: 0.5200\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6886 - accuracy: 0.5244 - val_loss: 0.6793 - val_accuracy: 0.6150\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6687 - accuracy: 0.6094 - val_loss: 0.6632 - val_accuracy: 0.6675\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6514 - accuracy: 0.6606 - val_loss: 0.6492 - val_accuracy: 0.6950\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6363 - accuracy: 0.6931 - val_loss: 0.6368 - val_accuracy: 0.7025\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6230 - accuracy: 0.7138 - val_loss: 0.6259 - val_accuracy: 0.7000\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6113 - accuracy: 0.7212 - val_loss: 0.6162 - val_accuracy: 0.7000\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6010 - accuracy: 0.7300 - val_loss: 0.6073 - val_accuracy: 0.7050\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5914 - accuracy: 0.7369 - val_loss: 0.5992 - val_accuracy: 0.7125\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5827 - accuracy: 0.7431 - val_loss: 0.5919 - val_accuracy: 0.7175\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5749 - accuracy: 0.7437 - val_loss: 0.5851 - val_accuracy: 0.7150\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5677 - accuracy: 0.7481 - val_loss: 0.5791 - val_accuracy: 0.7250\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5612 - accuracy: 0.7481 - val_loss: 0.5733 - val_accuracy: 0.7250\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5551 - accuracy: 0.7494 - val_loss: 0.5681 - val_accuracy: 0.7250\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5494 - accuracy: 0.7525 - val_loss: 0.5631 - val_accuracy: 0.7300\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5442 - accuracy: 0.7544 - val_loss: 0.5584 - val_accuracy: 0.7275\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5392 - accuracy: 0.7544 - val_loss: 0.5542 - val_accuracy: 0.7275\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5347 - accuracy: 0.7544 - val_loss: 0.5503 - val_accuracy: 0.7250\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5306 - accuracy: 0.7569 - val_loss: 0.5465 - val_accuracy: 0.7300\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5266 - accuracy: 0.7581 - val_loss: 0.5431 - val_accuracy: 0.7400\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5231 - accuracy: 0.7594 - val_loss: 0.5399 - val_accuracy: 0.7400\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5197 - accuracy: 0.7606 - val_loss: 0.5368 - val_accuracy: 0.7425\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5165 - accuracy: 0.7625 - val_loss: 0.5339 - val_accuracy: 0.7425\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5134 - accuracy: 0.7613 - val_loss: 0.5312 - val_accuracy: 0.7475\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5106 - accuracy: 0.7588 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5080 - accuracy: 0.7613 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5056 - accuracy: 0.7625 - val_loss: 0.5242 - val_accuracy: 0.7550\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5033 - accuracy: 0.7650 - val_loss: 0.5220 - val_accuracy: 0.7600\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5011 - accuracy: 0.7644 - val_loss: 0.5200 - val_accuracy: 0.7650\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4991 - accuracy: 0.7644 - val_loss: 0.5182 - val_accuracy: 0.7650\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4971 - accuracy: 0.7644 - val_loss: 0.5165 - val_accuracy: 0.7650\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4954 - accuracy: 0.7644 - val_loss: 0.5147 - val_accuracy: 0.7650\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4936 - accuracy: 0.7669 - val_loss: 0.5131 - val_accuracy: 0.7700\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4921 - accuracy: 0.7681 - val_loss: 0.5116 - val_accuracy: 0.7650\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4904 - accuracy: 0.7675 - val_loss: 0.5101 - val_accuracy: 0.7650\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4889 - accuracy: 0.7663 - val_loss: 0.5087 - val_accuracy: 0.7650\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4875 - accuracy: 0.7681 - val_loss: 0.5075 - val_accuracy: 0.7675\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4862 - accuracy: 0.7681 - val_loss: 0.5063 - val_accuracy: 0.7700\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4849 - accuracy: 0.7694 - val_loss: 0.5051 - val_accuracy: 0.7700\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4837 - accuracy: 0.7694 - val_loss: 0.5040 - val_accuracy: 0.7675\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4825 - accuracy: 0.7706 - val_loss: 0.5028 - val_accuracy: 0.7675\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4814 - accuracy: 0.7694 - val_loss: 0.5020 - val_accuracy: 0.7675\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4803 - accuracy: 0.7694 - val_loss: 0.5010 - val_accuracy: 0.7700\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4793 - accuracy: 0.7713 - val_loss: 0.5000 - val_accuracy: 0.7700\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.4783 - accuracy: 0.7713 - val_loss: 0.4991 - val_accuracy: 0.7700\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4774 - accuracy: 0.7725 - val_loss: 0.4982 - val_accuracy: 0.7700\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4764 - accuracy: 0.7725 - val_loss: 0.4974 - val_accuracy: 0.7700\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4755 - accuracy: 0.7725 - val_loss: 0.4965 - val_accuracy: 0.7700\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4747 - accuracy: 0.7731 - val_loss: 0.4956 - val_accuracy: 0.7700\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4739 - accuracy: 0.7744 - val_loss: 0.4950 - val_accuracy: 0.7700\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4730 - accuracy: 0.7763 - val_loss: 0.4942 - val_accuracy: 0.7700\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4722 - accuracy: 0.7750 - val_loss: 0.4934 - val_accuracy: 0.7700\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4715 - accuracy: 0.7763 - val_loss: 0.4928 - val_accuracy: 0.7675\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4708 - accuracy: 0.7775 - val_loss: 0.4921 - val_accuracy: 0.7675\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4701 - accuracy: 0.7794 - val_loss: 0.4914 - val_accuracy: 0.7650\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4694 - accuracy: 0.7812 - val_loss: 0.4908 - val_accuracy: 0.7650\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4687 - accuracy: 0.7812 - val_loss: 0.4902 - val_accuracy: 0.7650\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4681 - accuracy: 0.7800 - val_loss: 0.4896 - val_accuracy: 0.7650\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4675 - accuracy: 0.7800 - val_loss: 0.4891 - val_accuracy: 0.7650\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4668 - accuracy: 0.7806 - val_loss: 0.4887 - val_accuracy: 0.7650\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4663 - accuracy: 0.7806 - val_loss: 0.4882 - val_accuracy: 0.7625\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4657 - accuracy: 0.7806 - val_loss: 0.4877 - val_accuracy: 0.7625\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4651 - accuracy: 0.7794 - val_loss: 0.4872 - val_accuracy: 0.7575\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4646 - accuracy: 0.7781 - val_loss: 0.4867 - val_accuracy: 0.7575\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4640 - accuracy: 0.7781 - val_loss: 0.4862 - val_accuracy: 0.7575\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4635 - accuracy: 0.7769 - val_loss: 0.4858 - val_accuracy: 0.7575\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4630 - accuracy: 0.7769 - val_loss: 0.4853 - val_accuracy: 0.7575\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4625 - accuracy: 0.7769 - val_loss: 0.4849 - val_accuracy: 0.7575\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4620 - accuracy: 0.7775 - val_loss: 0.4844 - val_accuracy: 0.7575\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4615 - accuracy: 0.7769 - val_loss: 0.4840 - val_accuracy: 0.7575\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4610 - accuracy: 0.7769 - val_loss: 0.4836 - val_accuracy: 0.7575\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4606 - accuracy: 0.7769 - val_loss: 0.4832 - val_accuracy: 0.7600\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4602 - accuracy: 0.7756 - val_loss: 0.4828 - val_accuracy: 0.7575\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4598 - accuracy: 0.7769 - val_loss: 0.4827 - val_accuracy: 0.7600\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4594 - accuracy: 0.7756 - val_loss: 0.4823 - val_accuracy: 0.7600\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4589 - accuracy: 0.7756 - val_loss: 0.4819 - val_accuracy: 0.7600\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4585 - accuracy: 0.7744 - val_loss: 0.4816 - val_accuracy: 0.7600\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4581 - accuracy: 0.7738 - val_loss: 0.4811 - val_accuracy: 0.7600\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4577 - accuracy: 0.7738 - val_loss: 0.4808 - val_accuracy: 0.7600\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4574 - accuracy: 0.7738 - val_loss: 0.4805 - val_accuracy: 0.7600\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4570 - accuracy: 0.7738 - val_loss: 0.4801 - val_accuracy: 0.7600\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4567 - accuracy: 0.7738 - val_loss: 0.4797 - val_accuracy: 0.7600\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4563 - accuracy: 0.7738 - val_loss: 0.4794 - val_accuracy: 0.7600\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.7738 - val_loss: 0.4792 - val_accuracy: 0.7600\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4557 - accuracy: 0.7738 - val_loss: 0.4789 - val_accuracy: 0.7600\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4553 - accuracy: 0.7731 - val_loss: 0.4786 - val_accuracy: 0.7600\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4550 - accuracy: 0.7725 - val_loss: 0.4784 - val_accuracy: 0.7600\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4547 - accuracy: 0.7725 - val_loss: 0.4780 - val_accuracy: 0.7625\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4543 - accuracy: 0.7750 - val_loss: 0.4777 - val_accuracy: 0.7650\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4540 - accuracy: 0.7763 - val_loss: 0.4774 - val_accuracy: 0.7650\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4537 - accuracy: 0.7769 - val_loss: 0.4773 - val_accuracy: 0.7650\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4534 - accuracy: 0.7775 - val_loss: 0.4771 - val_accuracy: 0.7650\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4531 - accuracy: 0.7775 - val_loss: 0.4767 - val_accuracy: 0.7650\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4528 - accuracy: 0.7775 - val_loss: 0.4765 - val_accuracy: 0.7650\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4526 - accuracy: 0.7775 - val_loss: 0.4762 - val_accuracy: 0.7650\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4523 - accuracy: 0.7769 - val_loss: 0.4758 - val_accuracy: 0.7650\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4519 - accuracy: 0.7775 - val_loss: 0.4756 - val_accuracy: 0.7650\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4517 - accuracy: 0.7775 - val_loss: 0.4753 - val_accuracy: 0.7650\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4514 - accuracy: 0.7775 - val_loss: 0.4751 - val_accuracy: 0.7650\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4512 - accuracy: 0.7781 - val_loss: 0.4749 - val_accuracy: 0.7650\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4509 - accuracy: 0.7775 - val_loss: 0.4747 - val_accuracy: 0.7650\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4506 - accuracy: 0.7788 - val_loss: 0.4744 - val_accuracy: 0.7650\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4503 - accuracy: 0.7788 - val_loss: 0.4741 - val_accuracy: 0.7650\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4501 - accuracy: 0.7781 - val_loss: 0.4739 - val_accuracy: 0.7650\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4498 - accuracy: 0.7794 - val_loss: 0.4737 - val_accuracy: 0.7625\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4496 - accuracy: 0.7794 - val_loss: 0.4734 - val_accuracy: 0.7625\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4494 - accuracy: 0.7788 - val_loss: 0.4732 - val_accuracy: 0.7625\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4491 - accuracy: 0.7788 - val_loss: 0.4730 - val_accuracy: 0.7625\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4489 - accuracy: 0.7788 - val_loss: 0.4728 - val_accuracy: 0.7625\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4487 - accuracy: 0.7812 - val_loss: 0.4726 - val_accuracy: 0.7650\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4484 - accuracy: 0.7831 - val_loss: 0.4723 - val_accuracy: 0.7650\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4482 - accuracy: 0.7831 - val_loss: 0.4721 - val_accuracy: 0.7700\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4480 - accuracy: 0.7850 - val_loss: 0.4719 - val_accuracy: 0.7700\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4477 - accuracy: 0.7850 - val_loss: 0.4717 - val_accuracy: 0.7700\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4475 - accuracy: 0.7850 - val_loss: 0.4715 - val_accuracy: 0.7725\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4473 - accuracy: 0.7850 - val_loss: 0.4715 - val_accuracy: 0.7675\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4471 - accuracy: 0.7844 - val_loss: 0.4712 - val_accuracy: 0.7725\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4468 - accuracy: 0.7856 - val_loss: 0.4711 - val_accuracy: 0.7725\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4466 - accuracy: 0.7856 - val_loss: 0.4710 - val_accuracy: 0.7675\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4464 - accuracy: 0.7844 - val_loss: 0.4708 - val_accuracy: 0.7725\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4462 - accuracy: 0.7856 - val_loss: 0.4706 - val_accuracy: 0.7750\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.7856 - val_loss: 0.4705 - val_accuracy: 0.7750\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4458 - accuracy: 0.7862 - val_loss: 0.4703 - val_accuracy: 0.7750\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4456 - accuracy: 0.7862 - val_loss: 0.4701 - val_accuracy: 0.7750\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.7869 - val_loss: 0.4700 - val_accuracy: 0.7750\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4452 - accuracy: 0.7869 - val_loss: 0.4698 - val_accuracy: 0.7775\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4450 - accuracy: 0.7862 - val_loss: 0.4696 - val_accuracy: 0.7775\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4448 - accuracy: 0.7862 - val_loss: 0.4695 - val_accuracy: 0.7775\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4446 - accuracy: 0.7856 - val_loss: 0.4692 - val_accuracy: 0.7775\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4444 - accuracy: 0.7856 - val_loss: 0.4690 - val_accuracy: 0.7775\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4443 - accuracy: 0.7862 - val_loss: 0.4688 - val_accuracy: 0.7775\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4441 - accuracy: 0.7869 - val_loss: 0.4685 - val_accuracy: 0.7775\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4439 - accuracy: 0.7856 - val_loss: 0.4684 - val_accuracy: 0.7775\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4437 - accuracy: 0.7875 - val_loss: 0.4682 - val_accuracy: 0.7775\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4435 - accuracy: 0.7862 - val_loss: 0.4681 - val_accuracy: 0.7775\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4433 - accuracy: 0.7869 - val_loss: 0.4678 - val_accuracy: 0.7775\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4431 - accuracy: 0.7875 - val_loss: 0.4676 - val_accuracy: 0.7775\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4430 - accuracy: 0.7869 - val_loss: 0.4675 - val_accuracy: 0.7800\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4428 - accuracy: 0.7856 - val_loss: 0.4674 - val_accuracy: 0.7800\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4426 - accuracy: 0.7869 - val_loss: 0.4673 - val_accuracy: 0.7800\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4425 - accuracy: 0.7875 - val_loss: 0.4672 - val_accuracy: 0.7800\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4423 - accuracy: 0.7875 - val_loss: 0.4671 - val_accuracy: 0.7800\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.7875 - val_loss: 0.4669 - val_accuracy: 0.7775\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.7887 - val_loss: 0.4667 - val_accuracy: 0.7775\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.7875 - val_loss: 0.4665 - val_accuracy: 0.7775\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.7850 - val_loss: 0.4663 - val_accuracy: 0.7775\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4414 - accuracy: 0.7850 - val_loss: 0.4661 - val_accuracy: 0.7775\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7850 - val_loss: 0.4659 - val_accuracy: 0.7775\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4411 - accuracy: 0.7850 - val_loss: 0.4657 - val_accuracy: 0.7775\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4409 - accuracy: 0.7850 - val_loss: 0.4655 - val_accuracy: 0.7775\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.7850 - val_loss: 0.4652 - val_accuracy: 0.7725\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.7850 - val_loss: 0.4651 - val_accuracy: 0.7725\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.7850 - val_loss: 0.4649 - val_accuracy: 0.7750\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 0.7850 - val_loss: 0.4647 - val_accuracy: 0.7750\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4401 - accuracy: 0.7850 - val_loss: 0.4646 - val_accuracy: 0.7750\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7850 - val_loss: 0.4644 - val_accuracy: 0.7750\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4398 - accuracy: 0.7850 - val_loss: 0.4642 - val_accuracy: 0.7750\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4396 - accuracy: 0.7850 - val_loss: 0.4641 - val_accuracy: 0.7750\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4395 - accuracy: 0.7850 - val_loss: 0.4640 - val_accuracy: 0.7750\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4393 - accuracy: 0.7850 - val_loss: 0.4639 - val_accuracy: 0.7750\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4392 - accuracy: 0.7850 - val_loss: 0.4638 - val_accuracy: 0.7750\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4390 - accuracy: 0.7850 - val_loss: 0.4637 - val_accuracy: 0.7750\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4389 - accuracy: 0.7850 - val_loss: 0.4636 - val_accuracy: 0.7750\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4387 - accuracy: 0.7850 - val_loss: 0.4634 - val_accuracy: 0.7725\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4385 - accuracy: 0.7837 - val_loss: 0.4632 - val_accuracy: 0.7725\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4384 - accuracy: 0.7837 - val_loss: 0.4630 - val_accuracy: 0.7775\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4382 - accuracy: 0.7837 - val_loss: 0.4629 - val_accuracy: 0.7775\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4381 - accuracy: 0.7837 - val_loss: 0.4627 - val_accuracy: 0.7775\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4380 - accuracy: 0.7837 - val_loss: 0.4625 - val_accuracy: 0.7775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4378 - accuracy: 0.7819 - val_loss: 0.4623 - val_accuracy: 0.7775\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.7819 - val_loss: 0.4621 - val_accuracy: 0.7775\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.7819 - val_loss: 0.4620 - val_accuracy: 0.7775\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.7819 - val_loss: 0.4619 - val_accuracy: 0.7775\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.7819 - val_loss: 0.4618 - val_accuracy: 0.7775\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4371 - accuracy: 0.7819 - val_loss: 0.4616 - val_accuracy: 0.7775\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.7837 - val_loss: 0.4615 - val_accuracy: 0.7775\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.7837 - val_loss: 0.4613 - val_accuracy: 0.7775\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.7837 - val_loss: 0.4612 - val_accuracy: 0.7775\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4365 - accuracy: 0.7837 - val_loss: 0.4610 - val_accuracy: 0.7775\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4364 - accuracy: 0.7837 - val_loss: 0.4608 - val_accuracy: 0.7775\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4362 - accuracy: 0.7837 - val_loss: 0.4606 - val_accuracy: 0.7775\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.7837 - val_loss: 0.4605 - val_accuracy: 0.7775\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.7837 - val_loss: 0.4605 - val_accuracy: 0.7775\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.7837 - val_loss: 0.4603 - val_accuracy: 0.7775\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.7837 - val_loss: 0.4602 - val_accuracy: 0.7775\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.7837 - val_loss: 0.4602 - val_accuracy: 0.7775\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.7837 - val_loss: 0.4600 - val_accuracy: 0.7775\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4353 - accuracy: 0.7837 - val_loss: 0.4599 - val_accuracy: 0.7775\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4351 - accuracy: 0.7837 - val_loss: 0.4598 - val_accuracy: 0.7775\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4350 - accuracy: 0.7837 - val_loss: 0.4597 - val_accuracy: 0.7775\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4349 - accuracy: 0.7837 - val_loss: 0.4596 - val_accuracy: 0.7775\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4347 - accuracy: 0.7837 - val_loss: 0.4595 - val_accuracy: 0.7775\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4346 - accuracy: 0.7837 - val_loss: 0.4593 - val_accuracy: 0.7775\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4345 - accuracy: 0.7837 - val_loss: 0.4592 - val_accuracy: 0.7775\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4343 - accuracy: 0.7837 - val_loss: 0.4591 - val_accuracy: 0.7775\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4342 - accuracy: 0.7837 - val_loss: 0.4588 - val_accuracy: 0.7775\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4340 - accuracy: 0.7837 - val_loss: 0.4587 - val_accuracy: 0.7775\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4340 - accuracy: 0.7837 - val_loss: 0.4586 - val_accuracy: 0.7775\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4338 - accuracy: 0.7837 - val_loss: 0.4585 - val_accuracy: 0.7775\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4337 - accuracy: 0.7844 - val_loss: 0.4584 - val_accuracy: 0.7775\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.7856 - val_loss: 0.4582 - val_accuracy: 0.7775\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.7837 - val_loss: 0.4581 - val_accuracy: 0.7775\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.7837 - val_loss: 0.4580 - val_accuracy: 0.7775\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.7850 - val_loss: 0.4579 - val_accuracy: 0.7775\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.7869 - val_loss: 0.4578 - val_accuracy: 0.7775\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.7856 - val_loss: 0.4576 - val_accuracy: 0.7775\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4328 - accuracy: 0.7856 - val_loss: 0.4575 - val_accuracy: 0.7775\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4327 - accuracy: 0.7856 - val_loss: 0.4574 - val_accuracy: 0.7825\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.7875 - val_loss: 0.4573 - val_accuracy: 0.7825\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4324 - accuracy: 0.7850 - val_loss: 0.4571 - val_accuracy: 0.7825\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4323 - accuracy: 0.7875 - val_loss: 0.4571 - val_accuracy: 0.7825\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4322 - accuracy: 0.7856 - val_loss: 0.4569 - val_accuracy: 0.7825\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4321 - accuracy: 0.7856 - val_loss: 0.4566 - val_accuracy: 0.7825\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.7850 - val_loss: 0.4565 - val_accuracy: 0.7825\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4318 - accuracy: 0.7856 - val_loss: 0.4564 - val_accuracy: 0.7825\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4317 - accuracy: 0.7856 - val_loss: 0.4562 - val_accuracy: 0.7825\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4316 - accuracy: 0.7856 - val_loss: 0.4561 - val_accuracy: 0.7825\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4315 - accuracy: 0.7856 - val_loss: 0.4560 - val_accuracy: 0.7825\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4313 - accuracy: 0.7856 - val_loss: 0.4559 - val_accuracy: 0.7825\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4312 - accuracy: 0.7856 - val_loss: 0.4558 - val_accuracy: 0.7825\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4311 - accuracy: 0.7856 - val_loss: 0.4556 - val_accuracy: 0.7825\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4310 - accuracy: 0.7856 - val_loss: 0.4555 - val_accuracy: 0.7825\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4309 - accuracy: 0.7856 - val_loss: 0.4554 - val_accuracy: 0.7825\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4307 - accuracy: 0.7856 - val_loss: 0.4552 - val_accuracy: 0.7825\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4306 - accuracy: 0.7856 - val_loss: 0.4552 - val_accuracy: 0.7825\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4305 - accuracy: 0.7856 - val_loss: 0.4551 - val_accuracy: 0.7825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4304 - accuracy: 0.7856 - val_loss: 0.4548 - val_accuracy: 0.7825\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4303 - accuracy: 0.7862 - val_loss: 0.4547 - val_accuracy: 0.7825\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.7856 - val_loss: 0.4545 - val_accuracy: 0.7825\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4300 - accuracy: 0.7869 - val_loss: 0.4544 - val_accuracy: 0.7825\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.7856 - val_loss: 0.4544 - val_accuracy: 0.7825\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.7862 - val_loss: 0.4542 - val_accuracy: 0.7825\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.7869 - val_loss: 0.4543 - val_accuracy: 0.7825\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.7856 - val_loss: 0.4542 - val_accuracy: 0.7825\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.7856 - val_loss: 0.4541 - val_accuracy: 0.7825\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.7856 - val_loss: 0.4539 - val_accuracy: 0.7825\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.7856 - val_loss: 0.4538 - val_accuracy: 0.7825\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4291 - accuracy: 0.7862 - val_loss: 0.4537 - val_accuracy: 0.7825\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.7856 - val_loss: 0.4535 - val_accuracy: 0.7825\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.7856 - val_loss: 0.4534 - val_accuracy: 0.7825\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.7862 - val_loss: 0.4533 - val_accuracy: 0.7825\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4286 - accuracy: 0.7856 - val_loss: 0.4532 - val_accuracy: 0.7825\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.7856 - val_loss: 0.4531 - val_accuracy: 0.7825\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.7862 - val_loss: 0.4530 - val_accuracy: 0.7825\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4283 - accuracy: 0.7856 - val_loss: 0.4529 - val_accuracy: 0.7825\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4281 - accuracy: 0.7862 - val_loss: 0.4528 - val_accuracy: 0.7825\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4280 - accuracy: 0.7856 - val_loss: 0.4527 - val_accuracy: 0.7825\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4279 - accuracy: 0.7856 - val_loss: 0.4526 - val_accuracy: 0.7825\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4278 - accuracy: 0.7869 - val_loss: 0.4525 - val_accuracy: 0.7825\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4277 - accuracy: 0.7856 - val_loss: 0.4524 - val_accuracy: 0.7825\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4276 - accuracy: 0.7856 - val_loss: 0.4523 - val_accuracy: 0.7825\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4275 - accuracy: 0.7869 - val_loss: 0.4522 - val_accuracy: 0.7825\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.7869 - val_loss: 0.4521 - val_accuracy: 0.7825\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4273 - accuracy: 0.7875 - val_loss: 0.4520 - val_accuracy: 0.7825\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4272 - accuracy: 0.7862 - val_loss: 0.4518 - val_accuracy: 0.7825\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4271 - accuracy: 0.7850 - val_loss: 0.4517 - val_accuracy: 0.7825\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.7850 - val_loss: 0.4516 - val_accuracy: 0.7825\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.7875 - val_loss: 0.4515 - val_accuracy: 0.7825\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.7869 - val_loss: 0.4513 - val_accuracy: 0.7825\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.7862 - val_loss: 0.4511 - val_accuracy: 0.7825\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.7869 - val_loss: 0.4510 - val_accuracy: 0.7825\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4264 - accuracy: 0.7856 - val_loss: 0.4510 - val_accuracy: 0.7825\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4263 - accuracy: 0.7869 - val_loss: 0.4509 - val_accuracy: 0.7825\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.7862 - val_loss: 0.4507 - val_accuracy: 0.7850\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4261 - accuracy: 0.7875 - val_loss: 0.4506 - val_accuracy: 0.7850\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4260 - accuracy: 0.7881 - val_loss: 0.4505 - val_accuracy: 0.7850\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4259 - accuracy: 0.7862 - val_loss: 0.4505 - val_accuracy: 0.7850\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4258 - accuracy: 0.7875 - val_loss: 0.4503 - val_accuracy: 0.7850\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4257 - accuracy: 0.7875 - val_loss: 0.4502 - val_accuracy: 0.7850\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4256 - accuracy: 0.7881 - val_loss: 0.4501 - val_accuracy: 0.7850\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4255 - accuracy: 0.7862 - val_loss: 0.4501 - val_accuracy: 0.7850\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4254 - accuracy: 0.7869 - val_loss: 0.4500 - val_accuracy: 0.7850\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4253 - accuracy: 0.7875 - val_loss: 0.4498 - val_accuracy: 0.7850\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.7869 - val_loss: 0.4496 - val_accuracy: 0.7850\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.7869 - val_loss: 0.4495 - val_accuracy: 0.7850\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4250 - accuracy: 0.7869 - val_loss: 0.4494 - val_accuracy: 0.7850\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4249 - accuracy: 0.7862 - val_loss: 0.4494 - val_accuracy: 0.7850\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4248 - accuracy: 0.7862 - val_loss: 0.4493 - val_accuracy: 0.7850\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4246 - accuracy: 0.7869 - val_loss: 0.4491 - val_accuracy: 0.7850\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4246 - accuracy: 0.7869 - val_loss: 0.4489 - val_accuracy: 0.7900\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4245 - accuracy: 0.7869 - val_loss: 0.4488 - val_accuracy: 0.7900\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4244 - accuracy: 0.7862 - val_loss: 0.4489 - val_accuracy: 0.7900\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.4242 - accuracy: 0.7875 - val_loss: 0.4488 - val_accuracy: 0.7900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4242 - accuracy: 0.7862 - val_loss: 0.4486 - val_accuracy: 0.7900\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4241 - accuracy: 0.7869 - val_loss: 0.4485 - val_accuracy: 0.7900\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4240 - accuracy: 0.7856 - val_loss: 0.4484 - val_accuracy: 0.7900\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4239 - accuracy: 0.7856 - val_loss: 0.4484 - val_accuracy: 0.7900\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4238 - accuracy: 0.7862 - val_loss: 0.4483 - val_accuracy: 0.7900\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.7875 - val_loss: 0.4482 - val_accuracy: 0.7900\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4236 - accuracy: 0.7869 - val_loss: 0.4482 - val_accuracy: 0.7900\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.7869 - val_loss: 0.4480 - val_accuracy: 0.7900\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4234 - accuracy: 0.7869 - val_loss: 0.4480 - val_accuracy: 0.7900\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.7869 - val_loss: 0.4479 - val_accuracy: 0.7900\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.7869 - val_loss: 0.4478 - val_accuracy: 0.7900\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4231 - accuracy: 0.7869 - val_loss: 0.4478 - val_accuracy: 0.7900\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4230 - accuracy: 0.7862 - val_loss: 0.4478 - val_accuracy: 0.7900\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.7850 - val_loss: 0.4477 - val_accuracy: 0.7900\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.7850 - val_loss: 0.4476 - val_accuracy: 0.7900\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4227 - accuracy: 0.7850 - val_loss: 0.4475 - val_accuracy: 0.7900\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4226 - accuracy: 0.7850 - val_loss: 0.4474 - val_accuracy: 0.7900\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4226 - accuracy: 0.7856 - val_loss: 0.4472 - val_accuracy: 0.7900\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4225 - accuracy: 0.7850 - val_loss: 0.4471 - val_accuracy: 0.7900\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4224 - accuracy: 0.7850 - val_loss: 0.4471 - val_accuracy: 0.7900\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4223 - accuracy: 0.7850 - val_loss: 0.4470 - val_accuracy: 0.7900\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.7850 - val_loss: 0.4469 - val_accuracy: 0.7900\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4221 - accuracy: 0.7850 - val_loss: 0.4468 - val_accuracy: 0.7900\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4220 - accuracy: 0.7856 - val_loss: 0.4467 - val_accuracy: 0.7900\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4219 - accuracy: 0.7869 - val_loss: 0.4466 - val_accuracy: 0.7900\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4218 - accuracy: 0.7850 - val_loss: 0.4465 - val_accuracy: 0.7900\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4218 - accuracy: 0.7850 - val_loss: 0.4465 - val_accuracy: 0.7900\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4216 - accuracy: 0.7850 - val_loss: 0.4464 - val_accuracy: 0.7900\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4216 - accuracy: 0.7850 - val_loss: 0.4462 - val_accuracy: 0.7900\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4215 - accuracy: 0.7850 - val_loss: 0.4462 - val_accuracy: 0.7900\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.7850 - val_loss: 0.4461 - val_accuracy: 0.7900\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4213 - accuracy: 0.7850 - val_loss: 0.4460 - val_accuracy: 0.7900\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4212 - accuracy: 0.7850 - val_loss: 0.4459 - val_accuracy: 0.7900\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4211 - accuracy: 0.7850 - val_loss: 0.4457 - val_accuracy: 0.7900\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.7862 - val_loss: 0.4456 - val_accuracy: 0.7900\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4209 - accuracy: 0.7856 - val_loss: 0.4454 - val_accuracy: 0.7900\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4208 - accuracy: 0.7850 - val_loss: 0.4453 - val_accuracy: 0.7900\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4208 - accuracy: 0.7856 - val_loss: 0.4453 - val_accuracy: 0.7900\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4207 - accuracy: 0.7856 - val_loss: 0.4451 - val_accuracy: 0.7900\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4205 - accuracy: 0.7850 - val_loss: 0.4450 - val_accuracy: 0.7900\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4205 - accuracy: 0.7862 - val_loss: 0.4449 - val_accuracy: 0.7900\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.7856 - val_loss: 0.4449 - val_accuracy: 0.7900\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.7869 - val_loss: 0.4448 - val_accuracy: 0.7900\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.7869 - val_loss: 0.4447 - val_accuracy: 0.7900\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.7881 - val_loss: 0.4447 - val_accuracy: 0.7850\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.7875 - val_loss: 0.4445 - val_accuracy: 0.7850\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.7862 - val_loss: 0.4445 - val_accuracy: 0.7850\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.7869 - val_loss: 0.4444 - val_accuracy: 0.7850\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.7881 - val_loss: 0.4442 - val_accuracy: 0.7850\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.7875 - val_loss: 0.4440 - val_accuracy: 0.7850\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.7887 - val_loss: 0.4441 - val_accuracy: 0.7850\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.7869 - val_loss: 0.4440 - val_accuracy: 0.7850\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4194 - accuracy: 0.7875 - val_loss: 0.4439 - val_accuracy: 0.7850\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4193 - accuracy: 0.7856 - val_loss: 0.4437 - val_accuracy: 0.7850\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.7887 - val_loss: 0.4437 - val_accuracy: 0.7850\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4191 - accuracy: 0.7887 - val_loss: 0.4437 - val_accuracy: 0.7850\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4190 - accuracy: 0.7875 - val_loss: 0.4436 - val_accuracy: 0.7850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.7875 - val_loss: 0.4435 - val_accuracy: 0.7850\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4188 - accuracy: 0.7887 - val_loss: 0.4434 - val_accuracy: 0.7850\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.7887 - val_loss: 0.4434 - val_accuracy: 0.7850\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.7869 - val_loss: 0.4433 - val_accuracy: 0.7850\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.7900 - val_loss: 0.4432 - val_accuracy: 0.7850\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.7887 - val_loss: 0.4431 - val_accuracy: 0.7850\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.7869 - val_loss: 0.4431 - val_accuracy: 0.7850\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.7862 - val_loss: 0.4430 - val_accuracy: 0.7850\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.7875 - val_loss: 0.4429 - val_accuracy: 0.7900\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.7881 - val_loss: 0.4428 - val_accuracy: 0.7900\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.7900 - val_loss: 0.4427 - val_accuracy: 0.7875\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.7900 - val_loss: 0.4426 - val_accuracy: 0.7875\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.7875 - val_loss: 0.4425 - val_accuracy: 0.7875\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.7894 - val_loss: 0.4424 - val_accuracy: 0.7875\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.7906 - val_loss: 0.4424 - val_accuracy: 0.7875\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.7887 - val_loss: 0.4423 - val_accuracy: 0.7875\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.7881 - val_loss: 0.4421 - val_accuracy: 0.7875\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.7906 - val_loss: 0.4420 - val_accuracy: 0.7875\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.7906 - val_loss: 0.4420 - val_accuracy: 0.7850\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.7881 - val_loss: 0.4419 - val_accuracy: 0.7850\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.7894 - val_loss: 0.4419 - val_accuracy: 0.7850\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.7894 - val_loss: 0.4418 - val_accuracy: 0.7850\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.7894 - val_loss: 0.4417 - val_accuracy: 0.7850\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4170 - accuracy: 0.7900 - val_loss: 0.4417 - val_accuracy: 0.7850\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.7912 - val_loss: 0.4415 - val_accuracy: 0.7875\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4168 - accuracy: 0.7912 - val_loss: 0.4415 - val_accuracy: 0.7875\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.7919 - val_loss: 0.4413 - val_accuracy: 0.7875\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.7919 - val_loss: 0.4412 - val_accuracy: 0.7875\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4166 - accuracy: 0.7919 - val_loss: 0.4411 - val_accuracy: 0.7875\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4164 - accuracy: 0.7906 - val_loss: 0.4410 - val_accuracy: 0.7875\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.4164 - accuracy: 0.7912 - val_loss: 0.4410 - val_accuracy: 0.7875\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.7919 - val_loss: 0.4409 - val_accuracy: 0.7875\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4162 - accuracy: 0.7912 - val_loss: 0.4406 - val_accuracy: 0.7850\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4161 - accuracy: 0.7900 - val_loss: 0.4405 - val_accuracy: 0.7850\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4161 - accuracy: 0.7900 - val_loss: 0.4404 - val_accuracy: 0.7850\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.7900 - val_loss: 0.4403 - val_accuracy: 0.7850\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.7906 - val_loss: 0.4402 - val_accuracy: 0.7850\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.7900 - val_loss: 0.4402 - val_accuracy: 0.7850\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.7900 - val_loss: 0.4400 - val_accuracy: 0.7850\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.7900 - val_loss: 0.4400 - val_accuracy: 0.7850\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.7894 - val_loss: 0.4399 - val_accuracy: 0.7850\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.7900 - val_loss: 0.4398 - val_accuracy: 0.7850\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4154 - accuracy: 0.7900 - val_loss: 0.4398 - val_accuracy: 0.7850\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.7900 - val_loss: 0.4397 - val_accuracy: 0.7850\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.7906 - val_loss: 0.4396 - val_accuracy: 0.7850\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.7906 - val_loss: 0.4396 - val_accuracy: 0.7850\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.7900 - val_loss: 0.4395 - val_accuracy: 0.7875\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4150 - accuracy: 0.7900 - val_loss: 0.4394 - val_accuracy: 0.7875\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4149 - accuracy: 0.7894 - val_loss: 0.4394 - val_accuracy: 0.7850\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4148 - accuracy: 0.7900 - val_loss: 0.4392 - val_accuracy: 0.7875\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4148 - accuracy: 0.7912 - val_loss: 0.4392 - val_accuracy: 0.7850\n",
      "Epoch 394/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4147 - accuracy: 0.7912 - val_loss: 0.4392 - val_accuracy: 0.7850\n",
      "Epoch 395/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4146 - accuracy: 0.7900 - val_loss: 0.4391 - val_accuracy: 0.7850\n",
      "Epoch 396/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4145 - accuracy: 0.7906 - val_loss: 0.4391 - val_accuracy: 0.7850\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4145 - accuracy: 0.7894 - val_loss: 0.4389 - val_accuracy: 0.7850\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4144 - accuracy: 0.7894 - val_loss: 0.4388 - val_accuracy: 0.7850\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4143 - accuracy: 0.7900 - val_loss: 0.4387 - val_accuracy: 0.7850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4142 - accuracy: 0.7900 - val_loss: 0.4386 - val_accuracy: 0.7850\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4141 - accuracy: 0.7900 - val_loss: 0.4385 - val_accuracy: 0.7850\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4140 - accuracy: 0.7900 - val_loss: 0.4384 - val_accuracy: 0.7850\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.7906 - val_loss: 0.4385 - val_accuracy: 0.7850\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4139 - accuracy: 0.7900 - val_loss: 0.4383 - val_accuracy: 0.7850\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.7900 - val_loss: 0.4383 - val_accuracy: 0.7850\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.7900 - val_loss: 0.4382 - val_accuracy: 0.7850\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.7900 - val_loss: 0.4381 - val_accuracy: 0.7850\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4135 - accuracy: 0.7900 - val_loss: 0.4381 - val_accuracy: 0.7850\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.7900 - val_loss: 0.4380 - val_accuracy: 0.7850\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.7900 - val_loss: 0.4378 - val_accuracy: 0.7850\n",
      "Epoch 411/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.7900 - val_loss: 0.4378 - val_accuracy: 0.7850\n",
      "Epoch 412/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.7900 - val_loss: 0.4376 - val_accuracy: 0.7850\n",
      "Epoch 413/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.7900 - val_loss: 0.4375 - val_accuracy: 0.7850\n",
      "Epoch 414/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.7900 - val_loss: 0.4374 - val_accuracy: 0.7850\n",
      "Epoch 415/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.7900 - val_loss: 0.4373 - val_accuracy: 0.7850\n",
      "Epoch 416/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.7900 - val_loss: 0.4374 - val_accuracy: 0.7850\n",
      "Epoch 417/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.7900 - val_loss: 0.4373 - val_accuracy: 0.7850\n",
      "Epoch 418/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.7900 - val_loss: 0.4373 - val_accuracy: 0.7850\n",
      "Epoch 419/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.7900 - val_loss: 0.4373 - val_accuracy: 0.7850\n",
      "Epoch 420/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4126 - accuracy: 0.7900 - val_loss: 0.4372 - val_accuracy: 0.7850\n",
      "Epoch 421/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4125 - accuracy: 0.7900 - val_loss: 0.4372 - val_accuracy: 0.7850\n",
      "Epoch 422/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4124 - accuracy: 0.7900 - val_loss: 0.4372 - val_accuracy: 0.7850\n",
      "Epoch 423/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4124 - accuracy: 0.7900 - val_loss: 0.4371 - val_accuracy: 0.7850\n",
      "Epoch 424/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4123 - accuracy: 0.7900 - val_loss: 0.4371 - val_accuracy: 0.7850\n",
      "Epoch 425/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4123 - accuracy: 0.7900 - val_loss: 0.4370 - val_accuracy: 0.7850\n",
      "Epoch 426/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.7900 - val_loss: 0.4369 - val_accuracy: 0.7850\n",
      "Epoch 427/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.7900 - val_loss: 0.4368 - val_accuracy: 0.7850\n",
      "Epoch 428/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4121 - accuracy: 0.7900 - val_loss: 0.4367 - val_accuracy: 0.7850\n",
      "Epoch 429/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.7912 - val_loss: 0.4367 - val_accuracy: 0.7850\n",
      "Epoch 430/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4118 - accuracy: 0.7900 - val_loss: 0.4366 - val_accuracy: 0.7850\n",
      "Epoch 431/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4118 - accuracy: 0.7912 - val_loss: 0.4366 - val_accuracy: 0.7850\n",
      "Epoch 432/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.7900 - val_loss: 0.4366 - val_accuracy: 0.7850\n",
      "Epoch 433/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.7900 - val_loss: 0.4365 - val_accuracy: 0.7850\n",
      "Epoch 434/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.7900 - val_loss: 0.4365 - val_accuracy: 0.7850\n",
      "Epoch 435/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.7900 - val_loss: 0.4365 - val_accuracy: 0.7850\n",
      "Epoch 436/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.7900 - val_loss: 0.4364 - val_accuracy: 0.7850\n",
      "Epoch 437/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.7887 - val_loss: 0.4363 - val_accuracy: 0.7850\n",
      "Epoch 438/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.7912 - val_loss: 0.4364 - val_accuracy: 0.7850\n",
      "Epoch 439/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.7912 - val_loss: 0.4363 - val_accuracy: 0.7875\n",
      "Epoch 440/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.7900 - val_loss: 0.4361 - val_accuracy: 0.7875\n",
      "Epoch 441/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.7900 - val_loss: 0.4361 - val_accuracy: 0.7875\n",
      "Epoch 442/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.7925 - val_loss: 0.4360 - val_accuracy: 0.7875\n",
      "Epoch 443/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.7900 - val_loss: 0.4360 - val_accuracy: 0.7875\n",
      "Epoch 444/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.7900 - val_loss: 0.4359 - val_accuracy: 0.7875\n",
      "Epoch 445/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.7912 - val_loss: 0.4358 - val_accuracy: 0.7875\n",
      "Epoch 446/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.7912 - val_loss: 0.4356 - val_accuracy: 0.7875\n",
      "Epoch 447/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.7919 - val_loss: 0.4356 - val_accuracy: 0.7875\n",
      "Epoch 448/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.4105 - accuracy: 0.7931 - val_loss: 0.4354 - val_accuracy: 0.7875\n",
      "Epoch 449/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.7925 - val_loss: 0.4354 - val_accuracy: 0.7875\n",
      "Epoch 450/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4104 - accuracy: 0.7925 - val_loss: 0.4353 - val_accuracy: 0.7875\n",
      "Epoch 451/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.7931 - val_loss: 0.4351 - val_accuracy: 0.7875\n",
      "Epoch 452/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.7931 - val_loss: 0.4350 - val_accuracy: 0.7875\n",
      "Epoch 453/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4102 - accuracy: 0.7931 - val_loss: 0.4350 - val_accuracy: 0.7875\n",
      "Epoch 454/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4101 - accuracy: 0.7931 - val_loss: 0.4349 - val_accuracy: 0.7875\n",
      "Epoch 455/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4100 - accuracy: 0.7931 - val_loss: 0.4348 - val_accuracy: 0.7875\n",
      "Epoch 456/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4099 - accuracy: 0.7931 - val_loss: 0.4347 - val_accuracy: 0.7875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4099 - accuracy: 0.7925 - val_loss: 0.4347 - val_accuracy: 0.7875\n",
      "Epoch 458/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4098 - accuracy: 0.7925 - val_loss: 0.4347 - val_accuracy: 0.7875\n",
      "Epoch 459/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4097 - accuracy: 0.7944 - val_loss: 0.4345 - val_accuracy: 0.7875\n",
      "Epoch 460/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4097 - accuracy: 0.7937 - val_loss: 0.4345 - val_accuracy: 0.7875\n",
      "Epoch 461/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4097 - accuracy: 0.7931 - val_loss: 0.4344 - val_accuracy: 0.7850\n",
      "Epoch 462/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4095 - accuracy: 0.7937 - val_loss: 0.4344 - val_accuracy: 0.7850\n",
      "Epoch 463/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4095 - accuracy: 0.7925 - val_loss: 0.4345 - val_accuracy: 0.7850\n",
      "Epoch 464/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4094 - accuracy: 0.7937 - val_loss: 0.4344 - val_accuracy: 0.7850\n",
      "Epoch 465/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4093 - accuracy: 0.7931 - val_loss: 0.4344 - val_accuracy: 0.7850\n",
      "Epoch 466/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4093 - accuracy: 0.7925 - val_loss: 0.4342 - val_accuracy: 0.7875\n",
      "Epoch 467/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4092 - accuracy: 0.7931 - val_loss: 0.4341 - val_accuracy: 0.7875\n",
      "Epoch 468/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4091 - accuracy: 0.7937 - val_loss: 0.4341 - val_accuracy: 0.7875\n",
      "Epoch 469/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4091 - accuracy: 0.7937 - val_loss: 0.4340 - val_accuracy: 0.7875\n",
      "Epoch 470/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4090 - accuracy: 0.7950 - val_loss: 0.4339 - val_accuracy: 0.7875\n",
      "Epoch 471/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4089 - accuracy: 0.7950 - val_loss: 0.4339 - val_accuracy: 0.7875\n",
      "Epoch 472/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4088 - accuracy: 0.7944 - val_loss: 0.4339 - val_accuracy: 0.7875\n",
      "Epoch 473/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4088 - accuracy: 0.7944 - val_loss: 0.4337 - val_accuracy: 0.7875\n",
      "Epoch 474/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4087 - accuracy: 0.7981 - val_loss: 0.4337 - val_accuracy: 0.7875\n",
      "Epoch 475/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4086 - accuracy: 0.7956 - val_loss: 0.4335 - val_accuracy: 0.7875\n",
      "Epoch 476/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4086 - accuracy: 0.7981 - val_loss: 0.4335 - val_accuracy: 0.7875\n",
      "Epoch 477/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4085 - accuracy: 0.7962 - val_loss: 0.4334 - val_accuracy: 0.7875\n",
      "Epoch 478/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4085 - accuracy: 0.7969 - val_loss: 0.4333 - val_accuracy: 0.7875\n",
      "Epoch 479/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4084 - accuracy: 0.7969 - val_loss: 0.4332 - val_accuracy: 0.7875\n",
      "Epoch 480/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4083 - accuracy: 0.7969 - val_loss: 0.4331 - val_accuracy: 0.7875\n",
      "Epoch 481/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4083 - accuracy: 0.7956 - val_loss: 0.4331 - val_accuracy: 0.7925\n",
      "Epoch 482/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4082 - accuracy: 0.7975 - val_loss: 0.4330 - val_accuracy: 0.7925\n",
      "Epoch 483/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4081 - accuracy: 0.7981 - val_loss: 0.4329 - val_accuracy: 0.7875\n",
      "Epoch 484/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4080 - accuracy: 0.7975 - val_loss: 0.4329 - val_accuracy: 0.7925\n",
      "Epoch 485/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4080 - accuracy: 0.7969 - val_loss: 0.4328 - val_accuracy: 0.7875\n",
      "Epoch 486/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4080 - accuracy: 0.7975 - val_loss: 0.4329 - val_accuracy: 0.7900\n",
      "Epoch 487/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.7975 - val_loss: 0.4327 - val_accuracy: 0.7950\n",
      "Epoch 488/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4078 - accuracy: 0.7962 - val_loss: 0.4327 - val_accuracy: 0.7900\n",
      "Epoch 489/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4077 - accuracy: 0.7969 - val_loss: 0.4327 - val_accuracy: 0.7950\n",
      "Epoch 490/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4077 - accuracy: 0.7975 - val_loss: 0.4326 - val_accuracy: 0.7900\n",
      "Epoch 491/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4076 - accuracy: 0.7962 - val_loss: 0.4327 - val_accuracy: 0.7900\n",
      "Epoch 492/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.7987 - val_loss: 0.4327 - val_accuracy: 0.7900\n",
      "Epoch 493/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4075 - accuracy: 0.7987 - val_loss: 0.4324 - val_accuracy: 0.7950\n",
      "Epoch 494/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4074 - accuracy: 0.7987 - val_loss: 0.4323 - val_accuracy: 0.7950\n",
      "Epoch 495/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4074 - accuracy: 0.7994 - val_loss: 0.4324 - val_accuracy: 0.7900\n",
      "Epoch 496/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4073 - accuracy: 0.7987 - val_loss: 0.4323 - val_accuracy: 0.7950\n",
      "Epoch 497/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4073 - accuracy: 0.7987 - val_loss: 0.4322 - val_accuracy: 0.7950\n",
      "Epoch 498/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.7994 - val_loss: 0.4320 - val_accuracy: 0.7950\n",
      "Epoch 499/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4071 - accuracy: 0.7994 - val_loss: 0.4320 - val_accuracy: 0.7950\n",
      "Epoch 500/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.7975 - val_loss: 0.4318 - val_accuracy: 0.7950\n",
      "Epoch 501/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4070 - accuracy: 0.7975 - val_loss: 0.4318 - val_accuracy: 0.7950\n",
      "Epoch 502/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4069 - accuracy: 0.7981 - val_loss: 0.4318 - val_accuracy: 0.7950\n",
      "Epoch 503/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4069 - accuracy: 0.7975 - val_loss: 0.4318 - val_accuracy: 0.7950\n",
      "Epoch 504/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4068 - accuracy: 0.7969 - val_loss: 0.4318 - val_accuracy: 0.7950\n",
      "Epoch 505/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4068 - accuracy: 0.7969 - val_loss: 0.4318 - val_accuracy: 0.7950\n",
      "Epoch 506/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4066 - accuracy: 0.7981 - val_loss: 0.4317 - val_accuracy: 0.7950\n",
      "Epoch 507/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4066 - accuracy: 0.7969 - val_loss: 0.4317 - val_accuracy: 0.7950\n",
      "Epoch 508/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4065 - accuracy: 0.7975 - val_loss: 0.4316 - val_accuracy: 0.7950\n",
      "Epoch 509/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4065 - accuracy: 0.7975 - val_loss: 0.4316 - val_accuracy: 0.7950\n",
      "Epoch 510/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4064 - accuracy: 0.7981 - val_loss: 0.4316 - val_accuracy: 0.7950\n",
      "Epoch 511/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4063 - accuracy: 0.7969 - val_loss: 0.4316 - val_accuracy: 0.7950\n",
      "Epoch 512/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4063 - accuracy: 0.7975 - val_loss: 0.4314 - val_accuracy: 0.7950\n",
      "Epoch 513/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4062 - accuracy: 0.7975 - val_loss: 0.4314 - val_accuracy: 0.7950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4061 - accuracy: 0.7981 - val_loss: 0.4313 - val_accuracy: 0.7950\n",
      "Epoch 515/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.7981 - val_loss: 0.4312 - val_accuracy: 0.7950\n",
      "Epoch 516/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4060 - accuracy: 0.7981 - val_loss: 0.4311 - val_accuracy: 0.7975\n",
      "Epoch 517/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4060 - accuracy: 0.7981 - val_loss: 0.4311 - val_accuracy: 0.7975\n",
      "Epoch 518/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4059 - accuracy: 0.7994 - val_loss: 0.4310 - val_accuracy: 0.7975\n",
      "Epoch 519/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4058 - accuracy: 0.7994 - val_loss: 0.4310 - val_accuracy: 0.7975\n",
      "Epoch 520/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4058 - accuracy: 0.7994 - val_loss: 0.4308 - val_accuracy: 0.7975\n",
      "Epoch 521/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.7987 - val_loss: 0.4308 - val_accuracy: 0.7975\n",
      "Epoch 522/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4056 - accuracy: 0.7994 - val_loss: 0.4306 - val_accuracy: 0.7975\n",
      "Epoch 523/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4056 - accuracy: 0.7994 - val_loss: 0.4306 - val_accuracy: 0.7975\n",
      "Epoch 524/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4055 - accuracy: 0.7987 - val_loss: 0.4306 - val_accuracy: 0.7975\n",
      "Epoch 525/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.7994 - val_loss: 0.4306 - val_accuracy: 0.7975\n",
      "Epoch 526/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.7987 - val_loss: 0.4306 - val_accuracy: 0.7975\n",
      "Epoch 527/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.7994 - val_loss: 0.4306 - val_accuracy: 0.7975\n",
      "Epoch 528/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.7994 - val_loss: 0.4306 - val_accuracy: 0.7975\n",
      "Epoch 529/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4052 - accuracy: 0.7994 - val_loss: 0.4306 - val_accuracy: 0.7975\n",
      "Epoch 530/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.7994 - val_loss: 0.4305 - val_accuracy: 0.7975\n",
      "Epoch 531/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4050 - accuracy: 0.7994 - val_loss: 0.4303 - val_accuracy: 0.7975\n",
      "Epoch 532/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4050 - accuracy: 0.7987 - val_loss: 0.4302 - val_accuracy: 0.7975\n",
      "Epoch 533/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4050 - accuracy: 0.7994 - val_loss: 0.4302 - val_accuracy: 0.7975\n",
      "Epoch 534/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4049 - accuracy: 0.7994 - val_loss: 0.4302 - val_accuracy: 0.7975\n",
      "Epoch 535/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4048 - accuracy: 0.7994 - val_loss: 0.4300 - val_accuracy: 0.7975\n",
      "Epoch 536/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4048 - accuracy: 0.7994 - val_loss: 0.4300 - val_accuracy: 0.7975\n",
      "Epoch 537/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4047 - accuracy: 0.7994 - val_loss: 0.4298 - val_accuracy: 0.7975\n",
      "Epoch 538/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4046 - accuracy: 0.8000 - val_loss: 0.4297 - val_accuracy: 0.7975\n",
      "Epoch 539/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4046 - accuracy: 0.7994 - val_loss: 0.4298 - val_accuracy: 0.7975\n",
      "Epoch 540/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4045 - accuracy: 0.7994 - val_loss: 0.4296 - val_accuracy: 0.7975\n",
      "Epoch 541/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4045 - accuracy: 0.8006 - val_loss: 0.4296 - val_accuracy: 0.7975\n",
      "Epoch 542/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4044 - accuracy: 0.8000 - val_loss: 0.4297 - val_accuracy: 0.7975\n",
      "Epoch 543/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4043 - accuracy: 0.8012 - val_loss: 0.4296 - val_accuracy: 0.7975\n",
      "Epoch 544/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4042 - accuracy: 0.8012 - val_loss: 0.4294 - val_accuracy: 0.7975\n",
      "Epoch 545/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4042 - accuracy: 0.8012 - val_loss: 0.4294 - val_accuracy: 0.7975\n",
      "Epoch 546/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4041 - accuracy: 0.8012 - val_loss: 0.4293 - val_accuracy: 0.7975\n",
      "Epoch 547/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4040 - accuracy: 0.8019 - val_loss: 0.4293 - val_accuracy: 0.7975\n",
      "Epoch 548/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4040 - accuracy: 0.8019 - val_loss: 0.4292 - val_accuracy: 0.8000\n",
      "Epoch 549/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4039 - accuracy: 0.8019 - val_loss: 0.4292 - val_accuracy: 0.8000\n",
      "Epoch 550/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4039 - accuracy: 0.8025 - val_loss: 0.4291 - val_accuracy: 0.8000\n",
      "Epoch 551/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4038 - accuracy: 0.8012 - val_loss: 0.4291 - val_accuracy: 0.8000\n",
      "Epoch 552/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4038 - accuracy: 0.8025 - val_loss: 0.4290 - val_accuracy: 0.7975\n",
      "Epoch 553/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4037 - accuracy: 0.8012 - val_loss: 0.4288 - val_accuracy: 0.7975\n",
      "Epoch 554/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8012 - val_loss: 0.4288 - val_accuracy: 0.7975\n",
      "Epoch 555/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8012 - val_loss: 0.4286 - val_accuracy: 0.7975\n",
      "Epoch 556/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4035 - accuracy: 0.8012 - val_loss: 0.4286 - val_accuracy: 0.8000\n",
      "Epoch 557/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4035 - accuracy: 0.8019 - val_loss: 0.4286 - val_accuracy: 0.8000\n",
      "Epoch 558/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4034 - accuracy: 0.8012 - val_loss: 0.4285 - val_accuracy: 0.8000\n",
      "Epoch 559/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4033 - accuracy: 0.8012 - val_loss: 0.4285 - val_accuracy: 0.7975\n",
      "Epoch 560/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4033 - accuracy: 0.8012 - val_loss: 0.4285 - val_accuracy: 0.7975\n",
      "Epoch 561/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4032 - accuracy: 0.8019 - val_loss: 0.4284 - val_accuracy: 0.7975\n",
      "Epoch 562/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4032 - accuracy: 0.8019 - val_loss: 0.4284 - val_accuracy: 0.7975\n",
      "Epoch 563/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4031 - accuracy: 0.8019 - val_loss: 0.4283 - val_accuracy: 0.8025\n",
      "Epoch 564/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4030 - accuracy: 0.8025 - val_loss: 0.4281 - val_accuracy: 0.8025\n",
      "Epoch 565/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4030 - accuracy: 0.8019 - val_loss: 0.4281 - val_accuracy: 0.8025\n",
      "Epoch 566/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4029 - accuracy: 0.8019 - val_loss: 0.4280 - val_accuracy: 0.8050\n",
      "Epoch 567/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4028 - accuracy: 0.8019 - val_loss: 0.4279 - val_accuracy: 0.8050\n",
      "Epoch 568/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4028 - accuracy: 0.8025 - val_loss: 0.4278 - val_accuracy: 0.8050\n",
      "Epoch 569/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4027 - accuracy: 0.8031 - val_loss: 0.4279 - val_accuracy: 0.8050\n",
      "Epoch 570/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4027 - accuracy: 0.8025 - val_loss: 0.4279 - val_accuracy: 0.8025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4026 - accuracy: 0.8019 - val_loss: 0.4279 - val_accuracy: 0.8025\n",
      "Epoch 572/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.8019 - val_loss: 0.4277 - val_accuracy: 0.8025\n",
      "Epoch 573/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4025 - accuracy: 0.8019 - val_loss: 0.4277 - val_accuracy: 0.8025\n",
      "Epoch 574/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4024 - accuracy: 0.8019 - val_loss: 0.4275 - val_accuracy: 0.8050\n",
      "Epoch 575/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4023 - accuracy: 0.8031 - val_loss: 0.4275 - val_accuracy: 0.8050\n",
      "Epoch 576/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4023 - accuracy: 0.8044 - val_loss: 0.4276 - val_accuracy: 0.8025\n",
      "Epoch 577/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4023 - accuracy: 0.8025 - val_loss: 0.4275 - val_accuracy: 0.8025\n",
      "Epoch 578/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4022 - accuracy: 0.8019 - val_loss: 0.4274 - val_accuracy: 0.8025\n",
      "Epoch 579/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8019 - val_loss: 0.4273 - val_accuracy: 0.8050\n",
      "Epoch 580/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8025 - val_loss: 0.4272 - val_accuracy: 0.8025\n",
      "Epoch 581/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.8019 - val_loss: 0.4273 - val_accuracy: 0.8025\n",
      "Epoch 582/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4019 - accuracy: 0.8025 - val_loss: 0.4273 - val_accuracy: 0.8025\n",
      "Epoch 583/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4019 - accuracy: 0.8019 - val_loss: 0.4272 - val_accuracy: 0.8025\n",
      "Epoch 584/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4018 - accuracy: 0.8019 - val_loss: 0.4272 - val_accuracy: 0.8025\n",
      "Epoch 585/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4018 - accuracy: 0.8019 - val_loss: 0.4271 - val_accuracy: 0.8025\n",
      "Epoch 586/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4018 - accuracy: 0.8019 - val_loss: 0.4268 - val_accuracy: 0.8025\n",
      "Epoch 587/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4017 - accuracy: 0.8019 - val_loss: 0.4267 - val_accuracy: 0.8050\n",
      "Epoch 588/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.8031 - val_loss: 0.4266 - val_accuracy: 0.8075\n",
      "Epoch 589/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4015 - accuracy: 0.8037 - val_loss: 0.4266 - val_accuracy: 0.8075\n",
      "Epoch 590/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4015 - accuracy: 0.8019 - val_loss: 0.4264 - val_accuracy: 0.8075\n",
      "Epoch 591/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4015 - accuracy: 0.8037 - val_loss: 0.4263 - val_accuracy: 0.8050\n",
      "Epoch 592/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4014 - accuracy: 0.8037 - val_loss: 0.4262 - val_accuracy: 0.8050\n",
      "Epoch 593/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4013 - accuracy: 0.8037 - val_loss: 0.4261 - val_accuracy: 0.8050\n",
      "Epoch 594/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4013 - accuracy: 0.8044 - val_loss: 0.4261 - val_accuracy: 0.8075\n",
      "Epoch 595/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4012 - accuracy: 0.8037 - val_loss: 0.4260 - val_accuracy: 0.8075\n",
      "Epoch 596/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4011 - accuracy: 0.8037 - val_loss: 0.4260 - val_accuracy: 0.8050\n",
      "Epoch 597/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4011 - accuracy: 0.8031 - val_loss: 0.4259 - val_accuracy: 0.8050\n",
      "Epoch 598/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4011 - accuracy: 0.8037 - val_loss: 0.4259 - val_accuracy: 0.8050\n",
      "Epoch 599/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4010 - accuracy: 0.8037 - val_loss: 0.4259 - val_accuracy: 0.8025\n",
      "Epoch 600/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4009 - accuracy: 0.8025 - val_loss: 0.4259 - val_accuracy: 0.8050\n",
      "Epoch 601/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4009 - accuracy: 0.8044 - val_loss: 0.4260 - val_accuracy: 0.8050\n",
      "Epoch 602/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4008 - accuracy: 0.8025 - val_loss: 0.4259 - val_accuracy: 0.8050\n",
      "Epoch 603/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4008 - accuracy: 0.8031 - val_loss: 0.4259 - val_accuracy: 0.8050\n",
      "Epoch 604/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8031 - val_loss: 0.4258 - val_accuracy: 0.8050\n",
      "Epoch 605/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8031 - val_loss: 0.4257 - val_accuracy: 0.8050\n",
      "Epoch 606/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4006 - accuracy: 0.8037 - val_loss: 0.4256 - val_accuracy: 0.8075\n",
      "Epoch 607/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4006 - accuracy: 0.8025 - val_loss: 0.4256 - val_accuracy: 0.8050\n",
      "Epoch 608/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4005 - accuracy: 0.8037 - val_loss: 0.4255 - val_accuracy: 0.8050\n",
      "Epoch 609/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4005 - accuracy: 0.8037 - val_loss: 0.4256 - val_accuracy: 0.8050\n",
      "Epoch 610/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4004 - accuracy: 0.8037 - val_loss: 0.4255 - val_accuracy: 0.8025\n",
      "Epoch 611/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.8037 - val_loss: 0.4255 - val_accuracy: 0.8025\n",
      "Epoch 612/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.8025 - val_loss: 0.4254 - val_accuracy: 0.8050\n",
      "Epoch 613/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4002 - accuracy: 0.8031 - val_loss: 0.4254 - val_accuracy: 0.8050\n",
      "Epoch 614/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4002 - accuracy: 0.8037 - val_loss: 0.4253 - val_accuracy: 0.8075\n",
      "Epoch 615/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.8050 - val_loss: 0.4252 - val_accuracy: 0.8075\n",
      "Epoch 616/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.8056 - val_loss: 0.4253 - val_accuracy: 0.8075\n",
      "Epoch 617/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.8050 - val_loss: 0.4252 - val_accuracy: 0.8075\n",
      "Epoch 618/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3999 - accuracy: 0.8081 - val_loss: 0.4252 - val_accuracy: 0.8075\n",
      "Epoch 619/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3999 - accuracy: 0.8050 - val_loss: 0.4252 - val_accuracy: 0.8075\n",
      "Epoch 620/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3998 - accuracy: 0.8056 - val_loss: 0.4251 - val_accuracy: 0.8075\n",
      "Epoch 621/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3997 - accuracy: 0.8069 - val_loss: 0.4252 - val_accuracy: 0.8075\n",
      "Epoch 622/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3997 - accuracy: 0.8075 - val_loss: 0.4251 - val_accuracy: 0.8075\n",
      "Epoch 623/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3997 - accuracy: 0.8075 - val_loss: 0.4250 - val_accuracy: 0.8075\n",
      "Epoch 624/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3996 - accuracy: 0.8069 - val_loss: 0.4249 - val_accuracy: 0.8075\n",
      "Epoch 625/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3996 - accuracy: 0.8081 - val_loss: 0.4249 - val_accuracy: 0.8075\n",
      "Epoch 626/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3995 - accuracy: 0.8075 - val_loss: 0.4248 - val_accuracy: 0.8075\n",
      "Epoch 627/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3995 - accuracy: 0.8081 - val_loss: 0.4247 - val_accuracy: 0.8075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3994 - accuracy: 0.8075 - val_loss: 0.4246 - val_accuracy: 0.8075\n",
      "Epoch 629/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3994 - accuracy: 0.8075 - val_loss: 0.4247 - val_accuracy: 0.8075\n",
      "Epoch 630/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.8081 - val_loss: 0.4247 - val_accuracy: 0.8075\n",
      "Epoch 631/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.8081 - val_loss: 0.4248 - val_accuracy: 0.8075\n",
      "Epoch 632/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3992 - accuracy: 0.8087 - val_loss: 0.4247 - val_accuracy: 0.8075\n",
      "Epoch 633/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8075 - val_loss: 0.4246 - val_accuracy: 0.8075\n",
      "Epoch 634/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8075 - val_loss: 0.4245 - val_accuracy: 0.8075\n",
      "Epoch 635/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8081 - val_loss: 0.4244 - val_accuracy: 0.8075\n",
      "Epoch 636/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8081 - val_loss: 0.4244 - val_accuracy: 0.8075\n",
      "Epoch 637/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8081 - val_loss: 0.4243 - val_accuracy: 0.8075\n",
      "Epoch 638/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8081 - val_loss: 0.4243 - val_accuracy: 0.8075\n",
      "Epoch 639/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8081 - val_loss: 0.4243 - val_accuracy: 0.8075\n",
      "Epoch 640/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8081 - val_loss: 0.4243 - val_accuracy: 0.8075\n",
      "Epoch 641/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8081 - val_loss: 0.4242 - val_accuracy: 0.8075\n",
      "Epoch 642/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8081 - val_loss: 0.4241 - val_accuracy: 0.8075\n",
      "Epoch 643/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8081 - val_loss: 0.4242 - val_accuracy: 0.8075\n",
      "Epoch 644/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8081 - val_loss: 0.4241 - val_accuracy: 0.8075\n",
      "Epoch 645/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8081 - val_loss: 0.4241 - val_accuracy: 0.8075\n",
      "Epoch 646/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3985 - accuracy: 0.8081 - val_loss: 0.4241 - val_accuracy: 0.8075\n",
      "Epoch 647/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3984 - accuracy: 0.8081 - val_loss: 0.4241 - val_accuracy: 0.8075\n",
      "Epoch 648/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3984 - accuracy: 0.8081 - val_loss: 0.4239 - val_accuracy: 0.8075\n",
      "Epoch 649/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3983 - accuracy: 0.8081 - val_loss: 0.4239 - val_accuracy: 0.8075\n",
      "Epoch 650/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3983 - accuracy: 0.8081 - val_loss: 0.4239 - val_accuracy: 0.8075\n",
      "Epoch 651/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3982 - accuracy: 0.8081 - val_loss: 0.4239 - val_accuracy: 0.8075\n",
      "Epoch 652/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3982 - accuracy: 0.8081 - val_loss: 0.4238 - val_accuracy: 0.8075\n",
      "Epoch 653/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3981 - accuracy: 0.8081 - val_loss: 0.4236 - val_accuracy: 0.8075\n",
      "Epoch 654/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3980 - accuracy: 0.8081 - val_loss: 0.4236 - val_accuracy: 0.8075\n",
      "Epoch 655/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3980 - accuracy: 0.8081 - val_loss: 0.4235 - val_accuracy: 0.8075\n",
      "Epoch 656/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3980 - accuracy: 0.8081 - val_loss: 0.4234 - val_accuracy: 0.8075\n",
      "Epoch 657/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3979 - accuracy: 0.8087 - val_loss: 0.4233 - val_accuracy: 0.8075\n",
      "Epoch 658/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3978 - accuracy: 0.8081 - val_loss: 0.4234 - val_accuracy: 0.8100\n",
      "Epoch 659/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3978 - accuracy: 0.8094 - val_loss: 0.4234 - val_accuracy: 0.8100\n",
      "Epoch 660/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8094 - val_loss: 0.4233 - val_accuracy: 0.8100\n",
      "Epoch 661/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8087 - val_loss: 0.4234 - val_accuracy: 0.8100\n",
      "Epoch 662/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8087 - val_loss: 0.4235 - val_accuracy: 0.8100\n",
      "Epoch 663/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8106 - val_loss: 0.4234 - val_accuracy: 0.8100\n",
      "Epoch 664/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8087 - val_loss: 0.4234 - val_accuracy: 0.8100\n",
      "Epoch 665/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8100 - val_loss: 0.4233 - val_accuracy: 0.8100\n",
      "Epoch 666/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8087 - val_loss: 0.4233 - val_accuracy: 0.8100\n",
      "Epoch 667/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8100 - val_loss: 0.4233 - val_accuracy: 0.8075\n",
      "Epoch 668/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3973 - accuracy: 0.8100 - val_loss: 0.4231 - val_accuracy: 0.8100\n",
      "Epoch 669/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3973 - accuracy: 0.8087 - val_loss: 0.4231 - val_accuracy: 0.8125\n",
      "Epoch 670/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8100 - val_loss: 0.4231 - val_accuracy: 0.8100\n",
      "Epoch 671/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8094 - val_loss: 0.4231 - val_accuracy: 0.8125\n",
      "Epoch 672/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8100 - val_loss: 0.4231 - val_accuracy: 0.8125\n",
      "Epoch 673/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8112 - val_loss: 0.4230 - val_accuracy: 0.8125\n",
      "Epoch 674/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3970 - accuracy: 0.8106 - val_loss: 0.4230 - val_accuracy: 0.8125\n",
      "Epoch 675/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3970 - accuracy: 0.8106 - val_loss: 0.4229 - val_accuracy: 0.8125\n",
      "Epoch 676/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3969 - accuracy: 0.8112 - val_loss: 0.4229 - val_accuracy: 0.8125\n",
      "Epoch 677/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3968 - accuracy: 0.8100 - val_loss: 0.4228 - val_accuracy: 0.8125\n",
      "Epoch 678/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3968 - accuracy: 0.8094 - val_loss: 0.4228 - val_accuracy: 0.8125\n",
      "Epoch 679/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3968 - accuracy: 0.8100 - val_loss: 0.4227 - val_accuracy: 0.8125\n",
      "Epoch 680/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3967 - accuracy: 0.8100 - val_loss: 0.4227 - val_accuracy: 0.8125\n",
      "Epoch 681/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3966 - accuracy: 0.8100 - val_loss: 0.4226 - val_accuracy: 0.8125\n",
      "Epoch 682/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3966 - accuracy: 0.8100 - val_loss: 0.4226 - val_accuracy: 0.8125\n",
      "Epoch 683/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3965 - accuracy: 0.8100 - val_loss: 0.4226 - val_accuracy: 0.8125\n",
      "Epoch 684/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.3965 - accuracy: 0.8112 - val_loss: 0.4225 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3965 - accuracy: 0.8100 - val_loss: 0.4225 - val_accuracy: 0.8125\n",
      "Epoch 686/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3964 - accuracy: 0.8100 - val_loss: 0.4225 - val_accuracy: 0.8125\n",
      "Epoch 687/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8119 - val_loss: 0.4225 - val_accuracy: 0.8125\n",
      "Epoch 688/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8119 - val_loss: 0.4225 - val_accuracy: 0.8125\n",
      "Epoch 689/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8106 - val_loss: 0.4225 - val_accuracy: 0.8125\n",
      "Epoch 690/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8112 - val_loss: 0.4226 - val_accuracy: 0.8125\n",
      "Epoch 691/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8119 - val_loss: 0.4224 - val_accuracy: 0.8125\n",
      "Epoch 692/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8119 - val_loss: 0.4222 - val_accuracy: 0.8125\n",
      "Epoch 693/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8100 - val_loss: 0.4221 - val_accuracy: 0.8125\n",
      "Epoch 694/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8119 - val_loss: 0.4222 - val_accuracy: 0.8125\n",
      "Epoch 695/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8119 - val_loss: 0.4221 - val_accuracy: 0.8125\n",
      "Epoch 696/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3959 - accuracy: 0.8112 - val_loss: 0.4220 - val_accuracy: 0.8125\n",
      "Epoch 697/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8119 - val_loss: 0.4219 - val_accuracy: 0.8125\n",
      "Epoch 698/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8119 - val_loss: 0.4219 - val_accuracy: 0.8125\n",
      "Epoch 699/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8119 - val_loss: 0.4219 - val_accuracy: 0.8125\n",
      "Epoch 700/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8119 - val_loss: 0.4219 - val_accuracy: 0.8125\n",
      "Epoch 701/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8125 - val_loss: 0.4217 - val_accuracy: 0.8125\n",
      "Epoch 702/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8125 - val_loss: 0.4217 - val_accuracy: 0.8125\n",
      "Epoch 703/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8119 - val_loss: 0.4217 - val_accuracy: 0.8125\n",
      "Epoch 704/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3956 - accuracy: 0.8125 - val_loss: 0.4216 - val_accuracy: 0.8125\n",
      "Epoch 705/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3955 - accuracy: 0.8131 - val_loss: 0.4214 - val_accuracy: 0.8125\n",
      "Epoch 706/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3954 - accuracy: 0.8131 - val_loss: 0.4215 - val_accuracy: 0.8125\n",
      "Epoch 707/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3954 - accuracy: 0.8131 - val_loss: 0.4214 - val_accuracy: 0.8125\n",
      "Epoch 708/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3953 - accuracy: 0.8131 - val_loss: 0.4215 - val_accuracy: 0.8125\n",
      "Epoch 709/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3953 - accuracy: 0.8125 - val_loss: 0.4214 - val_accuracy: 0.8125\n",
      "Epoch 710/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3953 - accuracy: 0.8131 - val_loss: 0.4213 - val_accuracy: 0.8125\n",
      "Epoch 711/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3952 - accuracy: 0.8131 - val_loss: 0.4213 - val_accuracy: 0.8125\n",
      "Epoch 712/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3951 - accuracy: 0.8131 - val_loss: 0.4212 - val_accuracy: 0.8125\n",
      "Epoch 713/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3951 - accuracy: 0.8131 - val_loss: 0.4211 - val_accuracy: 0.8125\n",
      "Epoch 714/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3950 - accuracy: 0.8125 - val_loss: 0.4211 - val_accuracy: 0.8125\n",
      "Epoch 715/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3950 - accuracy: 0.8131 - val_loss: 0.4211 - val_accuracy: 0.8125\n",
      "Epoch 716/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3949 - accuracy: 0.8119 - val_loss: 0.4212 - val_accuracy: 0.8125\n",
      "Epoch 717/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3949 - accuracy: 0.8131 - val_loss: 0.4212 - val_accuracy: 0.8125\n",
      "Epoch 718/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3948 - accuracy: 0.8131 - val_loss: 0.4211 - val_accuracy: 0.8125\n",
      "Epoch 719/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3948 - accuracy: 0.8125 - val_loss: 0.4210 - val_accuracy: 0.8125\n",
      "Epoch 720/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3948 - accuracy: 0.8125 - val_loss: 0.4210 - val_accuracy: 0.8125\n",
      "Epoch 721/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8131 - val_loss: 0.4209 - val_accuracy: 0.8125\n",
      "Epoch 722/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8131 - val_loss: 0.4209 - val_accuracy: 0.8125\n",
      "Epoch 723/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8144 - val_loss: 0.4207 - val_accuracy: 0.8125\n",
      "Epoch 724/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3945 - accuracy: 0.8131 - val_loss: 0.4206 - val_accuracy: 0.8125\n",
      "Epoch 725/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3945 - accuracy: 0.8125 - val_loss: 0.4206 - val_accuracy: 0.8125\n",
      "Epoch 726/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8125 - val_loss: 0.4206 - val_accuracy: 0.8125\n",
      "Epoch 727/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8131 - val_loss: 0.4205 - val_accuracy: 0.8125\n",
      "Epoch 728/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8119 - val_loss: 0.4205 - val_accuracy: 0.8125\n",
      "Epoch 729/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8131 - val_loss: 0.4204 - val_accuracy: 0.8125\n",
      "Epoch 730/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8112 - val_loss: 0.4204 - val_accuracy: 0.8125\n",
      "Epoch 731/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8112 - val_loss: 0.4203 - val_accuracy: 0.8125\n",
      "Epoch 732/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3941 - accuracy: 0.8112 - val_loss: 0.4203 - val_accuracy: 0.8125\n",
      "Epoch 733/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3941 - accuracy: 0.8112 - val_loss: 0.4201 - val_accuracy: 0.8125\n",
      "Epoch 734/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3940 - accuracy: 0.8112 - val_loss: 0.4202 - val_accuracy: 0.8125\n",
      "Epoch 735/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3940 - accuracy: 0.8125 - val_loss: 0.4201 - val_accuracy: 0.8125\n",
      "Epoch 736/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3939 - accuracy: 0.8119 - val_loss: 0.4201 - val_accuracy: 0.8125\n",
      "Epoch 737/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3939 - accuracy: 0.8119 - val_loss: 0.4201 - val_accuracy: 0.8125\n",
      "Epoch 738/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3938 - accuracy: 0.8112 - val_loss: 0.4202 - val_accuracy: 0.8125\n",
      "Epoch 739/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3938 - accuracy: 0.8156 - val_loss: 0.4200 - val_accuracy: 0.8125\n",
      "Epoch 740/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3937 - accuracy: 0.8138 - val_loss: 0.4200 - val_accuracy: 0.8125\n",
      "Epoch 741/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3937 - accuracy: 0.8125 - val_loss: 0.4200 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3936 - accuracy: 0.8138 - val_loss: 0.4199 - val_accuracy: 0.8125\n",
      "Epoch 743/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3936 - accuracy: 0.8125 - val_loss: 0.4199 - val_accuracy: 0.8125\n",
      "Epoch 744/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3935 - accuracy: 0.8144 - val_loss: 0.4197 - val_accuracy: 0.8125\n",
      "Epoch 745/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8144 - val_loss: 0.4197 - val_accuracy: 0.8125\n",
      "Epoch 746/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8144 - val_loss: 0.4196 - val_accuracy: 0.8125\n",
      "Epoch 747/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8125 - val_loss: 0.4196 - val_accuracy: 0.8125\n",
      "Epoch 748/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8144 - val_loss: 0.4195 - val_accuracy: 0.8125\n",
      "Epoch 749/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8150 - val_loss: 0.4194 - val_accuracy: 0.8125\n",
      "Epoch 750/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8144 - val_loss: 0.4194 - val_accuracy: 0.8125\n",
      "Epoch 751/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8119 - val_loss: 0.4194 - val_accuracy: 0.8125\n",
      "Epoch 752/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8138 - val_loss: 0.4193 - val_accuracy: 0.8125\n",
      "Epoch 753/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8144 - val_loss: 0.4193 - val_accuracy: 0.8125\n",
      "Epoch 754/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8144 - val_loss: 0.4193 - val_accuracy: 0.8125\n",
      "Epoch 755/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8144 - val_loss: 0.4192 - val_accuracy: 0.8125\n",
      "Epoch 756/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3929 - accuracy: 0.8144 - val_loss: 0.4192 - val_accuracy: 0.8125\n",
      "Epoch 757/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3929 - accuracy: 0.8150 - val_loss: 0.4191 - val_accuracy: 0.8125\n",
      "Epoch 758/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.8144 - val_loss: 0.4190 - val_accuracy: 0.8125\n",
      "Epoch 759/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.8144 - val_loss: 0.4191 - val_accuracy: 0.8125\n",
      "Epoch 760/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.8150 - val_loss: 0.4189 - val_accuracy: 0.8125\n",
      "Epoch 761/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3927 - accuracy: 0.8138 - val_loss: 0.4190 - val_accuracy: 0.8125\n",
      "Epoch 762/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3926 - accuracy: 0.8138 - val_loss: 0.4188 - val_accuracy: 0.8125\n",
      "Epoch 763/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3925 - accuracy: 0.8131 - val_loss: 0.4188 - val_accuracy: 0.8125\n",
      "Epoch 764/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3925 - accuracy: 0.8138 - val_loss: 0.4189 - val_accuracy: 0.8125\n",
      "Epoch 765/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3925 - accuracy: 0.8144 - val_loss: 0.4189 - val_accuracy: 0.8125\n",
      "Epoch 766/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3924 - accuracy: 0.8131 - val_loss: 0.4188 - val_accuracy: 0.8125\n",
      "Epoch 767/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3924 - accuracy: 0.8144 - val_loss: 0.4187 - val_accuracy: 0.8125\n",
      "Epoch 768/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3923 - accuracy: 0.8131 - val_loss: 0.4187 - val_accuracy: 0.8125\n",
      "Epoch 769/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3923 - accuracy: 0.8138 - val_loss: 0.4186 - val_accuracy: 0.8125\n",
      "Epoch 770/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3922 - accuracy: 0.8131 - val_loss: 0.4184 - val_accuracy: 0.8125\n",
      "Epoch 771/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.3922 - accuracy: 0.8131 - val_loss: 0.4184 - val_accuracy: 0.8125\n",
      "Epoch 772/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3921 - accuracy: 0.8131 - val_loss: 0.4184 - val_accuracy: 0.8125\n",
      "Epoch 773/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3921 - accuracy: 0.8131 - val_loss: 0.4183 - val_accuracy: 0.8125\n",
      "Epoch 774/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3920 - accuracy: 0.8131 - val_loss: 0.4183 - val_accuracy: 0.8125\n",
      "Epoch 775/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3920 - accuracy: 0.8131 - val_loss: 0.4184 - val_accuracy: 0.8125\n",
      "Epoch 776/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3919 - accuracy: 0.8125 - val_loss: 0.4182 - val_accuracy: 0.8125\n",
      "Epoch 777/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3919 - accuracy: 0.8131 - val_loss: 0.4182 - val_accuracy: 0.8125\n",
      "Epoch 778/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3918 - accuracy: 0.8131 - val_loss: 0.4181 - val_accuracy: 0.8125\n",
      "Epoch 779/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3918 - accuracy: 0.8131 - val_loss: 0.4180 - val_accuracy: 0.8125\n",
      "Epoch 780/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8131 - val_loss: 0.4180 - val_accuracy: 0.8125\n",
      "Epoch 781/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8131 - val_loss: 0.4179 - val_accuracy: 0.8125\n",
      "Epoch 782/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8131 - val_loss: 0.4179 - val_accuracy: 0.8125\n",
      "Epoch 783/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8119 - val_loss: 0.4179 - val_accuracy: 0.8125\n",
      "Epoch 784/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3915 - accuracy: 0.8119 - val_loss: 0.4178 - val_accuracy: 0.8125\n",
      "Epoch 785/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3915 - accuracy: 0.8131 - val_loss: 0.4178 - val_accuracy: 0.8125\n",
      "Epoch 786/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3915 - accuracy: 0.8119 - val_loss: 0.4178 - val_accuracy: 0.8125\n",
      "Epoch 787/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3914 - accuracy: 0.8131 - val_loss: 0.4178 - val_accuracy: 0.8125\n",
      "Epoch 788/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3914 - accuracy: 0.8131 - val_loss: 0.4178 - val_accuracy: 0.8125\n",
      "Epoch 789/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3913 - accuracy: 0.8131 - val_loss: 0.4177 - val_accuracy: 0.8125\n",
      "Epoch 790/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3913 - accuracy: 0.8131 - val_loss: 0.4177 - val_accuracy: 0.8125\n",
      "Epoch 791/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3912 - accuracy: 0.8131 - val_loss: 0.4175 - val_accuracy: 0.8125\n",
      "Epoch 792/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3911 - accuracy: 0.8125 - val_loss: 0.4175 - val_accuracy: 0.8125\n",
      "Epoch 793/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3911 - accuracy: 0.8125 - val_loss: 0.4175 - val_accuracy: 0.8125\n",
      "Epoch 794/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3911 - accuracy: 0.8125 - val_loss: 0.4174 - val_accuracy: 0.8125\n",
      "Epoch 795/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8131 - val_loss: 0.4173 - val_accuracy: 0.8125\n",
      "Epoch 796/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8119 - val_loss: 0.4173 - val_accuracy: 0.8125\n",
      "Epoch 797/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3909 - accuracy: 0.8119 - val_loss: 0.4172 - val_accuracy: 0.8125\n",
      "Epoch 798/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3909 - accuracy: 0.8125 - val_loss: 0.4172 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3908 - accuracy: 0.8119 - val_loss: 0.4171 - val_accuracy: 0.8125\n",
      "Epoch 800/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3908 - accuracy: 0.8112 - val_loss: 0.4172 - val_accuracy: 0.8125\n",
      "Epoch 801/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3907 - accuracy: 0.8119 - val_loss: 0.4171 - val_accuracy: 0.8125\n",
      "Epoch 802/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.8119 - val_loss: 0.4170 - val_accuracy: 0.8125\n",
      "Epoch 803/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3906 - accuracy: 0.8119 - val_loss: 0.4171 - val_accuracy: 0.8125\n",
      "Epoch 804/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3906 - accuracy: 0.8119 - val_loss: 0.4170 - val_accuracy: 0.8125\n",
      "Epoch 805/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3905 - accuracy: 0.8119 - val_loss: 0.4170 - val_accuracy: 0.8125\n",
      "Epoch 806/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3905 - accuracy: 0.8119 - val_loss: 0.4169 - val_accuracy: 0.8125\n",
      "Epoch 807/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3904 - accuracy: 0.8125 - val_loss: 0.4168 - val_accuracy: 0.8125\n",
      "Epoch 808/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3904 - accuracy: 0.8131 - val_loss: 0.4168 - val_accuracy: 0.8125\n",
      "Epoch 809/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3903 - accuracy: 0.8138 - val_loss: 0.4167 - val_accuracy: 0.8125\n",
      "Epoch 810/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3903 - accuracy: 0.8131 - val_loss: 0.4168 - val_accuracy: 0.8125\n",
      "Epoch 811/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3903 - accuracy: 0.8131 - val_loss: 0.4168 - val_accuracy: 0.8125\n",
      "Epoch 812/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3902 - accuracy: 0.8131 - val_loss: 0.4168 - val_accuracy: 0.8125\n",
      "Epoch 813/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3901 - accuracy: 0.8144 - val_loss: 0.4166 - val_accuracy: 0.8125\n",
      "Epoch 814/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3901 - accuracy: 0.8131 - val_loss: 0.4165 - val_accuracy: 0.8125\n",
      "Epoch 815/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3901 - accuracy: 0.8131 - val_loss: 0.4165 - val_accuracy: 0.8125\n",
      "Epoch 816/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3900 - accuracy: 0.8131 - val_loss: 0.4165 - val_accuracy: 0.8125\n",
      "Epoch 817/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3899 - accuracy: 0.8138 - val_loss: 0.4163 - val_accuracy: 0.8125\n",
      "Epoch 818/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3900 - accuracy: 0.8138 - val_loss: 0.4164 - val_accuracy: 0.8125\n",
      "Epoch 819/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3899 - accuracy: 0.8144 - val_loss: 0.4164 - val_accuracy: 0.8125\n",
      "Epoch 820/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3899 - accuracy: 0.8125 - val_loss: 0.4163 - val_accuracy: 0.8125\n",
      "Epoch 821/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3898 - accuracy: 0.8131 - val_loss: 0.4163 - val_accuracy: 0.8125\n",
      "Epoch 822/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3897 - accuracy: 0.8138 - val_loss: 0.4162 - val_accuracy: 0.8125\n",
      "Epoch 823/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3897 - accuracy: 0.8131 - val_loss: 0.4160 - val_accuracy: 0.8125\n",
      "Epoch 824/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3897 - accuracy: 0.8131 - val_loss: 0.4160 - val_accuracy: 0.8125\n",
      "Epoch 825/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3896 - accuracy: 0.8131 - val_loss: 0.4159 - val_accuracy: 0.8125\n",
      "Epoch 826/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3895 - accuracy: 0.8131 - val_loss: 0.4159 - val_accuracy: 0.8125\n",
      "Epoch 827/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3895 - accuracy: 0.8131 - val_loss: 0.4158 - val_accuracy: 0.8125\n",
      "Epoch 828/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3895 - accuracy: 0.8131 - val_loss: 0.4157 - val_accuracy: 0.8125\n",
      "Epoch 829/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3894 - accuracy: 0.8131 - val_loss: 0.4156 - val_accuracy: 0.8125\n",
      "Epoch 830/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3894 - accuracy: 0.8131 - val_loss: 0.4157 - val_accuracy: 0.8125\n",
      "Epoch 831/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3894 - accuracy: 0.8131 - val_loss: 0.4156 - val_accuracy: 0.8125\n",
      "Epoch 832/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3893 - accuracy: 0.8112 - val_loss: 0.4156 - val_accuracy: 0.8125\n",
      "Epoch 833/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3892 - accuracy: 0.8125 - val_loss: 0.4155 - val_accuracy: 0.8125\n",
      "Epoch 834/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3892 - accuracy: 0.8131 - val_loss: 0.4155 - val_accuracy: 0.8125\n",
      "Epoch 835/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3892 - accuracy: 0.8131 - val_loss: 0.4156 - val_accuracy: 0.8125\n",
      "Epoch 836/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3891 - accuracy: 0.8131 - val_loss: 0.4156 - val_accuracy: 0.8125\n",
      "Epoch 837/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3891 - accuracy: 0.8131 - val_loss: 0.4156 - val_accuracy: 0.8125\n",
      "Epoch 838/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3890 - accuracy: 0.8131 - val_loss: 0.4155 - val_accuracy: 0.8125\n",
      "Epoch 839/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3890 - accuracy: 0.8131 - val_loss: 0.4155 - val_accuracy: 0.8125\n",
      "Epoch 840/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3889 - accuracy: 0.8131 - val_loss: 0.4154 - val_accuracy: 0.8125\n",
      "Epoch 841/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3889 - accuracy: 0.8131 - val_loss: 0.4154 - val_accuracy: 0.8125\n",
      "Epoch 842/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3889 - accuracy: 0.8131 - val_loss: 0.4153 - val_accuracy: 0.8125\n",
      "Epoch 843/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3888 - accuracy: 0.8119 - val_loss: 0.4153 - val_accuracy: 0.8125\n",
      "Epoch 844/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3887 - accuracy: 0.8131 - val_loss: 0.4153 - val_accuracy: 0.8125\n",
      "Epoch 845/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3887 - accuracy: 0.8131 - val_loss: 0.4151 - val_accuracy: 0.8125\n",
      "Epoch 846/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3886 - accuracy: 0.8131 - val_loss: 0.4151 - val_accuracy: 0.8125\n",
      "Epoch 847/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3886 - accuracy: 0.8131 - val_loss: 0.4151 - val_accuracy: 0.8125\n",
      "Epoch 848/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.3886 - accuracy: 0.8131 - val_loss: 0.4151 - val_accuracy: 0.8125\n",
      "Epoch 849/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3885 - accuracy: 0.8131 - val_loss: 0.4151 - val_accuracy: 0.8125\n",
      "Epoch 850/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3885 - accuracy: 0.8131 - val_loss: 0.4149 - val_accuracy: 0.8125\n",
      "Epoch 851/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3884 - accuracy: 0.8131 - val_loss: 0.4149 - val_accuracy: 0.8125\n",
      "Epoch 852/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3884 - accuracy: 0.8131 - val_loss: 0.4148 - val_accuracy: 0.8125\n",
      "Epoch 853/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3884 - accuracy: 0.8131 - val_loss: 0.4147 - val_accuracy: 0.8125\n",
      "Epoch 854/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3883 - accuracy: 0.8131 - val_loss: 0.4147 - val_accuracy: 0.8125\n",
      "Epoch 855/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3883 - accuracy: 0.8131 - val_loss: 0.4147 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3882 - accuracy: 0.8131 - val_loss: 0.4146 - val_accuracy: 0.8125\n",
      "Epoch 857/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3882 - accuracy: 0.8131 - val_loss: 0.4147 - val_accuracy: 0.8125\n",
      "Epoch 858/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3882 - accuracy: 0.8131 - val_loss: 0.4148 - val_accuracy: 0.8125\n",
      "Epoch 859/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3881 - accuracy: 0.8131 - val_loss: 0.4146 - val_accuracy: 0.8125\n",
      "Epoch 860/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.8131 - val_loss: 0.4144 - val_accuracy: 0.8125\n",
      "Epoch 861/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.8131 - val_loss: 0.4145 - val_accuracy: 0.8125\n",
      "Epoch 862/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3879 - accuracy: 0.8131 - val_loss: 0.4146 - val_accuracy: 0.8125\n",
      "Epoch 863/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3879 - accuracy: 0.8131 - val_loss: 0.4145 - val_accuracy: 0.8125\n",
      "Epoch 864/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8131 - val_loss: 0.4144 - val_accuracy: 0.8125\n",
      "Epoch 865/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8131 - val_loss: 0.4144 - val_accuracy: 0.8125\n",
      "Epoch 866/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8131 - val_loss: 0.4142 - val_accuracy: 0.8125\n",
      "Epoch 867/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3877 - accuracy: 0.8125 - val_loss: 0.4143 - val_accuracy: 0.8125\n",
      "Epoch 868/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3876 - accuracy: 0.8131 - val_loss: 0.4143 - val_accuracy: 0.8125\n",
      "Epoch 869/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3876 - accuracy: 0.8131 - val_loss: 0.4142 - val_accuracy: 0.8125\n",
      "Epoch 870/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3876 - accuracy: 0.8131 - val_loss: 0.4142 - val_accuracy: 0.8125\n",
      "Epoch 871/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3875 - accuracy: 0.8131 - val_loss: 0.4142 - val_accuracy: 0.8100\n",
      "Epoch 872/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3875 - accuracy: 0.8131 - val_loss: 0.4141 - val_accuracy: 0.8125\n",
      "Epoch 873/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3874 - accuracy: 0.8125 - val_loss: 0.4140 - val_accuracy: 0.8100\n",
      "Epoch 874/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3874 - accuracy: 0.8125 - val_loss: 0.4140 - val_accuracy: 0.8100\n",
      "Epoch 875/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3873 - accuracy: 0.8125 - val_loss: 0.4140 - val_accuracy: 0.8100\n",
      "Epoch 876/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3873 - accuracy: 0.8125 - val_loss: 0.4140 - val_accuracy: 0.8100\n",
      "Epoch 877/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3872 - accuracy: 0.8131 - val_loss: 0.4139 - val_accuracy: 0.8100\n",
      "Epoch 878/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3872 - accuracy: 0.8125 - val_loss: 0.4138 - val_accuracy: 0.8100\n",
      "Epoch 879/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3872 - accuracy: 0.8131 - val_loss: 0.4138 - val_accuracy: 0.8100\n",
      "Epoch 880/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3871 - accuracy: 0.8125 - val_loss: 0.4137 - val_accuracy: 0.8100\n",
      "Epoch 881/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3871 - accuracy: 0.8125 - val_loss: 0.4137 - val_accuracy: 0.8100\n",
      "Epoch 882/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3870 - accuracy: 0.8125 - val_loss: 0.4136 - val_accuracy: 0.8100\n",
      "Epoch 883/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3870 - accuracy: 0.8125 - val_loss: 0.4134 - val_accuracy: 0.8100\n",
      "Epoch 884/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3869 - accuracy: 0.8125 - val_loss: 0.4134 - val_accuracy: 0.8100\n",
      "Epoch 885/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3869 - accuracy: 0.8125 - val_loss: 0.4133 - val_accuracy: 0.8100\n",
      "Epoch 886/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3868 - accuracy: 0.8131 - val_loss: 0.4132 - val_accuracy: 0.8100\n",
      "Epoch 887/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3868 - accuracy: 0.8131 - val_loss: 0.4132 - val_accuracy: 0.8100\n",
      "Epoch 888/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3867 - accuracy: 0.8125 - val_loss: 0.4133 - val_accuracy: 0.8100\n",
      "Epoch 889/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3867 - accuracy: 0.8131 - val_loss: 0.4132 - val_accuracy: 0.8100\n",
      "Epoch 890/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3866 - accuracy: 0.8125 - val_loss: 0.4133 - val_accuracy: 0.8100\n",
      "Epoch 891/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3866 - accuracy: 0.8125 - val_loss: 0.4133 - val_accuracy: 0.8100\n",
      "Epoch 892/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3866 - accuracy: 0.8125 - val_loss: 0.4133 - val_accuracy: 0.8100\n",
      "Epoch 893/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3865 - accuracy: 0.8125 - val_loss: 0.4132 - val_accuracy: 0.8100\n",
      "Epoch 894/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3865 - accuracy: 0.8125 - val_loss: 0.4131 - val_accuracy: 0.8100\n",
      "Epoch 895/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3865 - accuracy: 0.8125 - val_loss: 0.4131 - val_accuracy: 0.8100\n",
      "Epoch 896/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3864 - accuracy: 0.8131 - val_loss: 0.4131 - val_accuracy: 0.8100\n",
      "Epoch 897/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.8125 - val_loss: 0.4132 - val_accuracy: 0.8100\n",
      "Epoch 898/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.8125 - val_loss: 0.4132 - val_accuracy: 0.8100\n",
      "Epoch 899/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3862 - accuracy: 0.8156 - val_loss: 0.4132 - val_accuracy: 0.8100\n",
      "Epoch 900/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3861 - accuracy: 0.8138 - val_loss: 0.4131 - val_accuracy: 0.8100\n",
      "Epoch 901/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3862 - accuracy: 0.8144 - val_loss: 0.4130 - val_accuracy: 0.8100\n",
      "Epoch 902/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3861 - accuracy: 0.8131 - val_loss: 0.4129 - val_accuracy: 0.8100\n",
      "Epoch 903/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3860 - accuracy: 0.8131 - val_loss: 0.4128 - val_accuracy: 0.8100\n",
      "Epoch 904/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3860 - accuracy: 0.8131 - val_loss: 0.4128 - val_accuracy: 0.8100\n",
      "Epoch 905/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3860 - accuracy: 0.8138 - val_loss: 0.4128 - val_accuracy: 0.8100\n",
      "Epoch 906/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3859 - accuracy: 0.8150 - val_loss: 0.4127 - val_accuracy: 0.8100\n",
      "Epoch 907/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3858 - accuracy: 0.8150 - val_loss: 0.4127 - val_accuracy: 0.8100\n",
      "Epoch 908/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3858 - accuracy: 0.8163 - val_loss: 0.4127 - val_accuracy: 0.8100\n",
      "Epoch 909/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3858 - accuracy: 0.8163 - val_loss: 0.4126 - val_accuracy: 0.8100\n",
      "Epoch 910/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3857 - accuracy: 0.8144 - val_loss: 0.4126 - val_accuracy: 0.8100\n",
      "Epoch 911/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3857 - accuracy: 0.8156 - val_loss: 0.4125 - val_accuracy: 0.8100\n",
      "Epoch 912/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3856 - accuracy: 0.8150 - val_loss: 0.4124 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3856 - accuracy: 0.8169 - val_loss: 0.4123 - val_accuracy: 0.8125\n",
      "Epoch 914/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3856 - accuracy: 0.8163 - val_loss: 0.4122 - val_accuracy: 0.8125\n",
      "Epoch 915/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3855 - accuracy: 0.8169 - val_loss: 0.4121 - val_accuracy: 0.8125\n",
      "Epoch 916/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3855 - accuracy: 0.8163 - val_loss: 0.4122 - val_accuracy: 0.8125\n",
      "Epoch 917/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3854 - accuracy: 0.8175 - val_loss: 0.4122 - val_accuracy: 0.8125\n",
      "Epoch 918/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3854 - accuracy: 0.8181 - val_loss: 0.4123 - val_accuracy: 0.8125\n",
      "Epoch 919/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8181 - val_loss: 0.4122 - val_accuracy: 0.8125\n",
      "Epoch 920/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8181 - val_loss: 0.4122 - val_accuracy: 0.8125\n",
      "Epoch 921/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.8175 - val_loss: 0.4121 - val_accuracy: 0.8125\n",
      "Epoch 922/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.8163 - val_loss: 0.4120 - val_accuracy: 0.8125\n",
      "Epoch 923/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3851 - accuracy: 0.8188 - val_loss: 0.4120 - val_accuracy: 0.8125\n",
      "Epoch 924/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.8175 - val_loss: 0.4118 - val_accuracy: 0.8125\n",
      "Epoch 925/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.8169 - val_loss: 0.4118 - val_accuracy: 0.8125\n",
      "Epoch 926/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.8175 - val_loss: 0.4118 - val_accuracy: 0.8125\n",
      "Epoch 927/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.8181 - val_loss: 0.4117 - val_accuracy: 0.8125\n",
      "Epoch 928/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3849 - accuracy: 0.8175 - val_loss: 0.4118 - val_accuracy: 0.8125\n",
      "Epoch 929/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3848 - accuracy: 0.8188 - val_loss: 0.4117 - val_accuracy: 0.8125\n",
      "Epoch 930/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3849 - accuracy: 0.8156 - val_loss: 0.4117 - val_accuracy: 0.8125\n",
      "Epoch 931/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3848 - accuracy: 0.8175 - val_loss: 0.4116 - val_accuracy: 0.8125\n",
      "Epoch 932/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3848 - accuracy: 0.8169 - val_loss: 0.4116 - val_accuracy: 0.8125\n",
      "Epoch 933/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3847 - accuracy: 0.8181 - val_loss: 0.4115 - val_accuracy: 0.8125\n",
      "Epoch 934/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3846 - accuracy: 0.8175 - val_loss: 0.4114 - val_accuracy: 0.8125\n",
      "Epoch 935/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3846 - accuracy: 0.8175 - val_loss: 0.4113 - val_accuracy: 0.8125\n",
      "Epoch 936/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3846 - accuracy: 0.8194 - val_loss: 0.4111 - val_accuracy: 0.8125\n",
      "Epoch 937/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3845 - accuracy: 0.8181 - val_loss: 0.4111 - val_accuracy: 0.8125\n",
      "Epoch 938/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3845 - accuracy: 0.8169 - val_loss: 0.4112 - val_accuracy: 0.8125\n",
      "Epoch 939/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3844 - accuracy: 0.8181 - val_loss: 0.4112 - val_accuracy: 0.8125\n",
      "Epoch 940/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3844 - accuracy: 0.8169 - val_loss: 0.4112 - val_accuracy: 0.8125\n",
      "Epoch 941/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3843 - accuracy: 0.8181 - val_loss: 0.4112 - val_accuracy: 0.8125\n",
      "Epoch 942/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3843 - accuracy: 0.8169 - val_loss: 0.4112 - val_accuracy: 0.8125\n",
      "Epoch 943/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3843 - accuracy: 0.8175 - val_loss: 0.4112 - val_accuracy: 0.8125\n",
      "Epoch 944/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3842 - accuracy: 0.8169 - val_loss: 0.4111 - val_accuracy: 0.8125\n",
      "Epoch 945/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3842 - accuracy: 0.8169 - val_loss: 0.4111 - val_accuracy: 0.8125\n",
      "Epoch 946/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3841 - accuracy: 0.8175 - val_loss: 0.4110 - val_accuracy: 0.8125\n",
      "Epoch 947/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.8169 - val_loss: 0.4109 - val_accuracy: 0.8125\n",
      "Epoch 948/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3840 - accuracy: 0.8175 - val_loss: 0.4108 - val_accuracy: 0.8125\n",
      "Epoch 949/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3840 - accuracy: 0.8181 - val_loss: 0.4106 - val_accuracy: 0.8125\n",
      "Epoch 950/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3839 - accuracy: 0.8181 - val_loss: 0.4106 - val_accuracy: 0.8125\n",
      "Epoch 951/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3839 - accuracy: 0.8181 - val_loss: 0.4107 - val_accuracy: 0.8125\n",
      "Epoch 952/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3839 - accuracy: 0.8169 - val_loss: 0.4106 - val_accuracy: 0.8125\n",
      "Epoch 953/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3838 - accuracy: 0.8175 - val_loss: 0.4106 - val_accuracy: 0.8125\n",
      "Epoch 954/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3838 - accuracy: 0.8175 - val_loss: 0.4106 - val_accuracy: 0.8125\n",
      "Epoch 955/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3837 - accuracy: 0.8181 - val_loss: 0.4106 - val_accuracy: 0.8125\n",
      "Epoch 956/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3837 - accuracy: 0.8181 - val_loss: 0.4105 - val_accuracy: 0.8125\n",
      "Epoch 957/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3836 - accuracy: 0.8188 - val_loss: 0.4105 - val_accuracy: 0.8125\n",
      "Epoch 958/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3837 - accuracy: 0.8188 - val_loss: 0.4104 - val_accuracy: 0.8125\n",
      "Epoch 959/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3836 - accuracy: 0.8194 - val_loss: 0.4104 - val_accuracy: 0.8100\n",
      "Epoch 960/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3835 - accuracy: 0.8169 - val_loss: 0.4105 - val_accuracy: 0.8125\n",
      "Epoch 961/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3835 - accuracy: 0.8163 - val_loss: 0.4105 - val_accuracy: 0.8100\n",
      "Epoch 962/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3834 - accuracy: 0.8188 - val_loss: 0.4104 - val_accuracy: 0.8100\n",
      "Epoch 963/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3834 - accuracy: 0.8175 - val_loss: 0.4104 - val_accuracy: 0.8100\n",
      "Epoch 964/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3834 - accuracy: 0.8188 - val_loss: 0.4104 - val_accuracy: 0.8100\n",
      "Epoch 965/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3833 - accuracy: 0.8188 - val_loss: 0.4103 - val_accuracy: 0.8125\n",
      "Epoch 966/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3832 - accuracy: 0.8181 - val_loss: 0.4102 - val_accuracy: 0.8125\n",
      "Epoch 967/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3832 - accuracy: 0.8200 - val_loss: 0.4102 - val_accuracy: 0.8125\n",
      "Epoch 968/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3832 - accuracy: 0.8194 - val_loss: 0.4103 - val_accuracy: 0.8125\n",
      "Epoch 969/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3831 - accuracy: 0.8194 - val_loss: 0.4102 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3831 - accuracy: 0.8194 - val_loss: 0.4101 - val_accuracy: 0.8125\n",
      "Epoch 971/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3830 - accuracy: 0.8194 - val_loss: 0.4101 - val_accuracy: 0.8125\n",
      "Epoch 972/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3830 - accuracy: 0.8188 - val_loss: 0.4101 - val_accuracy: 0.8100\n",
      "Epoch 973/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3829 - accuracy: 0.8188 - val_loss: 0.4100 - val_accuracy: 0.8100\n",
      "Epoch 974/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3828 - accuracy: 0.8188 - val_loss: 0.4099 - val_accuracy: 0.8100\n",
      "Epoch 975/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3828 - accuracy: 0.8181 - val_loss: 0.4099 - val_accuracy: 0.8100\n",
      "Epoch 976/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3828 - accuracy: 0.8194 - val_loss: 0.4099 - val_accuracy: 0.8100\n",
      "Epoch 977/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.8188 - val_loss: 0.4099 - val_accuracy: 0.8100\n",
      "Epoch 978/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.8188 - val_loss: 0.4099 - val_accuracy: 0.8100\n",
      "Epoch 979/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.8188 - val_loss: 0.4098 - val_accuracy: 0.8100\n",
      "Epoch 980/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3826 - accuracy: 0.8181 - val_loss: 0.4098 - val_accuracy: 0.8100\n",
      "Epoch 981/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3826 - accuracy: 0.8188 - val_loss: 0.4098 - val_accuracy: 0.8100\n",
      "Epoch 982/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3825 - accuracy: 0.8175 - val_loss: 0.4097 - val_accuracy: 0.8100\n",
      "Epoch 983/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3825 - accuracy: 0.8181 - val_loss: 0.4096 - val_accuracy: 0.8100\n",
      "Epoch 984/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3825 - accuracy: 0.8181 - val_loss: 0.4095 - val_accuracy: 0.8100\n",
      "Epoch 985/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3824 - accuracy: 0.8175 - val_loss: 0.4095 - val_accuracy: 0.8100\n",
      "Epoch 986/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3824 - accuracy: 0.8175 - val_loss: 0.4095 - val_accuracy: 0.8100\n",
      "Epoch 987/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3823 - accuracy: 0.8181 - val_loss: 0.4095 - val_accuracy: 0.8100\n",
      "Epoch 988/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3823 - accuracy: 0.8175 - val_loss: 0.4093 - val_accuracy: 0.8100\n",
      "Epoch 989/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3822 - accuracy: 0.8188 - val_loss: 0.4092 - val_accuracy: 0.8100\n",
      "Epoch 990/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3822 - accuracy: 0.8169 - val_loss: 0.4092 - val_accuracy: 0.8100\n",
      "Epoch 991/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3821 - accuracy: 0.8181 - val_loss: 0.4092 - val_accuracy: 0.8125\n",
      "Epoch 992/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3821 - accuracy: 0.8181 - val_loss: 0.4092 - val_accuracy: 0.8125\n",
      "Epoch 993/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3820 - accuracy: 0.8188 - val_loss: 0.4092 - val_accuracy: 0.8125\n",
      "Epoch 994/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3820 - accuracy: 0.8169 - val_loss: 0.4091 - val_accuracy: 0.8125\n",
      "Epoch 995/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3819 - accuracy: 0.8169 - val_loss: 0.4091 - val_accuracy: 0.8125\n",
      "Epoch 996/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3819 - accuracy: 0.8175 - val_loss: 0.4090 - val_accuracy: 0.8125\n",
      "Epoch 997/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3818 - accuracy: 0.8181 - val_loss: 0.4090 - val_accuracy: 0.8125\n",
      "Epoch 998/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3818 - accuracy: 0.8175 - val_loss: 0.4092 - val_accuracy: 0.8125\n",
      "Epoch 999/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3818 - accuracy: 0.8181 - val_loss: 0.4091 - val_accuracy: 0.8125\n",
      "Epoch 1000/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3817 - accuracy: 0.8188 - val_loss: 0.4091 - val_accuracy: 0.8125\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8180\n",
      "\n",
      "accuracy: 81.80%\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "The new predection is: [[0.7109723]]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "The new predection is: [[0.26292396]]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "The new predection is: [[0.2122224]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "The new predection is: [[0.9492075]]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "The new predection is: [[0.8575809]]\n",
      "train_accuracy: 0.8193749785423279\n",
      "train_error: 0.38151514530181885)\n",
      "test_accuracy: 0.8125\n",
      "test_error: 0.40914031863212585\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(100,input_dim=8, activation='relu'))\n",
    "model4.add(Dense(1, activation='sigmoid'))\n",
    "model4.compile(loss='binary_crossentropy', optimizer='sgd',metrics=['accuracy'])\n",
    "history4=model4.fit(x_train,y_train,epochs=1000,batch_size=128,validation_data=(x_test,y_test))\n",
    "scores = model4.evaluate(inputVariables,outputVariables)\n",
    "print(\"\\n%s: %.2f%%\" % (model4.metrics_names[1],scores[1]*100))\n",
    "print(\"The new predection is:\",model4.predict(np.array([z_score([6,142,72,45,0,38.6,0.627,50])])))\n",
    "print(\"The new predection is:\",model4.predict(np.array([z_score([1,109,30,38,83,53.3,0.193,33])])))\n",
    "print(\"The new predection is:\",model4.predict(np.array([z_score([2,112,68,22,94,34.1,0.315,26])])))\n",
    "print(\"The new predection is:\",model4.predict(np.array([z_score([2,197,70,45,543,30.5,0.158,53])])))\n",
    "print(\"The new predection is:\",model4.predict(np.array([z_score([3,180,64,25,70,34,0.271,26])])))\n",
    "tr_eval_res = model4.evaluate(x_train,y_train,verbose=0)\n",
    "eval_res= model4.evaluate(x_test,y_test,verbose=0)\n",
    "print(f'train_accuracy: {tr_eval_res[1]}')\n",
    "print(f'train_error: {tr_eval_res[0]})')\n",
    "print(f'test_accuracy: {eval_res[1]}')\n",
    "print(f'test_error: {eval_res[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e298a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "80/80 [==============================] - 2s 15ms/step - loss: 0.6467 - accuracy: 0.6644 - val_loss: 0.6577 - val_accuracy: 0.6325\n",
      "Epoch 2/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6399 - accuracy: 0.6644 - val_loss: 0.6581 - val_accuracy: 0.6325\n",
      "Epoch 3/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6386 - accuracy: 0.6644 - val_loss: 0.6590 - val_accuracy: 0.6325\n",
      "Epoch 4/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6595 - val_accuracy: 0.6325\n",
      "Epoch 5/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 6/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 7/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 8/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 9/200\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 10/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 11/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 12/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6595 - val_accuracy: 0.6325\n",
      "Epoch 13/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 14/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 15/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 16/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 17/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6594 - val_accuracy: 0.6325\n",
      "Epoch 18/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6593 - val_accuracy: 0.6325\n",
      "Epoch 19/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 20/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 21/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 22/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 23/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 24/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 25/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6382 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 26/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 27/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 28/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6604 - val_accuracy: 0.6325\n",
      "Epoch 29/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 30/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 31/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 32/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 33/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 34/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 35/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6382 - accuracy: 0.6644 - val_loss: 0.6605 - val_accuracy: 0.6325\n",
      "Epoch 36/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 37/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6382 - accuracy: 0.6644 - val_loss: 0.6606 - val_accuracy: 0.6325\n",
      "Epoch 38/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6606 - val_accuracy: 0.6325\n",
      "Epoch 39/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 40/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6604 - val_accuracy: 0.6325\n",
      "Epoch 41/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6602 - val_accuracy: 0.6325\n",
      "Epoch 42/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 43/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 44/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 45/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 46/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6604 - val_accuracy: 0.6325\n",
      "Epoch 47/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6382 - accuracy: 0.6644 - val_loss: 0.6612 - val_accuracy: 0.6325\n",
      "Epoch 48/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6603 - val_accuracy: 0.6325\n",
      "Epoch 49/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 50/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6602 - val_accuracy: 0.6325\n",
      "Epoch 51/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6602 - val_accuracy: 0.6325\n",
      "Epoch 52/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 53/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 54/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 55/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 56/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6382 - accuracy: 0.6644 - val_loss: 0.6603 - val_accuracy: 0.6325\n",
      "Epoch 57/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6602 - val_accuracy: 0.6325\n",
      "Epoch 58/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 59/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 60/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6382 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 61/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 62/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 63/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 64/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 65/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 66/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 67/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 68/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 69/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 70/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 71/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6602 - val_accuracy: 0.6325\n",
      "Epoch 72/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 73/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 74/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6602 - val_accuracy: 0.6325\n",
      "Epoch 75/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 76/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 77/200\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 78/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 79/200\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 80/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 81/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 82/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 83/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 84/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 85/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 86/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6595 - val_accuracy: 0.6325\n",
      "Epoch 87/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 88/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 89/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 90/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 91/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 92/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 93/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 94/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 95/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 96/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 97/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 98/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 99/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 100/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 101/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 102/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 103/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 104/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6602 - val_accuracy: 0.6325\n",
      "Epoch 105/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6603 - val_accuracy: 0.6325\n",
      "Epoch 106/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 107/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 108/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6382 - accuracy: 0.6644 - val_loss: 0.6594 - val_accuracy: 0.6325\n",
      "Epoch 109/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 110/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 111/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 112/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 113/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6602 - val_accuracy: 0.6325\n",
      "Epoch 114/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6604 - val_accuracy: 0.6325\n",
      "Epoch 116/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 117/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 118/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 119/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 120/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 121/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 122/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6595 - val_accuracy: 0.6325\n",
      "Epoch 123/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 124/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 125/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 126/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 127/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 128/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 129/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 130/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 131/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 132/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 133/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 134/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6602 - val_accuracy: 0.6325\n",
      "Epoch 135/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 136/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 137/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6595 - val_accuracy: 0.6325\n",
      "Epoch 138/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 139/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 140/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6382 - accuracy: 0.6644 - val_loss: 0.6594 - val_accuracy: 0.6325\n",
      "Epoch 141/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 142/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 143/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 144/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 145/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 146/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 147/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 148/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 149/200\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6595 - val_accuracy: 0.6325\n",
      "Epoch 150/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 151/200\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 152/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6594 - val_accuracy: 0.6325\n",
      "Epoch 153/200\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6595 - val_accuracy: 0.6325\n",
      "Epoch 154/200\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 155/200\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 156/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 157/200\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 158/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6382 - accuracy: 0.6644 - val_loss: 0.6604 - val_accuracy: 0.6325\n",
      "Epoch 159/200\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6602 - val_accuracy: 0.6325\n",
      "Epoch 160/200\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 161/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6602 - val_accuracy: 0.6325\n",
      "Epoch 162/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 163/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 164/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6382 - accuracy: 0.6644 - val_loss: 0.6594 - val_accuracy: 0.6325\n",
      "Epoch 165/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6595 - val_accuracy: 0.6325\n",
      "Epoch 166/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 167/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 168/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 169/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 170/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 171/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6595 - val_accuracy: 0.6325\n",
      "Epoch 173/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 174/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 175/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6601 - val_accuracy: 0.6325\n",
      "Epoch 176/200\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 177/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 178/200\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 179/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 180/200\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6382 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 181/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 182/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 183/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 184/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6602 - val_accuracy: 0.6325\n",
      "Epoch 185/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6600 - val_accuracy: 0.6325\n",
      "Epoch 186/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 187/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 188/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 189/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6595 - val_accuracy: 0.6325\n",
      "Epoch 190/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6598 - val_accuracy: 0.6325\n",
      "Epoch 191/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6599 - val_accuracy: 0.6325\n",
      "Epoch 192/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6594 - val_accuracy: 0.6325\n",
      "Epoch 193/200\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6595 - val_accuracy: 0.6325\n",
      "Epoch 194/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 195/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6596 - val_accuracy: 0.6325\n",
      "Epoch 196/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 197/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 198/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 199/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6384 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "Epoch 200/200\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6383 - accuracy: 0.6644 - val_loss: 0.6597 - val_accuracy: 0.6325\n",
      "63/63 [==============================] - 1s 6ms/step - loss: 0.6424 - accuracy: 0.6580\n",
      "\n",
      "accuracy: 65.80%\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "The new predection is: [[0.33701214]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "The new predection is: [[0.33701202]]\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "The new predection is: [[0.33700988]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "The new predection is: [[0.33700988]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "The new predection is: [[0.33701104]]\n",
      "train_accuracy: 0.6643750071525574\n",
      "train_error: 0.638094425201416)\n",
      "test_accuracy: 0.6324999928474426\n",
      "test_error: 0.6596624851226807\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(1000,input_dim=8, activation='sigmoid'))\n",
    "model5.add(Dense(800, activation='sigmoid'))\n",
    "model5.add(Dense(400, activation='sigmoid'))\n",
    "model5.add(Dense(200, activation='sigmoid'))\n",
    "model5.add(Dense(100, activation='sigmoid'))\n",
    "model5.add(Dense(50, activation='sigmoid'))\n",
    "model5.add(Dense(25, activation='sigmoid'))\n",
    "model5.add(Dense(10, activation='sigmoid'))\n",
    "model5.add(Dense(1, activation='sigmoid'))\n",
    "model5.compile(loss='binary_crossentropy', optimizer='sgd',metrics=['accuracy'])\n",
    "history5=model5.fit(x_train,y_train,epochs=200,batch_size=20,validation_data=(x_test,y_test))\n",
    "scores = model5.evaluate(inputVariables,outputVariables)\n",
    "print(\"\\n%s: %.2f%%\" % (model5.metrics_names[1],scores[1]*100))\n",
    "print(\"The new predection is:\",model5.predict(np.array([z_score([6,142,72,45,0,38.6,0.627,50])])))\n",
    "print(\"The new predection is:\",model5.predict(np.array([z_score([1,109,30,38,83,53.3,0.193,33])])))\n",
    "print(\"The new predection is:\",model5.predict(np.array([z_score([2,112,68,22,94,34.1,0.315,26])])))\n",
    "print(\"The new predection is:\",model5.predict(np.array([z_score([2,197,70,45,543,30.5,0.158,53])])))\n",
    "print(\"The new predection is:\",model5.predict(np.array([z_score([3,180,64,25,70,34,0.271,26])])))\n",
    "tr_eval_res = model5.evaluate(x_train,y_train,verbose=0)\n",
    "eval_res= model5.evaluate(x_test,y_test,verbose=0)\n",
    "print(f'train_accuracy: {tr_eval_res[1]}')\n",
    "print(f'train_error: {tr_eval_res[0]})')\n",
    "print(f'test_accuracy: {eval_res[1]}')\n",
    "print(f'test_error: {eval_res[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edb7dacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 2s 16ms/step - loss: 0.7066 - accuracy: 0.6956 - val_loss: 0.5571 - val_accuracy: 0.7400\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 0.6254 - accuracy: 0.6994 - val_loss: 0.5063 - val_accuracy: 0.7225\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.5557 - accuracy: 0.7462 - val_loss: 0.4765 - val_accuracy: 0.7675\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.5020 - accuracy: 0.7544 - val_loss: 0.6522 - val_accuracy: 0.5825\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4956 - accuracy: 0.7412 - val_loss: 0.4733 - val_accuracy: 0.7775\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4685 - accuracy: 0.7713 - val_loss: 0.4903 - val_accuracy: 0.7600\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4556 - accuracy: 0.7819 - val_loss: 0.5057 - val_accuracy: 0.7950\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4689 - accuracy: 0.7631 - val_loss: 0.4530 - val_accuracy: 0.7825\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4429 - accuracy: 0.7775 - val_loss: 0.4349 - val_accuracy: 0.7850\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4368 - accuracy: 0.7719 - val_loss: 0.5000 - val_accuracy: 0.7850\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.4309 - accuracy: 0.7812 - val_loss: 0.4327 - val_accuracy: 0.7925\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4276 - accuracy: 0.7756 - val_loss: 0.5030 - val_accuracy: 0.7875\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4280 - accuracy: 0.7819 - val_loss: 0.4404 - val_accuracy: 0.7875\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.4231 - accuracy: 0.7812 - val_loss: 0.4954 - val_accuracy: 0.7925\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.4184 - accuracy: 0.7875 - val_loss: 0.4948 - val_accuracy: 0.7900\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.4229 - accuracy: 0.7956 - val_loss: 0.4489 - val_accuracy: 0.7950\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4129 - accuracy: 0.7906 - val_loss: 0.4854 - val_accuracy: 0.7800\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.5732 - accuracy: 0.7419 - val_loss: 0.5603 - val_accuracy: 0.7700\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.5666 - accuracy: 0.7750 - val_loss: 0.5554 - val_accuracy: 0.7675\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.5658 - accuracy: 0.7819 - val_loss: 0.5422 - val_accuracy: 0.7700\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.5582 - accuracy: 0.7775 - val_loss: 0.5437 - val_accuracy: 0.7600\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.5514 - accuracy: 0.7850 - val_loss: 0.5479 - val_accuracy: 0.7800\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.5409 - accuracy: 0.7869 - val_loss: 0.5719 - val_accuracy: 0.7625\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4927 - accuracy: 0.7856 - val_loss: 0.5062 - val_accuracy: 0.7875\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4682 - accuracy: 0.7931 - val_loss: 0.5055 - val_accuracy: 0.7900\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4682 - accuracy: 0.7825 - val_loss: 0.5031 - val_accuracy: 0.7775\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4681 - accuracy: 0.7875 - val_loss: 0.5037 - val_accuracy: 0.7825\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4552 - accuracy: 0.7906 - val_loss: 0.4898 - val_accuracy: 0.7950\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4670 - accuracy: 0.7912 - val_loss: 0.4910 - val_accuracy: 0.7875\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4493 - accuracy: 0.8000 - val_loss: 0.4818 - val_accuracy: 0.8025\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4534 - accuracy: 0.8031 - val_loss: 0.4785 - val_accuracy: 0.7900\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.4409 - accuracy: 0.7994 - val_loss: 0.4782 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4382 - accuracy: 0.8075 - val_loss: 0.4795 - val_accuracy: 0.8175\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4339 - accuracy: 0.8069 - val_loss: 0.4705 - val_accuracy: 0.7950\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4335 - accuracy: 0.8156 - val_loss: 0.4739 - val_accuracy: 0.8050\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4282 - accuracy: 0.8075 - val_loss: 0.4738 - val_accuracy: 0.8025\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4253 - accuracy: 0.8125 - val_loss: 0.4617 - val_accuracy: 0.8200\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4311 - accuracy: 0.8156 - val_loss: 0.4727 - val_accuracy: 0.8050\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4208 - accuracy: 0.8087 - val_loss: 0.4640 - val_accuracy: 0.8125\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4149 - accuracy: 0.8138 - val_loss: 0.4587 - val_accuracy: 0.8100\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4168 - accuracy: 0.8213 - val_loss: 0.4544 - val_accuracy: 0.8200\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4134 - accuracy: 0.8225 - val_loss: 0.4560 - val_accuracy: 0.8075\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4070 - accuracy: 0.8200 - val_loss: 0.4548 - val_accuracy: 0.8225\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4035 - accuracy: 0.8281 - val_loss: 0.4515 - val_accuracy: 0.8150\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.3997 - accuracy: 0.8169 - val_loss: 0.4456 - val_accuracy: 0.8175\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.3940 - accuracy: 0.8269 - val_loss: 0.4416 - val_accuracy: 0.8325\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4031 - accuracy: 0.8319 - val_loss: 0.4366 - val_accuracy: 0.8450\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.3978 - accuracy: 0.8250 - val_loss: 0.5244 - val_accuracy: 0.8200\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.8211 - accuracy: 0.7163 - val_loss: 0.8018 - val_accuracy: 0.7700\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6702 - accuracy: 0.7181 - val_loss: 0.5530 - val_accuracy: 0.7675\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6709 - accuracy: 0.7550 - val_loss: 0.5329 - val_accuracy: 0.7725\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.5907 - accuracy: 0.7475 - val_loss: 0.6858 - val_accuracy: 0.7525\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6265 - accuracy: 0.7669 - val_loss: 0.5292 - val_accuracy: 0.7525\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4839 - accuracy: 0.7744 - val_loss: 0.5310 - val_accuracy: 0.7625\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4758 - accuracy: 0.7925 - val_loss: 0.4868 - val_accuracy: 0.7950\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.4601 - accuracy: 0.8075 - val_loss: 0.4968 - val_accuracy: 0.7875\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.6398 - accuracy: 0.7200 - val_loss: 0.5695 - val_accuracy: 0.7425\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6387 - accuracy: 0.7719 - val_loss: 0.6286 - val_accuracy: 0.7800\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.5746 - accuracy: 0.7806 - val_loss: 0.5745 - val_accuracy: 0.7775\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.5500 - accuracy: 0.7887 - val_loss: 0.5515 - val_accuracy: 0.7925\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.5401 - accuracy: 0.7956 - val_loss: 0.5243 - val_accuracy: 0.7850\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.5328 - accuracy: 0.7962 - val_loss: 0.5086 - val_accuracy: 0.7850\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.4734 - accuracy: 0.8087 - val_loss: 0.4938 - val_accuracy: 0.7825\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.9283 - accuracy: 0.7437 - val_loss: 1.0422 - val_accuracy: 0.7475\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.5644 - accuracy: 0.7763 - val_loss: 0.5033 - val_accuracy: 0.7700\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.7128 - accuracy: 0.6781 - val_loss: 0.6000 - val_accuracy: 0.7200\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 1.0331 - accuracy: 0.6725 - val_loss: 0.9107 - val_accuracy: 0.4900\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.8090 - accuracy: 0.7312 - val_loss: 0.6564 - val_accuracy: 0.7525\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.7747 - accuracy: 0.7644 - val_loss: 0.6559 - val_accuracy: 0.7825\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.7493 - accuracy: 0.7738 - val_loss: 0.6294 - val_accuracy: 0.7775\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.7342 - accuracy: 0.7731 - val_loss: 0.6225 - val_accuracy: 0.8050\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.7255 - accuracy: 0.7831 - val_loss: 0.6193 - val_accuracy: 0.7925\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.7169 - accuracy: 0.7912 - val_loss: 0.6079 - val_accuracy: 0.7825\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.6521 - accuracy: 0.7644 - val_loss: 0.5837 - val_accuracy: 0.7725\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6229 - accuracy: 0.7912 - val_loss: 0.5983 - val_accuracy: 0.7950\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.5946 - accuracy: 0.7781 - val_loss: 0.5608 - val_accuracy: 0.7550\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 1.2505 - accuracy: 0.6325 - val_loss: 0.7939 - val_accuracy: 0.7300\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.8581 - accuracy: 0.7200 - val_loss: 0.7533 - val_accuracy: 0.7125\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 3.2338 - accuracy: 0.5444 - val_loss: 0.7662 - val_accuracy: 0.6625\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.5659 - accuracy: 0.7487 - val_loss: 0.6464 - val_accuracy: 0.7825\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.5286 - accuracy: 0.7744 - val_loss: 0.6002 - val_accuracy: 0.8100\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 1.1697 - accuracy: 0.6600 - val_loss: 0.6772 - val_accuracy: 0.5825\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.7207 - accuracy: 0.5250 - val_loss: 0.6900 - val_accuracy: 0.7500\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.7575 - accuracy: 0.7063 - val_loss: 0.8230 - val_accuracy: 0.7675\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.9624 - accuracy: 0.6350 - val_loss: 0.6492 - val_accuracy: 0.7025\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.7314 - accuracy: 0.6831 - val_loss: 0.5991 - val_accuracy: 0.7250\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.6354 - accuracy: 0.7331 - val_loss: 0.5385 - val_accuracy: 0.7550\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.5923 - accuracy: 0.7456 - val_loss: 0.5229 - val_accuracy: 0.7900\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.6799 - accuracy: 0.7325 - val_loss: 0.5555 - val_accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 2.9411 - accuracy: 0.6994 - val_loss: 5.0398 - val_accuracy: 0.6725\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 4.7876 - accuracy: 0.6888 - val_loss: 5.0398 - val_accuracy: 0.6725\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 4.7876 - accuracy: 0.6888 - val_loss: 5.0398 - val_accuracy: 0.6725\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 4.7876 - accuracy: 0.6888 - val_loss: 5.0398 - val_accuracy: 0.6725\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 4.7876 - accuracy: 0.6888 - val_loss: 5.0398 - val_accuracy: 0.6725\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 4.7876 - accuracy: 0.6888 - val_loss: 5.0398 - val_accuracy: 0.6725\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 4.7876 - accuracy: 0.6888 - val_loss: 5.0398 - val_accuracy: 0.6725\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 4.7876 - accuracy: 0.6888 - val_loss: 5.0398 - val_accuracy: 0.6725\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 4.7876 - accuracy: 0.6888 - val_loss: 5.0398 - val_accuracy: 0.6725\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 4.7876 - accuracy: 0.6888 - val_loss: 5.0398 - val_accuracy: 0.6725\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 4.7876 - accuracy: 0.6888 - val_loss: 5.0398 - val_accuracy: 0.6725\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 4.8381 - accuracy: 0.6855\n",
      "\n",
      "accuracy: 68.55%\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "The new predection is: [[-0.9999973]]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "The new predection is: [[-0.9999969]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "The new predection is: [[-0.9999969]]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "The new predection is: [[-0.999997]]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "The new predection is: [[-0.99999696]]\n",
      "train_accuracy: 0.6887500286102295\n",
      "train_error: 4.787616729736328)\n",
      "test_accuracy: 0.6725000143051147\n",
      "test_error: 5.0398101806640625\n"
     ]
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Dense(1000,input_dim=8, activation='tanh'))\n",
    "model6.add(Dense(800, activation='tanh'))\n",
    "model6.add(Dense(400, activation='tanh'))\n",
    "model6.add(Dense(200, activation='tanh'))\n",
    "model6.add(Dense(100, activation='tanh'))\n",
    "model6.add(Dense(50, activation='tanh'))\n",
    "model6.add(Dense(25, activation='tanh'))\n",
    "model6.add(Dense(10, activation='tanh'))\n",
    "model6.add(Dense(1, activation='tanh'))\n",
    "model6.compile(loss='binary_crossentropy', optimizer='sgd',metrics=['accuracy'])\n",
    "history6=model6.fit(x_train,y_train,epochs=100,batch_size=20,validation_data=(x_test,y_test))\n",
    "scores = model6.evaluate(inputVariables,outputVariables)\n",
    "print(\"\\n%s: %.2f%%\" % (model6.metrics_names[1],scores[1]*100))\n",
    "print(\"The new predection is:\",model6.predict(np.array([z_score([6,142,72,45,0,38.6,0.627,50])])))\n",
    "print(\"The new predection is:\",model6.predict(np.array([z_score([1,109,30,38,83,53.3,0.193,33])])))\n",
    "print(\"The new predection is:\",model6.predict(np.array([z_score([2,112,68,22,94,34.1,0.315,26])])))\n",
    "print(\"The new predection is:\",model6.predict(np.array([z_score([2,197,70,45,543,30.5,0.158,53])])))\n",
    "print(\"The new predection is:\",model6.predict(np.array([z_score([3,180,64,25,70,34,0.271,26])])))\n",
    "tr_eval_res = model6.evaluate(x_train,y_train,verbose=0)\n",
    "eval_res= model6.evaluate(x_test,y_test,verbose=0)\n",
    "print(f'train_accuracy: {tr_eval_res[1]}')\n",
    "print(f'train_error: {tr_eval_res[0]})')\n",
    "print(f'test_accuracy: {eval_res[1]}')\n",
    "print(f'test_error: {eval_res[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c37d7dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 3s 21ms/step - loss: 1.8000 - accuracy: 0.7275 - val_loss: 1.5740 - val_accuracy: 0.7375\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.1777 - accuracy: 0.7312 - val_loss: 1.5967 - val_accuracy: 0.6950\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.1844 - accuracy: 0.7075 - val_loss: 1.1330 - val_accuracy: 0.7425\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 1.1111 - accuracy: 0.7369 - val_loss: 1.1604 - val_accuracy: 0.7550\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.1994 - accuracy: 0.7525 - val_loss: 1.2399 - val_accuracy: 0.7600\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 1.1924 - accuracy: 0.7538 - val_loss: 1.3262 - val_accuracy: 0.7675\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.2845 - accuracy: 0.7500 - val_loss: 1.2202 - val_accuracy: 0.7600\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 1.1856 - accuracy: 0.7431 - val_loss: 1.0603 - val_accuracy: 0.7050\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.1263 - accuracy: 0.6856 - val_loss: 1.2420 - val_accuracy: 0.7000\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.1926 - accuracy: 0.7081 - val_loss: 1.1365 - val_accuracy: 0.7375\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 1.0739 - accuracy: 0.7000 - val_loss: 0.9551 - val_accuracy: 0.7025\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.0834 - accuracy: 0.6837 - val_loss: 1.0372 - val_accuracy: 0.7300\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.9926 - accuracy: 0.6781 - val_loss: 0.7626 - val_accuracy: 0.6725\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 0.8844 - accuracy: 0.6812 - val_loss: 0.8085 - val_accuracy: 0.6625\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 0.8883 - accuracy: 0.6550 - val_loss: 1.0637 - val_accuracy: 0.6300\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.0992 - accuracy: 0.7225 - val_loss: 1.2493 - val_accuracy: 0.7250\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.1810 - accuracy: 0.7294 - val_loss: 1.2703 - val_accuracy: 0.7400\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.2060 - accuracy: 0.7325 - val_loss: 1.2756 - val_accuracy: 0.7400\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.2365 - accuracy: 0.7375 - val_loss: 1.5944 - val_accuracy: 0.7275\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.3207 - accuracy: 0.7387 - val_loss: 1.5984 - val_accuracy: 0.7225\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.2277 - accuracy: 0.7369 - val_loss: 1.1909 - val_accuracy: 0.7475\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.1232 - accuracy: 0.7344 - val_loss: 1.0209 - val_accuracy: 0.7400\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.1174 - accuracy: 0.7312 - val_loss: 1.0228 - val_accuracy: 0.7400\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.1170 - accuracy: 0.7312 - val_loss: 1.0226 - val_accuracy: 0.7400\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.1171 - accuracy: 0.7312 - val_loss: 1.0229 - val_accuracy: 0.7400\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.1176 - accuracy: 0.7312 - val_loss: 1.0216 - val_accuracy: 0.7400\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.1170 - accuracy: 0.7312 - val_loss: 1.0209 - val_accuracy: 0.7400\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.1171 - accuracy: 0.7312 - val_loss: 1.0210 - val_accuracy: 0.7400\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.1165 - accuracy: 0.7312 - val_loss: 1.0242 - val_accuracy: 0.7400\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.1797 - accuracy: 0.7306 - val_loss: 1.5365 - val_accuracy: 0.7125\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.3422 - accuracy: 0.7256 - val_loss: 1.5556 - val_accuracy: 0.7300\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.3179 - accuracy: 0.7312 - val_loss: 1.5171 - val_accuracy: 0.7350\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.3079 - accuracy: 0.7331 - val_loss: 1.5132 - val_accuracy: 0.7375\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.3086 - accuracy: 0.7344 - val_loss: 1.5134 - val_accuracy: 0.7375\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.3069 - accuracy: 0.7344 - val_loss: 1.5169 - val_accuracy: 0.7375\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.3072 - accuracy: 0.7344 - val_loss: 1.5143 - val_accuracy: 0.7375\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.3073 - accuracy: 0.7344 - val_loss: 1.5152 - val_accuracy: 0.7375\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.3071 - accuracy: 0.7344 - val_loss: 1.5136 - val_accuracy: 0.7375\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.3074 - accuracy: 0.7344 - val_loss: 1.5141 - val_accuracy: 0.7375\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.3073 - accuracy: 0.7344 - val_loss: 1.5158 - val_accuracy: 0.7375\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.3073 - accuracy: 0.7344 - val_loss: 1.5135 - val_accuracy: 0.7375\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.3072 - accuracy: 0.7344 - val_loss: 1.5141 - val_accuracy: 0.7375\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.3073 - accuracy: 0.7344 - val_loss: 1.5155 - val_accuracy: 0.7375\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.3069 - accuracy: 0.7344 - val_loss: 1.5130 - val_accuracy: 0.7375\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.3078 - accuracy: 0.7344 - val_loss: 1.5130 - val_accuracy: 0.7375\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.3067 - accuracy: 0.7344 - val_loss: 1.5171 - val_accuracy: 0.7375\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.3074 - accuracy: 0.7344 - val_loss: 1.5140 - val_accuracy: 0.7375\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.3070 - accuracy: 0.7344 - val_loss: 1.5134 - val_accuracy: 0.7375\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.3074 - accuracy: 0.7344 - val_loss: 1.5158 - val_accuracy: 0.7375\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.3071 - accuracy: 0.7344 - val_loss: 1.5131 - val_accuracy: 0.7375\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.3080 - accuracy: 0.7344 - val_loss: 1.5133 - val_accuracy: 0.7375\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.3075 - accuracy: 0.7344 - val_loss: 1.5131 - val_accuracy: 0.7375\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.3070 - accuracy: 0.7344 - val_loss: 1.5135 - val_accuracy: 0.7375\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.3072 - accuracy: 0.7344 - val_loss: 1.5146 - val_accuracy: 0.7375\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.3070 - accuracy: 0.7344 - val_loss: 1.5137 - val_accuracy: 0.7375\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.3070 - accuracy: 0.7344 - val_loss: 1.5153 - val_accuracy: 0.7375\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.3075 - accuracy: 0.7344 - val_loss: 1.5189 - val_accuracy: 0.7375\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 1s 15ms/step - loss: 1.3077 - accuracy: 0.7344 - val_loss: 1.5152 - val_accuracy: 0.7375\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.3069 - accuracy: 0.7344 - val_loss: 1.5137 - val_accuracy: 0.7375\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.3074 - accuracy: 0.7344 - val_loss: 1.5133 - val_accuracy: 0.7375\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.3075 - accuracy: 0.7344 - val_loss: 1.5141 - val_accuracy: 0.7375\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.3072 - accuracy: 0.7344 - val_loss: 1.5150 - val_accuracy: 0.7375\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.3074 - accuracy: 0.7344 - val_loss: 1.5140 - val_accuracy: 0.7400\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.4035 - accuracy: 0.7362 - val_loss: 1.6584 - val_accuracy: 0.7325\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.4525 - accuracy: 0.7100 - val_loss: 1.7942 - val_accuracy: 0.7000\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.4938 - accuracy: 0.7212 - val_loss: 1.9023 - val_accuracy: 0.6925\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 1s 13ms/step - loss: 1.4853 - accuracy: 0.7194 - val_loss: 1.6450 - val_accuracy: 0.7075\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.2080 - accuracy: 0.7275 - val_loss: 1.2177 - val_accuracy: 0.7175\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.1998 - accuracy: 0.7262 - val_loss: 1.2159 - val_accuracy: 0.7175\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.2002 - accuracy: 0.7262 - val_loss: 1.2160 - val_accuracy: 0.7175\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 1.1996 - accuracy: 0.7269 - val_loss: 1.2140 - val_accuracy: 0.7200\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 1.2003 - accuracy: 0.7262 - val_loss: 1.2139 - val_accuracy: 0.7200\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 1.1999 - accuracy: 0.7262 - val_loss: 1.2140 - val_accuracy: 0.7200\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 1.2000 - accuracy: 0.7262 - val_loss: 1.2142 - val_accuracy: 0.7200\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 1.2002 - accuracy: 0.7262 - val_loss: 1.2139 - val_accuracy: 0.7200\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 1s 18ms/step - loss: 1.2001 - accuracy: 0.7262 - val_loss: 1.2176 - val_accuracy: 0.7200\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.2007 - accuracy: 0.7262 - val_loss: 1.2157 - val_accuracy: 0.7200\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.1998 - accuracy: 0.7262 - val_loss: 1.2138 - val_accuracy: 0.7200\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 1.2002 - accuracy: 0.7262 - val_loss: 1.2143 - val_accuracy: 0.7200\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 2.0505 - accuracy: 0.6744 - val_loss: 1.6407 - val_accuracy: 0.7450\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.6362 - accuracy: 0.7519 - val_loss: 1.6452 - val_accuracy: 0.7450\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 1.6238 - accuracy: 0.7556 - val_loss: 1.3980 - val_accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.5021 - accuracy: 0.7250 - val_loss: 1.4418 - val_accuracy: 0.6900\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.5091 - accuracy: 0.7462 - val_loss: 1.3922 - val_accuracy: 0.7850\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.4912 - accuracy: 0.7581 - val_loss: 1.4358 - val_accuracy: 0.7400\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.5441 - accuracy: 0.7531 - val_loss: 1.3951 - val_accuracy: 0.7550\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 1s 17ms/step - loss: 1.3972 - accuracy: 0.7544 - val_loss: 1.3953 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 1s 16ms/step - loss: 1.4295 - accuracy: 0.7500 - val_loss: 1.4709 - val_accuracy: 0.7450\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.3342 - accuracy: 0.7394 - val_loss: 1.2105 - val_accuracy: 0.7475\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.2991 - accuracy: 0.7312 - val_loss: 1.3442 - val_accuracy: 0.7350\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.3267 - accuracy: 0.7306 - val_loss: 1.3180 - val_accuracy: 0.7150\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.2762 - accuracy: 0.7412 - val_loss: 1.3423 - val_accuracy: 0.7300\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.2744 - accuracy: 0.7569 - val_loss: 1.3729 - val_accuracy: 0.7350\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.4195 - accuracy: 0.7594 - val_loss: 1.9365 - val_accuracy: 0.7650\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.6966 - accuracy: 0.7613 - val_loss: 3.2678 - val_accuracy: 0.7000\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.8208 - accuracy: 0.7369 - val_loss: 1.2378 - val_accuracy: 0.7275\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.2452 - accuracy: 0.7487 - val_loss: 1.2900 - val_accuracy: 0.7450\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.2295 - accuracy: 0.7556 - val_loss: 1.2842 - val_accuracy: 0.7550\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 1s 15ms/step - loss: 1.2204 - accuracy: 0.7700 - val_loss: 1.2901 - val_accuracy: 0.7425\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 1.2625 - accuracy: 0.7606 - val_loss: 1.3247 - val_accuracy: 0.7650\n",
      "63/63 [==============================] - 1s 7ms/step - loss: 1.2715 - accuracy: 0.7675\n",
      "\n",
      "accuracy: 76.75%\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "The new predection is: [[0.68988174]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "The new predection is: [[0.43269044]]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "The new predection is: [[-0.61939156]]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "The new predection is: [[0.6898902]]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "The new predection is: [[0.68984896]]\n",
      "train_accuracy: 0.7681249976158142\n",
      "train_error: 1.2582231760025024)\n",
      "test_accuracy: 0.7649999856948853\n",
      "test_error: 1.3247268199920654\n"
     ]
    }
   ],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(Dense(1000,input_dim=8, activation='tanh'))\n",
    "model7.add(Dense(800, activation='tanh'))\n",
    "model7.add(Dense(400, activation='tanh'))\n",
    "model7.add(Dense(200, activation='tanh'))\n",
    "model7.add(Dense(100, activation='tanh'))\n",
    "model7.add(Dense(50, activation='tanh'))\n",
    "model7.add(Dense(25, activation='tanh'))\n",
    "model7.add(Dense(10, activation='tanh'))\n",
    "model7.add(Dense(1, activation='tanh'))\n",
    "model7.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "history7=model7.fit(x_train,y_train,epochs=100,batch_size=20,validation_data=(x_test,y_test))\n",
    "scores = model7.evaluate(inputVariables,outputVariables)\n",
    "print(\"\\n%s: %.2f%%\" % (model7.metrics_names[1],scores[1]*100))\n",
    "print(\"The new predection is:\",model7.predict(np.array([z_score([6,142,72,45,0,38.6,0.627,50])])))\n",
    "print(\"The new predection is:\",model7.predict(np.array([z_score([1,109,30,38,83,53.3,0.193,33])])))\n",
    "print(\"The new predection is:\",model7.predict(np.array([z_score([2,112,68,22,94,34.1,0.315,26])])))\n",
    "print(\"The new predection is:\",model7.predict(np.array([z_score([2,197,70,45,543,30.5,0.158,53])])))\n",
    "print(\"The new predection is:\",model7.predict(np.array([z_score([3,180,64,25,70,34,0.271,26])])))\n",
    "tr_eval_res = model7.evaluate(x_train,y_train,verbose=0)\n",
    "eval_res= model7.evaluate(x_test,y_test,verbose=0)\n",
    "print(f'train_accuracy: {tr_eval_res[1]}')\n",
    "print(f'train_error: {tr_eval_res[0]})')\n",
    "print(f'test_accuracy: {eval_res[1]}')\n",
    "print(f'test_error: {eval_res[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2c51bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.6790 - accuracy: 0.6475 - val_loss: 0.6687 - val_accuracy: 0.6325\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6512 - accuracy: 0.6644 - val_loss: 0.6451 - val_accuracy: 0.6325\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6220 - accuracy: 0.6644 - val_loss: 0.6204 - val_accuracy: 0.6325\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5941 - accuracy: 0.6644 - val_loss: 0.5972 - val_accuracy: 0.6325\n",
      "Epoch 5/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5687 - accuracy: 0.6644 - val_loss: 0.5739 - val_accuracy: 0.6325\n",
      "Epoch 6/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5442 - accuracy: 0.6787 - val_loss: 0.5511 - val_accuracy: 0.6425\n",
      "Epoch 7/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.5226 - accuracy: 0.7100 - val_loss: 0.5305 - val_accuracy: 0.6900\n",
      "Epoch 8/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5044 - accuracy: 0.7394 - val_loss: 0.5130 - val_accuracy: 0.7350\n",
      "Epoch 9/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4893 - accuracy: 0.7563 - val_loss: 0.4979 - val_accuracy: 0.7600\n",
      "Epoch 10/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.7663 - val_loss: 0.4845 - val_accuracy: 0.7750\n",
      "Epoch 11/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7763 - val_loss: 0.4744 - val_accuracy: 0.7800\n",
      "Epoch 12/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7738 - val_loss: 0.4657 - val_accuracy: 0.7825\n",
      "Epoch 13/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7769 - val_loss: 0.4585 - val_accuracy: 0.7850\n",
      "Epoch 14/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7713 - val_loss: 0.4530 - val_accuracy: 0.7875\n",
      "Epoch 15/50\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.7763 - val_loss: 0.4473 - val_accuracy: 0.7850\n",
      "Epoch 16/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4368 - accuracy: 0.7869 - val_loss: 0.4450 - val_accuracy: 0.7825\n",
      "Epoch 17/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4328 - accuracy: 0.7825 - val_loss: 0.4394 - val_accuracy: 0.7975\n",
      "Epoch 18/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7894 - val_loss: 0.4362 - val_accuracy: 0.7950\n",
      "Epoch 19/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7900 - val_loss: 0.4337 - val_accuracy: 0.7925\n",
      "Epoch 20/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7894 - val_loss: 0.4310 - val_accuracy: 0.7950\n",
      "Epoch 21/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.7900 - val_loss: 0.4274 - val_accuracy: 0.7975\n",
      "Epoch 22/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.7944 - val_loss: 0.4250 - val_accuracy: 0.8050\n",
      "Epoch 23/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.7969 - val_loss: 0.4229 - val_accuracy: 0.8050\n",
      "Epoch 24/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.7981 - val_loss: 0.4219 - val_accuracy: 0.8150\n",
      "Epoch 25/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8019 - val_loss: 0.4184 - val_accuracy: 0.8025\n",
      "Epoch 26/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8006 - val_loss: 0.4179 - val_accuracy: 0.8125\n",
      "Epoch 27/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8012 - val_loss: 0.4149 - val_accuracy: 0.8125\n",
      "Epoch 28/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.8037 - val_loss: 0.4142 - val_accuracy: 0.8050\n",
      "Epoch 29/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8025 - val_loss: 0.4160 - val_accuracy: 0.8025\n",
      "Epoch 30/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8044 - val_loss: 0.4101 - val_accuracy: 0.8025\n",
      "Epoch 31/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8112 - val_loss: 0.4110 - val_accuracy: 0.8025\n",
      "Epoch 32/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8044 - val_loss: 0.4056 - val_accuracy: 0.8150\n",
      "Epoch 33/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8150 - val_loss: 0.4042 - val_accuracy: 0.8075\n",
      "Epoch 34/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8112 - val_loss: 0.4017 - val_accuracy: 0.8250\n",
      "Epoch 35/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8175 - val_loss: 0.4018 - val_accuracy: 0.8200\n",
      "Epoch 36/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8156 - val_loss: 0.4031 - val_accuracy: 0.8050\n",
      "Epoch 37/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8213 - val_loss: 0.3968 - val_accuracy: 0.8250\n",
      "Epoch 38/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8188 - val_loss: 0.3975 - val_accuracy: 0.8175\n",
      "Epoch 39/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3805 - accuracy: 0.8219 - val_loss: 0.3949 - val_accuracy: 0.8250\n",
      "Epoch 40/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.8225 - val_loss: 0.3931 - val_accuracy: 0.8200\n",
      "Epoch 41/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8256 - val_loss: 0.3900 - val_accuracy: 0.8250\n",
      "Epoch 42/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8250 - val_loss: 0.3927 - val_accuracy: 0.8125\n",
      "Epoch 43/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8269 - val_loss: 0.3879 - val_accuracy: 0.8225\n",
      "Epoch 44/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3710 - accuracy: 0.8294 - val_loss: 0.3882 - val_accuracy: 0.8275\n",
      "Epoch 45/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8344 - val_loss: 0.3837 - val_accuracy: 0.8250\n",
      "Epoch 46/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3673 - accuracy: 0.8306 - val_loss: 0.3835 - val_accuracy: 0.8200\n",
      "Epoch 47/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3647 - accuracy: 0.8263 - val_loss: 0.3848 - val_accuracy: 0.8225\n",
      "Epoch 48/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3632 - accuracy: 0.8331 - val_loss: 0.3809 - val_accuracy: 0.8200\n",
      "Epoch 49/50\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3608 - accuracy: 0.8300 - val_loss: 0.3788 - val_accuracy: 0.8275\n",
      "Epoch 50/50\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3591 - accuracy: 0.8325 - val_loss: 0.3780 - val_accuracy: 0.8300\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8395\n",
      "\n",
      "accuracy: 83.95%\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "The new predection is: [[0.70967346]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "The new predection is: [[0.4149356]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "The new predection is: [[0.20677108]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "The new predection is: [[0.90701014]]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "The new predection is: [[0.8472116]]\n",
      "train_accuracy: 0.8418750166893005\n",
      "train_error: 0.35487598180770874)\n",
      "test_accuracy: 0.8299999833106995\n",
      "test_error: 0.37796318531036377\n"
     ]
    }
   ],
   "source": [
    "# like model but sgd not adam \n",
    "model8 = Sequential()\n",
    "model8.add(Dense(320,input_dim=8, activation='relu'))\n",
    "model8.add(Dense(160, activation='relu'))\n",
    "model8.add(Dense(80, activation='relu'))\n",
    "model8.add(Dense(20, activation='relu'))\n",
    "model8.add(Dense(1, activation='sigmoid'))\n",
    "model8.compile(loss='binary_crossentropy', optimizer='sgd',metrics=['accuracy'])\n",
    "history8=model8.fit(x_train,y_train,epochs=50,batch_size=30,validation_data=(x_test,y_test))\n",
    "scores = model8.evaluate(inputVariables,outputVariables)\n",
    "print(\"\\n%s: %.2f%%\" % (model8.metrics_names[1],scores[1]*100))\n",
    "print(\"The new predection is:\",model8.predict(np.array([z_score([6,142,72,45,0,38.6,0.627,50])])))\n",
    "print(\"The new predection is:\",model8.predict(np.array([z_score([1,109,30,38,83,53.3,0.193,33])])))\n",
    "print(\"The new predection is:\",model8.predict(np.array([z_score([2,112,68,22,94,34.1,0.315,26])])))\n",
    "print(\"The new predection is:\",model8.predict(np.array([z_score([2,197,70,45,543,30.5,0.158,53])])))\n",
    "print(\"The new predection is:\",model8.predict(np.array([z_score([3,180,64,25,70,34,0.271,26])])))\n",
    "tr_eval_res = model8.evaluate(x_train,y_train,verbose=0)\n",
    "eval_res= model8.evaluate(x_test,y_test,verbose=0)\n",
    "print(f'train_accuracy: {tr_eval_res[1]}')\n",
    "print(f'train_error: {tr_eval_res[0]})')\n",
    "print(f'test_accuracy: {eval_res[1]}')\n",
    "print(f'test_error: {eval_res[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d312a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "13/13 [==============================] - 1s 21ms/step - loss: 0.6917 - accuracy: 0.6394 - val_loss: 0.6630 - val_accuracy: 0.6500\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6793 - accuracy: 0.6494 - val_loss: 0.6525 - val_accuracy: 0.6575\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6679 - accuracy: 0.6600 - val_loss: 0.6429 - val_accuracy: 0.6675\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6574 - accuracy: 0.6687 - val_loss: 0.6340 - val_accuracy: 0.6725\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6477 - accuracy: 0.6750 - val_loss: 0.6258 - val_accuracy: 0.6850\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6862 - val_loss: 0.6181 - val_accuracy: 0.6850\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6301 - accuracy: 0.6837 - val_loss: 0.6110 - val_accuracy: 0.6825\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6221 - accuracy: 0.6825 - val_loss: 0.6046 - val_accuracy: 0.6850\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6148 - accuracy: 0.6919 - val_loss: 0.5984 - val_accuracy: 0.7050\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6079 - accuracy: 0.6969 - val_loss: 0.5928 - val_accuracy: 0.7075\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6014 - accuracy: 0.6963 - val_loss: 0.5874 - val_accuracy: 0.7150\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5953 - accuracy: 0.7019 - val_loss: 0.5824 - val_accuracy: 0.7250\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5895 - accuracy: 0.7088 - val_loss: 0.5777 - val_accuracy: 0.7325\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5841 - accuracy: 0.7175 - val_loss: 0.5733 - val_accuracy: 0.7350\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5791 - accuracy: 0.7219 - val_loss: 0.5693 - val_accuracy: 0.7450\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5742 - accuracy: 0.7250 - val_loss: 0.5654 - val_accuracy: 0.7475\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5697 - accuracy: 0.7256 - val_loss: 0.5619 - val_accuracy: 0.7475\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5655 - accuracy: 0.7200 - val_loss: 0.5585 - val_accuracy: 0.7450\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5615 - accuracy: 0.7188 - val_loss: 0.5553 - val_accuracy: 0.7450\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5577 - accuracy: 0.7200 - val_loss: 0.5523 - val_accuracy: 0.7475\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5542 - accuracy: 0.7231 - val_loss: 0.5495 - val_accuracy: 0.7450\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5506 - accuracy: 0.7275 - val_loss: 0.5468 - val_accuracy: 0.7500\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5474 - accuracy: 0.7275 - val_loss: 0.5443 - val_accuracy: 0.7450\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5443 - accuracy: 0.7312 - val_loss: 0.5419 - val_accuracy: 0.7425\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7325 - val_loss: 0.5397 - val_accuracy: 0.7475\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5385 - accuracy: 0.7337 - val_loss: 0.5375 - val_accuracy: 0.7500\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5359 - accuracy: 0.7362 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5334 - accuracy: 0.7387 - val_loss: 0.5337 - val_accuracy: 0.7600\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5310 - accuracy: 0.7419 - val_loss: 0.5319 - val_accuracy: 0.7575\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5287 - accuracy: 0.7437 - val_loss: 0.5302 - val_accuracy: 0.7650\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7462 - val_loss: 0.5286 - val_accuracy: 0.7625\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7462 - val_loss: 0.5271 - val_accuracy: 0.7575\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5225 - accuracy: 0.7456 - val_loss: 0.5256 - val_accuracy: 0.7575\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5206 - accuracy: 0.7494 - val_loss: 0.5242 - val_accuracy: 0.7575\n",
      "Epoch 35/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5187 - accuracy: 0.7519 - val_loss: 0.5229 - val_accuracy: 0.7550\n",
      "Epoch 36/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5170 - accuracy: 0.7513 - val_loss: 0.5216 - val_accuracy: 0.7550\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7500 - val_loss: 0.5204 - val_accuracy: 0.7575\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.7513 - val_loss: 0.5193 - val_accuracy: 0.7625\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7513 - val_loss: 0.5182 - val_accuracy: 0.7625\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.7513 - val_loss: 0.5172 - val_accuracy: 0.7625\n",
      "Epoch 41/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5094 - accuracy: 0.7513 - val_loss: 0.5162 - val_accuracy: 0.7650\n",
      "Epoch 42/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5080 - accuracy: 0.7531 - val_loss: 0.5152 - val_accuracy: 0.7675\n",
      "Epoch 43/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5067 - accuracy: 0.7544 - val_loss: 0.5144 - val_accuracy: 0.7675\n",
      "Epoch 44/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.7538 - val_loss: 0.5135 - val_accuracy: 0.7650\n",
      "Epoch 45/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7544 - val_loss: 0.5127 - val_accuracy: 0.7650\n",
      "Epoch 46/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5032 - accuracy: 0.7519 - val_loss: 0.5119 - val_accuracy: 0.7650\n",
      "Epoch 47/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.7538 - val_loss: 0.5111 - val_accuracy: 0.7650\n",
      "Epoch 48/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5010 - accuracy: 0.7550 - val_loss: 0.5104 - val_accuracy: 0.7700\n",
      "Epoch 49/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.7556 - val_loss: 0.5097 - val_accuracy: 0.7700\n",
      "Epoch 50/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4990 - accuracy: 0.7544 - val_loss: 0.5091 - val_accuracy: 0.7700\n",
      "Epoch 51/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7531 - val_loss: 0.5084 - val_accuracy: 0.7700\n",
      "Epoch 52/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.7531 - val_loss: 0.5078 - val_accuracy: 0.7725\n",
      "Epoch 53/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.7556 - val_loss: 0.5072 - val_accuracy: 0.7750\n",
      "Epoch 54/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7563 - val_loss: 0.5067 - val_accuracy: 0.7750\n",
      "Epoch 55/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4946 - accuracy: 0.7569 - val_loss: 0.5062 - val_accuracy: 0.7750\n",
      "Epoch 56/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4938 - accuracy: 0.7544 - val_loss: 0.5056 - val_accuracy: 0.7700\n",
      "Epoch 57/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4931 - accuracy: 0.7538 - val_loss: 0.5052 - val_accuracy: 0.7700\n",
      "Epoch 58/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4923 - accuracy: 0.7538 - val_loss: 0.5047 - val_accuracy: 0.7700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7563 - val_loss: 0.5043 - val_accuracy: 0.7700\n",
      "Epoch 60/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7613 - val_loss: 0.5039 - val_accuracy: 0.7700\n",
      "Epoch 61/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7613 - val_loss: 0.5034 - val_accuracy: 0.7650\n",
      "Epoch 62/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7600 - val_loss: 0.5030 - val_accuracy: 0.7650\n",
      "Epoch 63/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4890 - accuracy: 0.7594 - val_loss: 0.5026 - val_accuracy: 0.7625\n",
      "Epoch 64/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7613 - val_loss: 0.5022 - val_accuracy: 0.7675\n",
      "Epoch 65/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.7619 - val_loss: 0.5019 - val_accuracy: 0.7675\n",
      "Epoch 66/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4872 - accuracy: 0.7606 - val_loss: 0.5016 - val_accuracy: 0.7675\n",
      "Epoch 67/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.7606 - val_loss: 0.5013 - val_accuracy: 0.7675\n",
      "Epoch 68/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4862 - accuracy: 0.7575 - val_loss: 0.5009 - val_accuracy: 0.7650\n",
      "Epoch 69/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7600 - val_loss: 0.5006 - val_accuracy: 0.7650\n",
      "Epoch 70/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4852 - accuracy: 0.7594 - val_loss: 0.5004 - val_accuracy: 0.7700\n",
      "Epoch 71/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7606 - val_loss: 0.5001 - val_accuracy: 0.7700\n",
      "Epoch 72/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4843 - accuracy: 0.7606 - val_loss: 0.4998 - val_accuracy: 0.7700\n",
      "Epoch 73/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7606 - val_loss: 0.4996 - val_accuracy: 0.7700\n",
      "Epoch 74/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4834 - accuracy: 0.7606 - val_loss: 0.4993 - val_accuracy: 0.7700\n",
      "Epoch 75/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7606 - val_loss: 0.4991 - val_accuracy: 0.7700\n",
      "Epoch 76/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7581 - val_loss: 0.4989 - val_accuracy: 0.7750\n",
      "Epoch 77/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7544 - val_loss: 0.4986 - val_accuracy: 0.7750\n",
      "Epoch 78/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7544 - val_loss: 0.4985 - val_accuracy: 0.7750\n",
      "Epoch 79/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7544 - val_loss: 0.4983 - val_accuracy: 0.7750\n",
      "Epoch 80/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4811 - accuracy: 0.7538 - val_loss: 0.4981 - val_accuracy: 0.7775\n",
      "Epoch 81/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4808 - accuracy: 0.7538 - val_loss: 0.4979 - val_accuracy: 0.7775\n",
      "Epoch 82/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7550 - val_loss: 0.4977 - val_accuracy: 0.7775\n",
      "Epoch 83/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4801 - accuracy: 0.7550 - val_loss: 0.4975 - val_accuracy: 0.7775\n",
      "Epoch 84/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.7550 - val_loss: 0.4974 - val_accuracy: 0.7775\n",
      "Epoch 85/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.7550 - val_loss: 0.4972 - val_accuracy: 0.7775\n",
      "Epoch 86/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7556 - val_loss: 0.4971 - val_accuracy: 0.7775\n",
      "Epoch 87/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7588 - val_loss: 0.4969 - val_accuracy: 0.7800\n",
      "Epoch 88/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4785 - accuracy: 0.7600 - val_loss: 0.4968 - val_accuracy: 0.7800\n",
      "Epoch 89/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.7600 - val_loss: 0.4966 - val_accuracy: 0.7800\n",
      "Epoch 90/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.7600 - val_loss: 0.4965 - val_accuracy: 0.7800\n",
      "Epoch 91/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.7600 - val_loss: 0.4963 - val_accuracy: 0.7800\n",
      "Epoch 92/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.7600 - val_loss: 0.4962 - val_accuracy: 0.7800\n",
      "Epoch 93/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7600 - val_loss: 0.4961 - val_accuracy: 0.7750\n",
      "Epoch 94/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4770 - accuracy: 0.7600 - val_loss: 0.4960 - val_accuracy: 0.7725\n",
      "Epoch 95/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.7594 - val_loss: 0.4959 - val_accuracy: 0.7725\n",
      "Epoch 96/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7594 - val_loss: 0.4958 - val_accuracy: 0.7725\n",
      "Epoch 97/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4764 - accuracy: 0.7606 - val_loss: 0.4957 - val_accuracy: 0.7725\n",
      "Epoch 98/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.7625 - val_loss: 0.4956 - val_accuracy: 0.7725\n",
      "Epoch 99/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4759 - accuracy: 0.7625 - val_loss: 0.4955 - val_accuracy: 0.7725\n",
      "Epoch 100/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4757 - accuracy: 0.7638 - val_loss: 0.4954 - val_accuracy: 0.7725\n",
      "Epoch 101/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4756 - accuracy: 0.7644 - val_loss: 0.4953 - val_accuracy: 0.7725\n",
      "Epoch 102/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4754 - accuracy: 0.7644 - val_loss: 0.4952 - val_accuracy: 0.7725\n",
      "Epoch 103/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4752 - accuracy: 0.7631 - val_loss: 0.4952 - val_accuracy: 0.7725\n",
      "Epoch 104/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7638 - val_loss: 0.4951 - val_accuracy: 0.7725\n",
      "Epoch 105/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.7638 - val_loss: 0.4950 - val_accuracy: 0.7725\n",
      "Epoch 106/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4747 - accuracy: 0.7644 - val_loss: 0.4949 - val_accuracy: 0.7725\n",
      "Epoch 107/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7650 - val_loss: 0.4949 - val_accuracy: 0.7725\n",
      "Epoch 108/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7650 - val_loss: 0.4948 - val_accuracy: 0.7725\n",
      "Epoch 109/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7650 - val_loss: 0.4947 - val_accuracy: 0.7725\n",
      "Epoch 110/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7650 - val_loss: 0.4947 - val_accuracy: 0.7675\n",
      "Epoch 111/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4739 - accuracy: 0.7650 - val_loss: 0.4947 - val_accuracy: 0.7675\n",
      "Epoch 112/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7631 - val_loss: 0.4946 - val_accuracy: 0.7675\n",
      "Epoch 113/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.7650 - val_loss: 0.4945 - val_accuracy: 0.7725\n",
      "Epoch 114/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7631 - val_loss: 0.4944 - val_accuracy: 0.7725\n",
      "Epoch 115/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7631 - val_loss: 0.4944 - val_accuracy: 0.7725\n",
      "Epoch 116/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.7631 - val_loss: 0.4943 - val_accuracy: 0.7725\n",
      "Epoch 117/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7631 - val_loss: 0.4943 - val_accuracy: 0.7725\n",
      "Epoch 118/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7631 - val_loss: 0.4942 - val_accuracy: 0.7725\n",
      "Epoch 119/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7631 - val_loss: 0.4942 - val_accuracy: 0.7725\n",
      "Epoch 120/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7631 - val_loss: 0.4942 - val_accuracy: 0.7725\n",
      "Epoch 121/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7631 - val_loss: 0.4941 - val_accuracy: 0.7725\n",
      "Epoch 122/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7631 - val_loss: 0.4941 - val_accuracy: 0.7700\n",
      "Epoch 123/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7619 - val_loss: 0.4940 - val_accuracy: 0.7700\n",
      "Epoch 124/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.7619 - val_loss: 0.4940 - val_accuracy: 0.7700\n",
      "Epoch 125/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7619 - val_loss: 0.4940 - val_accuracy: 0.7700\n",
      "Epoch 126/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7619 - val_loss: 0.4939 - val_accuracy: 0.7700\n",
      "Epoch 127/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7619 - val_loss: 0.4938 - val_accuracy: 0.7700\n",
      "Epoch 128/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7625 - val_loss: 0.4938 - val_accuracy: 0.7700\n",
      "Epoch 129/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7631 - val_loss: 0.4938 - val_accuracy: 0.7700\n",
      "Epoch 130/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7631 - val_loss: 0.4937 - val_accuracy: 0.7700\n",
      "Epoch 131/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7631 - val_loss: 0.4937 - val_accuracy: 0.7700\n",
      "Epoch 132/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7631 - val_loss: 0.4937 - val_accuracy: 0.7700\n",
      "Epoch 133/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.7631 - val_loss: 0.4936 - val_accuracy: 0.7700\n",
      "Epoch 134/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7638 - val_loss: 0.4936 - val_accuracy: 0.7700\n",
      "Epoch 135/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7650 - val_loss: 0.4936 - val_accuracy: 0.7700\n",
      "Epoch 136/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7650 - val_loss: 0.4936 - val_accuracy: 0.7700\n",
      "Epoch 137/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7650 - val_loss: 0.4935 - val_accuracy: 0.7700\n",
      "Epoch 138/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.7638 - val_loss: 0.4935 - val_accuracy: 0.7700\n",
      "Epoch 139/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4709 - accuracy: 0.7638 - val_loss: 0.4935 - val_accuracy: 0.7700\n",
      "Epoch 140/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.7650 - val_loss: 0.4935 - val_accuracy: 0.7700\n",
      "Epoch 141/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.7650 - val_loss: 0.4935 - val_accuracy: 0.7700\n",
      "Epoch 142/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7650 - val_loss: 0.4934 - val_accuracy: 0.7700\n",
      "Epoch 143/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7650 - val_loss: 0.4935 - val_accuracy: 0.7700\n",
      "Epoch 144/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.7650 - val_loss: 0.4934 - val_accuracy: 0.7700\n",
      "Epoch 145/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7650 - val_loss: 0.4933 - val_accuracy: 0.7700\n",
      "Epoch 146/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7650 - val_loss: 0.4933 - val_accuracy: 0.7700\n",
      "Epoch 147/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7650 - val_loss: 0.4933 - val_accuracy: 0.7700\n",
      "Epoch 148/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7650 - val_loss: 0.4933 - val_accuracy: 0.7700\n",
      "Epoch 149/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4702 - accuracy: 0.7650 - val_loss: 0.4932 - val_accuracy: 0.7700\n",
      "Epoch 150/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7650 - val_loss: 0.4933 - val_accuracy: 0.7700\n",
      "Epoch 151/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7650 - val_loss: 0.4932 - val_accuracy: 0.7700\n",
      "Epoch 152/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7650 - val_loss: 0.4932 - val_accuracy: 0.7700\n",
      "Epoch 153/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7650 - val_loss: 0.4932 - val_accuracy: 0.7700\n",
      "Epoch 154/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7650 - val_loss: 0.4931 - val_accuracy: 0.7700\n",
      "Epoch 155/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7650 - val_loss: 0.4931 - val_accuracy: 0.7700\n",
      "Epoch 156/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7663 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 157/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7663 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 158/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7675 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 159/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 160/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7656 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 161/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7650 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 162/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7700\n",
      "Epoch 163/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7663 - val_loss: 0.4930 - val_accuracy: 0.7700\n",
      "Epoch 164/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7656 - val_loss: 0.4929 - val_accuracy: 0.7700\n",
      "Epoch 165/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7650 - val_loss: 0.4930 - val_accuracy: 0.7700\n",
      "Epoch 166/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7650 - val_loss: 0.4929 - val_accuracy: 0.7700\n",
      "Epoch 167/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.7675 - val_loss: 0.4929 - val_accuracy: 0.7700\n",
      "Epoch 168/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.7650 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 169/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7675 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 170/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.7675 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 171/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.7675 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 172/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7650 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.7663 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 174/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7663 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 175/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7663 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 176/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7663 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 177/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7663 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 178/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 179/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 180/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 181/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 182/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 183/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 184/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 185/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 186/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 187/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 188/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 189/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 190/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 191/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4685 - accuracy: 0.7675 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 192/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4685 - accuracy: 0.7675 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 193/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7675 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 194/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4685 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 195/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.7675 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 196/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.7675 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 197/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.7675 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 198/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.7675 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 199/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7675 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 200/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7675 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 201/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 202/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 203/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 204/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7675 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 205/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7675 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 206/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7675 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 207/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 208/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 209/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 210/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 211/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 212/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7663 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 213/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7656 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 214/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7656 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 215/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7656 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 216/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7656 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 217/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7656 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 218/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7656 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 219/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7656 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 220/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7656 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 221/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7656 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 222/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7656 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 223/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7656 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 224/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7656 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 225/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7656 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 226/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7656 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 227/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7656 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 228/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7663 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 229/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 230/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4678 - accuracy: 0.7663 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 231/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 232/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 233/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 234/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 235/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 236/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 237/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 238/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 239/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 240/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 241/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 242/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 243/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 244/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 245/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 246/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7675 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 247/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 248/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 249/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 250/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 251/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 252/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 253/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 254/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 255/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 256/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 257/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 258/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 259/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7675 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 260/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7675 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 261/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7675 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 262/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7675 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 263/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7675 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 264/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 265/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 266/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7675 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 267/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 268/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 269/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7681 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 270/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 271/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 272/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7675 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 273/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7688 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 274/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 275/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 276/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 277/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 278/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 279/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 280/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7675 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 281/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7675 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 282/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7681 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 283/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 284/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 285/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7663 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 286/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7656 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7650 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 288/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 289/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7650 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 290/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7650 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 291/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7663 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 292/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7650 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 293/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 294/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 295/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7669 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 296/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 297/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7656 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 298/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7669 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 299/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 300/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 301/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 302/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 303/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7663 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 304/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7656 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 305/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 306/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7669 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 307/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 308/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 309/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 310/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 311/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 312/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 313/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 314/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 315/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 316/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 317/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 318/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 319/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 320/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 321/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 322/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 323/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 324/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 325/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 326/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 327/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 328/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 329/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 330/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 331/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 332/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 333/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 334/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 335/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 336/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 337/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 338/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 339/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 340/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 341/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 342/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 343/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 344/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 345/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 346/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 347/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 348/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 349/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 350/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 351/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 352/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 353/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 354/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 355/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 356/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 357/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 358/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 359/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 360/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 361/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 362/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 363/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 364/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 365/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 366/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 367/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 368/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 369/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 370/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 371/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 372/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 373/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 374/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 375/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 376/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 377/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 378/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 379/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 380/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 381/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 382/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7675 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 383/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 384/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 385/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 386/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 387/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 388/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 389/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7675 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 390/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 391/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 392/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 393/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 394/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 395/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 396/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 397/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 398/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 399/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 400/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 402/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 403/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 404/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 405/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 406/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 407/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 408/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 409/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 410/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 411/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 412/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 413/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 414/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 415/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 416/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 417/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 418/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 419/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 420/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 421/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4934 - val_accuracy: 0.7725\n",
      "Epoch 422/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 423/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 424/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 425/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 426/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 427/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 428/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 429/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 430/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 431/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 432/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 433/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 434/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 435/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 436/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 437/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 438/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 439/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 440/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 441/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 442/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 443/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 444/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 445/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 446/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 447/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 448/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 449/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 450/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 451/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 452/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7688 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 453/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7681 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 454/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7694 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 455/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7694 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 456/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 457/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 458/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7694 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 459/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 460/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 461/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 462/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 463/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 464/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7694 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 465/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 466/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 467/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 468/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 469/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 470/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 471/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 472/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 473/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 474/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 475/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 476/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 477/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 478/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 479/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 480/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 481/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 482/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 483/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 484/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 485/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 486/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 487/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 488/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 489/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 490/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 491/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 492/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 493/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 494/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 495/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 496/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 497/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 498/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 499/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 500/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7705\n",
      "\n",
      "accuracy: 77.05%\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "The new predection is: [[0.7321323]]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "The new predection is: [[0.5266951]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "The new predection is: [[0.18113446]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "The new predection is: [[0.71140146]]\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "The new predection is: [[0.7692876]]\n",
      "train_accuracy: 0.7699999809265137\n",
      "train_error: 0.46712005138397217)\n",
      "test_accuracy: 0.7724999785423279\n",
      "test_error: 0.4930076599121094\n"
     ]
    }
   ],
   "source": [
    "# 1 layer and sgd optimizer  # underfiting\n",
    "model9 = Sequential()\n",
    "model9.add(Dense(1,input_dim=8, activation='sigmoid'))\n",
    "model9.compile(loss='binary_crossentropy', optimizer='sgd',metrics=['accuracy'])\n",
    "history9=model9.fit(x_train,y_train,epochs=500,batch_size=128,validation_data=(x_test,y_test))\n",
    "scores = model9.evaluate(inputVariables,outputVariables)\n",
    "print(\"\\n%s: %.2f%%\" % (model9.metrics_names[1],scores[1]*100))\n",
    "print(\"The new predection is:\",model9.predict(np.array([z_score([6,142,72,45,0,38.6,0.627,50])])))\n",
    "print(\"The new predection is:\",model9.predict(np.array([z_score([1,109,30,38,83,53.3,0.193,33])])))\n",
    "print(\"The new predection is:\",model9.predict(np.array([z_score([2,112,68,22,94,34.1,0.315,26])])))\n",
    "print(\"The new predection is:\",model9.predict(np.array([z_score([2,197,70,45,543,30.5,0.158,53])])))\n",
    "print(\"The new predection is:\",model9.predict(np.array([z_score([3,180,64,25,70,34,0.271,26])])))\n",
    "tr_eval_res = model9.evaluate(x_train,y_train,verbose=0)\n",
    "eval_res= model9.evaluate(x_test,y_test,verbose=0)\n",
    "print(f'train_accuracy: {tr_eval_res[1]}')\n",
    "print(f'train_error: {tr_eval_res[0]})')\n",
    "print(f'test_accuracy: {eval_res[1]}')\n",
    "print(f'test_error: {eval_res[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0ecf41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "13/13 [==============================] - 1s 22ms/step - loss: 0.6603 - accuracy: 0.6731 - val_loss: 0.6421 - val_accuracy: 0.6925\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6527 - accuracy: 0.6725 - val_loss: 0.6354 - val_accuracy: 0.7025\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6455 - accuracy: 0.6756 - val_loss: 0.6289 - val_accuracy: 0.7025\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6819 - val_loss: 0.6227 - val_accuracy: 0.7050\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6321 - accuracy: 0.6837 - val_loss: 0.6168 - val_accuracy: 0.7000\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6256 - accuracy: 0.6869 - val_loss: 0.6113 - val_accuracy: 0.7025\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6197 - accuracy: 0.6881 - val_loss: 0.6059 - val_accuracy: 0.7150\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6140 - accuracy: 0.6888 - val_loss: 0.6008 - val_accuracy: 0.7150\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6083 - accuracy: 0.6900 - val_loss: 0.5961 - val_accuracy: 0.7225\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6031 - accuracy: 0.6900 - val_loss: 0.5916 - val_accuracy: 0.7175\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5980 - accuracy: 0.6900 - val_loss: 0.5870 - val_accuracy: 0.7200\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5930 - accuracy: 0.6919 - val_loss: 0.5827 - val_accuracy: 0.7200\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5882 - accuracy: 0.6956 - val_loss: 0.5786 - val_accuracy: 0.7225\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5837 - accuracy: 0.6944 - val_loss: 0.5746 - val_accuracy: 0.7300\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5792 - accuracy: 0.6975 - val_loss: 0.5709 - val_accuracy: 0.7325\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5751 - accuracy: 0.7019 - val_loss: 0.5671 - val_accuracy: 0.7325\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5710 - accuracy: 0.7125 - val_loss: 0.5636 - val_accuracy: 0.7400\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5671 - accuracy: 0.7163 - val_loss: 0.5603 - val_accuracy: 0.7400\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5634 - accuracy: 0.7194 - val_loss: 0.5570 - val_accuracy: 0.7400\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5598 - accuracy: 0.7250 - val_loss: 0.5539 - val_accuracy: 0.7450\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5562 - accuracy: 0.7281 - val_loss: 0.5510 - val_accuracy: 0.7500\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5528 - accuracy: 0.7306 - val_loss: 0.5481 - val_accuracy: 0.7475\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5495 - accuracy: 0.7319 - val_loss: 0.5454 - val_accuracy: 0.7525\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5464 - accuracy: 0.7337 - val_loss: 0.5427 - val_accuracy: 0.7575\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.7369 - val_loss: 0.5400 - val_accuracy: 0.7575\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5404 - accuracy: 0.7369 - val_loss: 0.5376 - val_accuracy: 0.7600\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5374 - accuracy: 0.7381 - val_loss: 0.5353 - val_accuracy: 0.7600\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5347 - accuracy: 0.7387 - val_loss: 0.5330 - val_accuracy: 0.7600\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7387 - val_loss: 0.5307 - val_accuracy: 0.7600\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7412 - val_loss: 0.5286 - val_accuracy: 0.7575\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5270 - accuracy: 0.7419 - val_loss: 0.5266 - val_accuracy: 0.7575\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5247 - accuracy: 0.7450 - val_loss: 0.5246 - val_accuracy: 0.7600\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5224 - accuracy: 0.7494 - val_loss: 0.5227 - val_accuracy: 0.7600\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5201 - accuracy: 0.7506 - val_loss: 0.5209 - val_accuracy: 0.7600\n",
      "Epoch 35/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5179 - accuracy: 0.7525 - val_loss: 0.5192 - val_accuracy: 0.7650\n",
      "Epoch 36/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5158 - accuracy: 0.7494 - val_loss: 0.5175 - val_accuracy: 0.7625\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.7494 - val_loss: 0.5158 - val_accuracy: 0.7700\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7519 - val_loss: 0.5144 - val_accuracy: 0.7700\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5100 - accuracy: 0.7544 - val_loss: 0.5129 - val_accuracy: 0.7625\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7519 - val_loss: 0.5114 - val_accuracy: 0.7625\n",
      "Epoch 41/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5065 - accuracy: 0.7519 - val_loss: 0.5102 - val_accuracy: 0.7625\n",
      "Epoch 42/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5048 - accuracy: 0.7487 - val_loss: 0.5090 - val_accuracy: 0.7700\n",
      "Epoch 43/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5033 - accuracy: 0.7506 - val_loss: 0.5078 - val_accuracy: 0.7725\n",
      "Epoch 44/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5016 - accuracy: 0.7487 - val_loss: 0.5066 - val_accuracy: 0.7650\n",
      "Epoch 45/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5002 - accuracy: 0.7519 - val_loss: 0.5055 - val_accuracy: 0.7700\n",
      "Epoch 46/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4988 - accuracy: 0.7556 - val_loss: 0.5044 - val_accuracy: 0.7725\n",
      "Epoch 47/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4973 - accuracy: 0.7563 - val_loss: 0.5034 - val_accuracy: 0.7775\n",
      "Epoch 48/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.7569 - val_loss: 0.5026 - val_accuracy: 0.7775\n",
      "Epoch 49/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4948 - accuracy: 0.7563 - val_loss: 0.5016 - val_accuracy: 0.7750\n",
      "Epoch 50/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7550 - val_loss: 0.5008 - val_accuracy: 0.7750\n",
      "Epoch 51/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4924 - accuracy: 0.7544 - val_loss: 0.5000 - val_accuracy: 0.7750\n",
      "Epoch 52/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4913 - accuracy: 0.7569 - val_loss: 0.4992 - val_accuracy: 0.7700\n",
      "Epoch 53/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7588 - val_loss: 0.4984 - val_accuracy: 0.7750\n",
      "Epoch 54/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4893 - accuracy: 0.7606 - val_loss: 0.4977 - val_accuracy: 0.7750\n",
      "Epoch 55/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4883 - accuracy: 0.7606 - val_loss: 0.4971 - val_accuracy: 0.7775\n",
      "Epoch 56/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7625 - val_loss: 0.4965 - val_accuracy: 0.7775\n",
      "Epoch 57/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4865 - accuracy: 0.7638 - val_loss: 0.4959 - val_accuracy: 0.7725\n",
      "Epoch 58/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7638 - val_loss: 0.4955 - val_accuracy: 0.7725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7638 - val_loss: 0.4950 - val_accuracy: 0.7725\n",
      "Epoch 60/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4840 - accuracy: 0.7625 - val_loss: 0.4945 - val_accuracy: 0.7750\n",
      "Epoch 61/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4832 - accuracy: 0.7638 - val_loss: 0.4940 - val_accuracy: 0.7725\n",
      "Epoch 62/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7638 - val_loss: 0.4936 - val_accuracy: 0.7750\n",
      "Epoch 63/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4818 - accuracy: 0.7638 - val_loss: 0.4933 - val_accuracy: 0.7750\n",
      "Epoch 64/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4812 - accuracy: 0.7625 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 65/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4805 - accuracy: 0.7625 - val_loss: 0.4925 - val_accuracy: 0.7725\n",
      "Epoch 66/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4798 - accuracy: 0.7625 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 67/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.7606 - val_loss: 0.4919 - val_accuracy: 0.7725\n",
      "Epoch 68/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7606 - val_loss: 0.4916 - val_accuracy: 0.7700\n",
      "Epoch 69/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7594 - val_loss: 0.4914 - val_accuracy: 0.7700\n",
      "Epoch 70/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7600 - val_loss: 0.4912 - val_accuracy: 0.7700\n",
      "Epoch 71/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7625 - val_loss: 0.4910 - val_accuracy: 0.7800\n",
      "Epoch 72/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7669 - val_loss: 0.4908 - val_accuracy: 0.7800\n",
      "Epoch 73/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.7663 - val_loss: 0.4906 - val_accuracy: 0.7800\n",
      "Epoch 74/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.7675 - val_loss: 0.4905 - val_accuracy: 0.7750\n",
      "Epoch 75/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.7688 - val_loss: 0.4903 - val_accuracy: 0.7750\n",
      "Epoch 76/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7681 - val_loss: 0.4901 - val_accuracy: 0.7750\n",
      "Epoch 77/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.7656 - val_loss: 0.4900 - val_accuracy: 0.7750\n",
      "Epoch 78/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7656 - val_loss: 0.4899 - val_accuracy: 0.7750\n",
      "Epoch 79/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4739 - accuracy: 0.7675 - val_loss: 0.4898 - val_accuracy: 0.7750\n",
      "Epoch 80/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.7669 - val_loss: 0.4897 - val_accuracy: 0.7750\n",
      "Epoch 81/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7688 - val_loss: 0.4897 - val_accuracy: 0.7775\n",
      "Epoch 82/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4730 - accuracy: 0.7719 - val_loss: 0.4895 - val_accuracy: 0.7775\n",
      "Epoch 83/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7719 - val_loss: 0.4895 - val_accuracy: 0.7775\n",
      "Epoch 84/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7719 - val_loss: 0.4895 - val_accuracy: 0.7775\n",
      "Epoch 85/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.7719 - val_loss: 0.4894 - val_accuracy: 0.7775\n",
      "Epoch 86/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7719 - val_loss: 0.4894 - val_accuracy: 0.7775\n",
      "Epoch 87/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7719 - val_loss: 0.4893 - val_accuracy: 0.7775\n",
      "Epoch 88/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7731 - val_loss: 0.4894 - val_accuracy: 0.7800\n",
      "Epoch 89/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7725 - val_loss: 0.4893 - val_accuracy: 0.7750\n",
      "Epoch 90/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.7731 - val_loss: 0.4893 - val_accuracy: 0.7725\n",
      "Epoch 91/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4709 - accuracy: 0.7706 - val_loss: 0.4893 - val_accuracy: 0.7800\n",
      "Epoch 92/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7719 - val_loss: 0.4893 - val_accuracy: 0.7825\n",
      "Epoch 93/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4705 - accuracy: 0.7725 - val_loss: 0.4893 - val_accuracy: 0.7775\n",
      "Epoch 94/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7731 - val_loss: 0.4893 - val_accuracy: 0.7775\n",
      "Epoch 95/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7731 - val_loss: 0.4893 - val_accuracy: 0.7775\n",
      "Epoch 96/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7731 - val_loss: 0.4893 - val_accuracy: 0.7775\n",
      "Epoch 97/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7731 - val_loss: 0.4893 - val_accuracy: 0.7775\n",
      "Epoch 98/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7731 - val_loss: 0.4894 - val_accuracy: 0.7775\n",
      "Epoch 99/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7719 - val_loss: 0.4894 - val_accuracy: 0.7775\n",
      "Epoch 100/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7713 - val_loss: 0.4895 - val_accuracy: 0.7750\n",
      "Epoch 101/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7700 - val_loss: 0.4896 - val_accuracy: 0.7775\n",
      "Epoch 102/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.7706 - val_loss: 0.4896 - val_accuracy: 0.7775\n",
      "Epoch 103/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7681 - val_loss: 0.4896 - val_accuracy: 0.7750\n",
      "Epoch 104/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7681 - val_loss: 0.4897 - val_accuracy: 0.7750\n",
      "Epoch 105/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7700 - val_loss: 0.4897 - val_accuracy: 0.7775\n",
      "Epoch 106/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.7706 - val_loss: 0.4898 - val_accuracy: 0.7775\n",
      "Epoch 107/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7706 - val_loss: 0.4899 - val_accuracy: 0.7775\n",
      "Epoch 108/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.7706 - val_loss: 0.4899 - val_accuracy: 0.7775\n",
      "Epoch 109/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7706 - val_loss: 0.4900 - val_accuracy: 0.7775\n",
      "Epoch 110/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7688 - val_loss: 0.4900 - val_accuracy: 0.7750\n",
      "Epoch 111/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4685 - accuracy: 0.7675 - val_loss: 0.4901 - val_accuracy: 0.7750\n",
      "Epoch 112/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.7688 - val_loss: 0.4901 - val_accuracy: 0.7750\n",
      "Epoch 113/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7688 - val_loss: 0.4901 - val_accuracy: 0.7750\n",
      "Epoch 114/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7688 - val_loss: 0.4903 - val_accuracy: 0.7750\n",
      "Epoch 115/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7688 - val_loss: 0.4902 - val_accuracy: 0.7750\n",
      "Epoch 116/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7688 - val_loss: 0.4904 - val_accuracy: 0.7750\n",
      "Epoch 117/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7688 - val_loss: 0.4904 - val_accuracy: 0.7750\n",
      "Epoch 118/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7688 - val_loss: 0.4904 - val_accuracy: 0.7750\n",
      "Epoch 119/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7688 - val_loss: 0.4905 - val_accuracy: 0.7750\n",
      "Epoch 120/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7688 - val_loss: 0.4906 - val_accuracy: 0.7750\n",
      "Epoch 121/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7688 - val_loss: 0.4906 - val_accuracy: 0.7750\n",
      "Epoch 122/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7688 - val_loss: 0.4906 - val_accuracy: 0.7750\n",
      "Epoch 123/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7688 - val_loss: 0.4907 - val_accuracy: 0.7750\n",
      "Epoch 124/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7688 - val_loss: 0.4907 - val_accuracy: 0.7750\n",
      "Epoch 125/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7700 - val_loss: 0.4907 - val_accuracy: 0.7750\n",
      "Epoch 126/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7700 - val_loss: 0.4907 - val_accuracy: 0.7750\n",
      "Epoch 127/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7700 - val_loss: 0.4907 - val_accuracy: 0.7750\n",
      "Epoch 128/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7700 - val_loss: 0.4906 - val_accuracy: 0.7750\n",
      "Epoch 129/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7700 - val_loss: 0.4907 - val_accuracy: 0.7750\n",
      "Epoch 130/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7700 - val_loss: 0.4907 - val_accuracy: 0.7750\n",
      "Epoch 131/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7700 - val_loss: 0.4907 - val_accuracy: 0.7750\n",
      "Epoch 132/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7706 - val_loss: 0.4907 - val_accuracy: 0.7750\n",
      "Epoch 133/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7700 - val_loss: 0.4909 - val_accuracy: 0.7750\n",
      "Epoch 134/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.7700 - val_loss: 0.4910 - val_accuracy: 0.7750\n",
      "Epoch 135/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7700 - val_loss: 0.4910 - val_accuracy: 0.7750\n",
      "Epoch 136/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7713 - val_loss: 0.4909 - val_accuracy: 0.7750\n",
      "Epoch 137/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7706 - val_loss: 0.4910 - val_accuracy: 0.7725\n",
      "Epoch 138/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7713 - val_loss: 0.4911 - val_accuracy: 0.7725\n",
      "Epoch 139/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7713 - val_loss: 0.4912 - val_accuracy: 0.7750\n",
      "Epoch 140/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7719 - val_loss: 0.4913 - val_accuracy: 0.7725\n",
      "Epoch 141/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7725 - val_loss: 0.4912 - val_accuracy: 0.7725\n",
      "Epoch 142/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7725 - val_loss: 0.4913 - val_accuracy: 0.7725\n",
      "Epoch 143/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7725 - val_loss: 0.4913 - val_accuracy: 0.7725\n",
      "Epoch 144/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7744 - val_loss: 0.4914 - val_accuracy: 0.7725\n",
      "Epoch 145/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7744 - val_loss: 0.4914 - val_accuracy: 0.7725\n",
      "Epoch 146/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7744 - val_loss: 0.4914 - val_accuracy: 0.7725\n",
      "Epoch 147/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7738 - val_loss: 0.4915 - val_accuracy: 0.7725\n",
      "Epoch 148/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7713 - val_loss: 0.4915 - val_accuracy: 0.7725\n",
      "Epoch 149/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7713 - val_loss: 0.4915 - val_accuracy: 0.7725\n",
      "Epoch 150/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7713 - val_loss: 0.4916 - val_accuracy: 0.7725\n",
      "Epoch 151/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7713 - val_loss: 0.4917 - val_accuracy: 0.7725\n",
      "Epoch 152/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7725 - val_loss: 0.4917 - val_accuracy: 0.7725\n",
      "Epoch 153/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7725 - val_loss: 0.4917 - val_accuracy: 0.7725\n",
      "Epoch 154/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7725 - val_loss: 0.4918 - val_accuracy: 0.7725\n",
      "Epoch 155/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7725 - val_loss: 0.4918 - val_accuracy: 0.7725\n",
      "Epoch 156/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7725 - val_loss: 0.4918 - val_accuracy: 0.7725\n",
      "Epoch 157/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7719 - val_loss: 0.4919 - val_accuracy: 0.7725\n",
      "Epoch 158/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7725 - val_loss: 0.4920 - val_accuracy: 0.7725\n",
      "Epoch 159/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7706 - val_loss: 0.4921 - val_accuracy: 0.7725\n",
      "Epoch 160/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7706 - val_loss: 0.4921 - val_accuracy: 0.7725\n",
      "Epoch 161/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7694 - val_loss: 0.4923 - val_accuracy: 0.7725\n",
      "Epoch 162/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4673 - accuracy: 0.7719 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 163/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7725 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 164/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7725 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 165/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7725 - val_loss: 0.4921 - val_accuracy: 0.7725\n",
      "Epoch 166/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7719 - val_loss: 0.4921 - val_accuracy: 0.7725\n",
      "Epoch 167/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7713 - val_loss: 0.4920 - val_accuracy: 0.7725\n",
      "Epoch 168/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4921 - val_accuracy: 0.7725\n",
      "Epoch 169/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7725 - val_loss: 0.4921 - val_accuracy: 0.7725\n",
      "Epoch 170/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7725 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 171/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 172/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4921 - val_accuracy: 0.7725\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4923 - val_accuracy: 0.7725\n",
      "Epoch 174/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 175/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 176/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4923 - val_accuracy: 0.7725\n",
      "Epoch 177/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 178/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4921 - val_accuracy: 0.7725\n",
      "Epoch 179/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 180/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4921 - val_accuracy: 0.7725\n",
      "Epoch 181/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 182/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 183/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 184/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 185/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 186/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 187/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 188/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4923 - val_accuracy: 0.7725\n",
      "Epoch 189/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 190/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4922 - val_accuracy: 0.7725\n",
      "Epoch 191/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4923 - val_accuracy: 0.7725\n",
      "Epoch 192/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4924 - val_accuracy: 0.7725\n",
      "Epoch 193/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4923 - val_accuracy: 0.7725\n",
      "Epoch 194/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4924 - val_accuracy: 0.7725\n",
      "Epoch 195/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4924 - val_accuracy: 0.7725\n",
      "Epoch 196/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4924 - val_accuracy: 0.7725\n",
      "Epoch 197/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4924 - val_accuracy: 0.7725\n",
      "Epoch 198/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4925 - val_accuracy: 0.7725\n",
      "Epoch 199/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4925 - val_accuracy: 0.7725\n",
      "Epoch 200/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4925 - val_accuracy: 0.7750\n",
      "Epoch 201/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7719 - val_loss: 0.4926 - val_accuracy: 0.7725\n",
      "Epoch 202/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 203/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7725 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 204/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4926 - val_accuracy: 0.7725\n",
      "Epoch 205/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7719 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 206/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7725 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 207/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7725 - val_loss: 0.4926 - val_accuracy: 0.7750\n",
      "Epoch 208/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4926 - val_accuracy: 0.7725\n",
      "Epoch 209/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4926 - val_accuracy: 0.7725\n",
      "Epoch 210/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4926 - val_accuracy: 0.7725\n",
      "Epoch 211/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 212/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 213/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 214/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 215/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 216/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 217/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 218/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 219/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7713 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 220/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 221/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 222/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 223/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 224/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 225/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 226/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 227/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 228/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 229/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 230/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 231/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 232/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 233/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 234/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 235/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 236/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4926 - val_accuracy: 0.7725\n",
      "Epoch 237/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 238/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 239/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 240/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 241/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 242/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4927 - val_accuracy: 0.7725\n",
      "Epoch 243/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 244/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 245/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 246/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 247/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 248/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 249/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 250/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 251/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 252/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 253/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 254/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 255/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 256/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 257/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 258/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4932 - val_accuracy: 0.7750\n",
      "Epoch 259/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 260/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 261/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 262/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 263/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 264/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 265/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 266/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 267/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4934 - val_accuracy: 0.7725\n",
      "Epoch 268/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4934 - val_accuracy: 0.7725\n",
      "Epoch 269/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 270/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 271/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 272/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 273/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 274/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 275/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 276/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 277/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 278/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 279/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 280/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7713 - val_loss: 0.4931 - val_accuracy: 0.7750\n",
      "Epoch 281/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 282/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 283/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 284/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 285/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4931 - val_accuracy: 0.7750\n",
      "Epoch 286/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7713 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 288/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 289/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 290/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 291/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7706 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 292/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7713 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 293/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7719 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 294/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7719 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 295/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 296/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 297/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 298/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 299/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 300/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 301/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 302/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 303/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 304/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 305/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 306/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 307/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 308/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 309/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 310/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 311/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 312/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 313/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 314/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 315/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 316/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 317/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 318/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 319/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 320/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 321/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 322/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 323/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 324/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 325/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 326/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 327/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 328/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 329/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 330/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 331/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 332/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 333/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 334/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 335/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 336/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 337/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 338/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 339/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 340/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 341/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 342/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 343/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 344/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 345/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7750\n",
      "Epoch 346/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 347/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7713 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 348/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7713 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 349/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7719 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 350/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 351/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 352/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7713 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 353/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 354/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 355/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4928 - val_accuracy: 0.7750\n",
      "Epoch 356/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4927 - val_accuracy: 0.7750\n",
      "Epoch 357/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 358/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 359/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 360/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 361/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 362/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 363/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 364/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 365/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 366/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7706 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 367/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4931 - val_accuracy: 0.7750\n",
      "Epoch 368/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 369/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 370/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4932 - val_accuracy: 0.7750\n",
      "Epoch 371/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 372/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 373/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 374/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 375/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 376/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 377/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 378/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 379/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 380/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 381/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 382/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 383/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4934 - val_accuracy: 0.7725\n",
      "Epoch 384/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4934 - val_accuracy: 0.7725\n",
      "Epoch 385/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 386/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 387/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 388/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 389/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4934 - val_accuracy: 0.7725\n",
      "Epoch 390/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 391/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 392/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4934 - val_accuracy: 0.7725\n",
      "Epoch 393/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 394/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 395/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 396/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 397/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 398/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 399/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 400/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 402/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 403/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 404/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 405/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 406/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 407/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 408/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 409/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 410/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 411/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 412/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 413/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 414/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 415/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 416/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 417/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 418/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 419/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 420/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 421/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 422/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 423/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 424/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 425/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 426/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 427/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4928 - val_accuracy: 0.7725\n",
      "Epoch 428/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 429/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 430/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 431/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 432/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 433/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 434/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 435/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 436/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 437/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 438/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 439/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 440/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 441/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 442/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 443/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 444/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 445/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 446/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 447/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 448/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4934 - val_accuracy: 0.7750\n",
      "Epoch 449/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4933 - val_accuracy: 0.7750\n",
      "Epoch 450/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 451/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 452/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4933 - val_accuracy: 0.7750\n",
      "Epoch 453/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4935 - val_accuracy: 0.7750\n",
      "Epoch 454/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 455/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 456/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4934 - val_accuracy: 0.7725\n",
      "Epoch 457/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4933 - val_accuracy: 0.7725\n",
      "Epoch 458/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 459/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 460/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 461/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 462/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 463/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 464/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 465/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4931 - val_accuracy: 0.7750\n",
      "Epoch 466/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7713 - val_loss: 0.4931 - val_accuracy: 0.7750\n",
      "Epoch 467/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 468/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 469/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 470/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 471/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 472/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 473/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7713 - val_loss: 0.4933 - val_accuracy: 0.7750\n",
      "Epoch 474/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4932 - val_accuracy: 0.7750\n",
      "Epoch 475/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4931 - val_accuracy: 0.7750\n",
      "Epoch 476/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4931 - val_accuracy: 0.7750\n",
      "Epoch 477/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7706 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 478/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4931 - val_accuracy: 0.7750\n",
      "Epoch 479/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4931 - val_accuracy: 0.7750\n",
      "Epoch 480/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4931 - val_accuracy: 0.7750\n",
      "Epoch 481/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 482/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 483/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "Epoch 484/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4931 - val_accuracy: 0.7750\n",
      "Epoch 485/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7706 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 486/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 487/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 488/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 489/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 490/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4932 - val_accuracy: 0.7725\n",
      "Epoch 491/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7725\n",
      "Epoch 492/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4931 - val_accuracy: 0.7750\n",
      "Epoch 493/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 494/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 495/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7706 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 496/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 497/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4929 - val_accuracy: 0.7725\n",
      "Epoch 498/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7700 - val_loss: 0.4930 - val_accuracy: 0.7725\n",
      "Epoch 499/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4929 - val_accuracy: 0.7750\n",
      "Epoch 500/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7713 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7720\n",
      "\n",
      "accuracy: 77.20%\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "The new predection is: [[0.7292234]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "The new predection is: [[0.52208966]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "The new predection is: [[0.18084483]]\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "The new predection is: [[0.6955466]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "The new predection is: [[0.770604]]\n",
      "train_accuracy: 0.7712500095367432\n",
      "train_error: 0.4671148955821991)\n",
      "test_accuracy: 0.7749999761581421\n",
      "test_error: 0.49300825595855713\n"
     ]
    }
   ],
   "source": [
    "# 1 layer and adam optimizer # underfiting\n",
    "model10 = Sequential()\n",
    "model10.add(Dense(1,input_dim=8, activation='sigmoid'))\n",
    "model10.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "history10=model10.fit(x_train,y_train,epochs=500,batch_size=128,validation_data=(x_test,y_test))\n",
    "scores = model10.evaluate(inputVariables,outputVariables)\n",
    "print(\"\\n%s: %.2f%%\" % (model10.metrics_names[1],scores[1]*100))\n",
    "print(\"The new predection is:\",model10.predict(np.array([z_score([6,142,72,45,0,38.6,0.627,50])])))\n",
    "print(\"The new predection is:\",model10.predict(np.array([z_score([1,109,30,38,83,53.3,0.193,33])])))\n",
    "print(\"The new predection is:\",model10.predict(np.array([z_score([2,112,68,22,94,34.1,0.315,26])])))\n",
    "print(\"The new predection is:\",model10.predict(np.array([z_score([2,197,70,45,543,30.5,0.158,53])])))\n",
    "print(\"The new predection is:\",model10.predict(np.array([z_score([3,180,64,25,70,34,0.271,26])])))\n",
    "tr_eval_res = model10.evaluate(x_train,y_train,verbose=0)\n",
    "eval_res= model10.evaluate(x_test,y_test,verbose=0)\n",
    "print(f'train_accuracy: {tr_eval_res[1]}')\n",
    "print(f'train_error: {tr_eval_res[0]})')\n",
    "print(f'test_accuracy: {eval_res[1]}')\n",
    "print(f'test_error: {eval_res[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7da4b1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 0.5585 - accuracy: 0.7050 - val_loss: 0.4782 - val_accuracy: 0.7767\n",
      "Epoch 2/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.4595 - accuracy: 0.7675 - val_loss: 0.4432 - val_accuracy: 0.7858\n",
      "Epoch 3/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.4222 - accuracy: 0.7912 - val_loss: 0.4307 - val_accuracy: 0.7775\n",
      "Epoch 4/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.4078 - accuracy: 0.7975 - val_loss: 0.4305 - val_accuracy: 0.7842\n",
      "Epoch 5/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.3805 - accuracy: 0.8238 - val_loss: 0.4385 - val_accuracy: 0.7700\n",
      "Epoch 6/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.3784 - accuracy: 0.8138 - val_loss: 0.4403 - val_accuracy: 0.7533\n",
      "Epoch 7/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.3568 - accuracy: 0.8313 - val_loss: 0.4148 - val_accuracy: 0.7983\n",
      "Epoch 8/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.3457 - accuracy: 0.8363 - val_loss: 0.4134 - val_accuracy: 0.8050\n",
      "Epoch 9/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.3262 - accuracy: 0.8537 - val_loss: 0.4019 - val_accuracy: 0.7950\n",
      "Epoch 10/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.3028 - accuracy: 0.8687 - val_loss: 0.4020 - val_accuracy: 0.8175\n",
      "Epoch 11/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.3082 - accuracy: 0.8700 - val_loss: 0.4289 - val_accuracy: 0.8100\n",
      "Epoch 12/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.2890 - accuracy: 0.8650 - val_loss: 0.4078 - val_accuracy: 0.8233\n",
      "Epoch 13/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2776 - accuracy: 0.8750 - val_loss: 0.4244 - val_accuracy: 0.8225\n",
      "Epoch 14/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.2502 - accuracy: 0.8988 - val_loss: 0.4141 - val_accuracy: 0.8392\n",
      "Epoch 15/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.2341 - accuracy: 0.8975 - val_loss: 0.4111 - val_accuracy: 0.8333\n",
      "Epoch 16/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.2163 - accuracy: 0.9112 - val_loss: 0.4364 - val_accuracy: 0.8133\n",
      "Epoch 17/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.2061 - accuracy: 0.9237 - val_loss: 0.4209 - val_accuracy: 0.8408\n",
      "Epoch 18/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.2107 - accuracy: 0.9175 - val_loss: 0.4315 - val_accuracy: 0.8392\n",
      "Epoch 19/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.1640 - accuracy: 0.9375 - val_loss: 0.4334 - val_accuracy: 0.8625\n",
      "Epoch 20/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.1545 - accuracy: 0.9475 - val_loss: 0.4301 - val_accuracy: 0.8575\n",
      "Epoch 21/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.1170 - accuracy: 0.9575 - val_loss: 0.4989 - val_accuracy: 0.8608\n",
      "Epoch 22/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.1324 - accuracy: 0.9475 - val_loss: 0.5132 - val_accuracy: 0.8542\n",
      "Epoch 23/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.1382 - accuracy: 0.9475 - val_loss: 0.5331 - val_accuracy: 0.8592\n",
      "Epoch 24/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.1280 - accuracy: 0.9500 - val_loss: 0.5548 - val_accuracy: 0.8542\n",
      "Epoch 25/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0981 - accuracy: 0.9675 - val_loss: 0.5317 - val_accuracy: 0.8767\n",
      "Epoch 26/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0703 - accuracy: 0.9825 - val_loss: 0.5270 - val_accuracy: 0.8725\n",
      "Epoch 27/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0506 - accuracy: 0.9887 - val_loss: 0.5821 - val_accuracy: 0.8683\n",
      "Epoch 28/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0427 - accuracy: 0.9912 - val_loss: 0.6218 - val_accuracy: 0.8692\n",
      "Epoch 29/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0467 - accuracy: 0.9837 - val_loss: 0.6079 - val_accuracy: 0.8767\n",
      "Epoch 30/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0507 - accuracy: 0.9850 - val_loss: 0.7174 - val_accuracy: 0.8550\n",
      "Epoch 31/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0917 - accuracy: 0.9663 - val_loss: 0.6466 - val_accuracy: 0.8500\n",
      "Epoch 32/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.1189 - accuracy: 0.9650 - val_loss: 0.6203 - val_accuracy: 0.8642\n",
      "Epoch 33/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.0908 - accuracy: 0.9737 - val_loss: 0.5980 - val_accuracy: 0.8658\n",
      "Epoch 34/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0422 - accuracy: 0.9862 - val_loss: 0.6600 - val_accuracy: 0.8683\n",
      "Epoch 35/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0317 - accuracy: 0.9912 - val_loss: 0.6926 - val_accuracy: 0.8608\n",
      "Epoch 36/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 0.9937 - val_loss: 0.6858 - val_accuracy: 0.8658\n",
      "Epoch 37/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0187 - accuracy: 0.9975 - val_loss: 0.6924 - val_accuracy: 0.8783\n",
      "Epoch 38/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0184 - accuracy: 0.9962 - val_loss: 0.7274 - val_accuracy: 0.8758\n",
      "Epoch 39/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.7444 - val_accuracy: 0.8692\n",
      "Epoch 40/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0123 - accuracy: 0.9950 - val_loss: 0.7518 - val_accuracy: 0.8733\n",
      "Epoch 41/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.7568 - val_accuracy: 0.8742\n",
      "Epoch 42/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 0.7745 - val_accuracy: 0.8800\n",
      "Epoch 43/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.8012 - val_accuracy: 0.8667\n",
      "Epoch 44/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0067 - accuracy: 0.9975 - val_loss: 0.8138 - val_accuracy: 0.8750\n",
      "Epoch 45/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.8467 - val_accuracy: 0.8700\n",
      "Epoch 46/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.0090 - accuracy: 0.9987 - val_loss: 0.8548 - val_accuracy: 0.8775\n",
      "Epoch 47/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0269 - accuracy: 0.9900 - val_loss: 0.8945 - val_accuracy: 0.8575\n",
      "Epoch 48/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0434 - accuracy: 0.9812 - val_loss: 0.9002 - val_accuracy: 0.8608\n",
      "Epoch 49/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.1458 - accuracy: 0.9600 - val_loss: 1.0570 - val_accuracy: 0.8025\n",
      "Epoch 50/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.2945 - accuracy: 0.9075 - val_loss: 0.7053 - val_accuracy: 0.8325\n",
      "Epoch 51/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.1037 - accuracy: 0.9613 - val_loss: 0.5185 - val_accuracy: 0.8600\n",
      "Epoch 52/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0500 - accuracy: 0.9937 - val_loss: 0.6583 - val_accuracy: 0.8717\n",
      "Epoch 53/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0291 - accuracy: 0.9962 - val_loss: 0.7275 - val_accuracy: 0.8650\n",
      "Epoch 54/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.7594 - val_accuracy: 0.8775\n",
      "Epoch 55/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0096 - accuracy: 0.9987 - val_loss: 0.8354 - val_accuracy: 0.8725\n",
      "Epoch 56/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0074 - accuracy: 0.9987 - val_loss: 0.8153 - val_accuracy: 0.8833\n",
      "Epoch 57/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.8906 - val_accuracy: 0.8717\n",
      "Epoch 58/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0080 - accuracy: 0.9987 - val_loss: 0.8616 - val_accuracy: 0.8842\n",
      "Epoch 59/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.9245 - val_accuracy: 0.8792\n",
      "Epoch 60/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 0.9962 - val_loss: 0.9139 - val_accuracy: 0.8850\n",
      "Epoch 61/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.9353 - val_accuracy: 0.8833\n",
      "Epoch 62/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.9423 - val_accuracy: 0.8892\n",
      "Epoch 63/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 0.9997 - val_accuracy: 0.8750\n",
      "Epoch 64/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.9601 - val_accuracy: 0.8792\n",
      "Epoch 65/300\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.9729 - val_accuracy: 0.8800\n",
      "Epoch 66/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 1.0159 - val_accuracy: 0.8808\n",
      "Epoch 67/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0043 - accuracy: 0.9975 - val_loss: 0.9991 - val_accuracy: 0.8900\n",
      "Epoch 68/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0063 - accuracy: 0.9975 - val_loss: 1.0641 - val_accuracy: 0.8717\n",
      "Epoch 69/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0302 - val_accuracy: 0.8833\n",
      "Epoch 70/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 1.0857 - val_accuracy: 0.8750\n",
      "Epoch 71/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0051 - accuracy: 0.9975 - val_loss: 1.0756 - val_accuracy: 0.8775\n",
      "Epoch 72/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 0.9975 - val_loss: 1.0581 - val_accuracy: 0.8825\n",
      "Epoch 73/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0081 - accuracy: 0.9987 - val_loss: 1.0763 - val_accuracy: 0.8867\n",
      "Epoch 74/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 1.0901 - val_accuracy: 0.8800\n",
      "Epoch 75/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.0975 - val_accuracy: 0.8808\n",
      "Epoch 76/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 1.1226 - val_accuracy: 0.8767\n",
      "Epoch 77/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.1171 - val_accuracy: 0.8842\n",
      "Epoch 78/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.9987 - val_loss: 1.1366 - val_accuracy: 0.8783\n",
      "Epoch 79/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 1.1312 - val_accuracy: 0.8817\n",
      "Epoch 80/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0020 - accuracy: 0.9987 - val_loss: 1.1358 - val_accuracy: 0.8842\n",
      "Epoch 81/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1464 - val_accuracy: 0.8842\n",
      "Epoch 82/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.1654 - val_accuracy: 0.8808\n",
      "Epoch 83/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1848 - val_accuracy: 0.8742\n",
      "Epoch 84/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 6.0121e-04 - accuracy: 1.0000 - val_loss: 1.1837 - val_accuracy: 0.8825\n",
      "Epoch 85/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 8.3241e-04 - accuracy: 1.0000 - val_loss: 1.2043 - val_accuracy: 0.8742\n",
      "Epoch 86/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 9.8599e-04 - accuracy: 1.0000 - val_loss: 1.1964 - val_accuracy: 0.8850\n",
      "Epoch 87/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2411 - val_accuracy: 0.8767\n",
      "Epoch 88/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0019 - accuracy: 0.9987 - val_loss: 1.2052 - val_accuracy: 0.8833\n",
      "Epoch 89/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0028 - accuracy: 0.9987 - val_loss: 1.2680 - val_accuracy: 0.8783\n",
      "Epoch 90/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 1.2330 - val_accuracy: 0.8842\n",
      "Epoch 91/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.0064 - accuracy: 0.9975 - val_loss: 1.2438 - val_accuracy: 0.8825\n",
      "Epoch 92/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.1170 - accuracy: 0.9650 - val_loss: 1.7220 - val_accuracy: 0.8125\n",
      "Epoch 93/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.3477 - accuracy: 0.9175 - val_loss: 0.8548 - val_accuracy: 0.8200\n",
      "Epoch 94/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.1471 - accuracy: 0.9425 - val_loss: 0.6096 - val_accuracy: 0.8533\n",
      "Epoch 95/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0558 - accuracy: 0.9862 - val_loss: 0.6858 - val_accuracy: 0.8617\n",
      "Epoch 96/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0204 - accuracy: 0.9975 - val_loss: 0.7559 - val_accuracy: 0.8675\n",
      "Epoch 97/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.7832 - val_accuracy: 0.8650\n",
      "Epoch 98/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.8436 - val_accuracy: 0.8733\n",
      "Epoch 99/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.8838 - val_accuracy: 0.8692\n",
      "Epoch 100/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.9513 - val_accuracy: 0.8692\n",
      "Epoch 101/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0135 - accuracy: 0.9950 - val_loss: 0.9167 - val_accuracy: 0.8692\n",
      "Epoch 102/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.9470 - val_accuracy: 0.8750\n",
      "Epoch 103/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.9757 - val_accuracy: 0.8608\n",
      "Epoch 104/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 1.0012 - val_accuracy: 0.8725\n",
      "Epoch 105/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0269 - val_accuracy: 0.8625\n",
      "Epoch 106/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 1.0295 - val_accuracy: 0.8642\n",
      "Epoch 107/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 1.0222 - val_accuracy: 0.8600\n",
      "Epoch 108/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 1.0454 - val_accuracy: 0.8667\n",
      "Epoch 109/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 1.0186 - val_accuracy: 0.8717\n",
      "Epoch 110/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0510 - val_accuracy: 0.8742\n",
      "Epoch 111/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0586 - val_accuracy: 0.8725\n",
      "Epoch 112/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 8.1300e-04 - accuracy: 1.0000 - val_loss: 1.0692 - val_accuracy: 0.8775\n",
      "Epoch 113/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 7.5840e-04 - accuracy: 1.0000 - val_loss: 1.0813 - val_accuracy: 0.8750\n",
      "Epoch 114/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 6.8153e-04 - accuracy: 1.0000 - val_loss: 1.0874 - val_accuracy: 0.8775\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 9ms/step - loss: 6.6605e-04 - accuracy: 1.0000 - val_loss: 1.1001 - val_accuracy: 0.8758\n",
      "Epoch 116/300\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 6.1597e-04 - accuracy: 1.0000 - val_loss: 1.1074 - val_accuracy: 0.8767\n",
      "Epoch 117/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 6.2262e-04 - accuracy: 1.0000 - val_loss: 1.1194 - val_accuracy: 0.8767\n",
      "Epoch 118/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 5.1385e-04 - accuracy: 1.0000 - val_loss: 1.1242 - val_accuracy: 0.8733\n",
      "Epoch 119/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 4.9344e-04 - accuracy: 1.0000 - val_loss: 1.1301 - val_accuracy: 0.8750\n",
      "Epoch 120/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 4.6386e-04 - accuracy: 1.0000 - val_loss: 1.1375 - val_accuracy: 0.8733\n",
      "Epoch 121/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 4.3455e-04 - accuracy: 1.0000 - val_loss: 1.1446 - val_accuracy: 0.8750\n",
      "Epoch 122/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 4.2222e-04 - accuracy: 1.0000 - val_loss: 1.1508 - val_accuracy: 0.8767\n",
      "Epoch 123/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 3.9990e-04 - accuracy: 1.0000 - val_loss: 1.1579 - val_accuracy: 0.8750\n",
      "Epoch 124/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 3.8462e-04 - accuracy: 1.0000 - val_loss: 1.1628 - val_accuracy: 0.8750\n",
      "Epoch 125/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 3.7315e-04 - accuracy: 1.0000 - val_loss: 1.1714 - val_accuracy: 0.8750\n",
      "Epoch 126/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.5530e-04 - accuracy: 1.0000 - val_loss: 1.1765 - val_accuracy: 0.8750\n",
      "Epoch 127/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.4090e-04 - accuracy: 1.0000 - val_loss: 1.1831 - val_accuracy: 0.8750\n",
      "Epoch 128/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.3365e-04 - accuracy: 1.0000 - val_loss: 1.1859 - val_accuracy: 0.8733\n",
      "Epoch 129/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.1392e-04 - accuracy: 1.0000 - val_loss: 1.1968 - val_accuracy: 0.8750\n",
      "Epoch 130/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 3.0089e-04 - accuracy: 1.0000 - val_loss: 1.2011 - val_accuracy: 0.8750\n",
      "Epoch 131/300\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 3.1824e-04 - accuracy: 1.0000 - val_loss: 1.2042 - val_accuracy: 0.8767\n",
      "Epoch 132/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 2.7656e-04 - accuracy: 1.0000 - val_loss: 1.2113 - val_accuracy: 0.8750\n",
      "Epoch 133/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 2.7004e-04 - accuracy: 1.0000 - val_loss: 1.2100 - val_accuracy: 0.8733\n",
      "Epoch 134/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 2.6100e-04 - accuracy: 1.0000 - val_loss: 1.2203 - val_accuracy: 0.8767\n",
      "Epoch 135/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 2.4236e-04 - accuracy: 1.0000 - val_loss: 1.2238 - val_accuracy: 0.8767\n",
      "Epoch 136/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 2.3585e-04 - accuracy: 1.0000 - val_loss: 1.2284 - val_accuracy: 0.8767\n",
      "Epoch 137/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 2.3039e-04 - accuracy: 1.0000 - val_loss: 1.2384 - val_accuracy: 0.8750\n",
      "Epoch 138/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 2.2988e-04 - accuracy: 1.0000 - val_loss: 1.2381 - val_accuracy: 0.8750\n",
      "Epoch 139/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 2.1846e-04 - accuracy: 1.0000 - val_loss: 1.2451 - val_accuracy: 0.8767\n",
      "Epoch 140/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 2.1294e-04 - accuracy: 1.0000 - val_loss: 1.2487 - val_accuracy: 0.8767\n",
      "Epoch 141/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.9747e-04 - accuracy: 1.0000 - val_loss: 1.2548 - val_accuracy: 0.8767\n",
      "Epoch 142/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 2.0136e-04 - accuracy: 1.0000 - val_loss: 1.2586 - val_accuracy: 0.8750\n",
      "Epoch 143/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.8985e-04 - accuracy: 1.0000 - val_loss: 1.2639 - val_accuracy: 0.8767\n",
      "Epoch 144/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.8861e-04 - accuracy: 1.0000 - val_loss: 1.2670 - val_accuracy: 0.8750\n",
      "Epoch 145/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.8420e-04 - accuracy: 1.0000 - val_loss: 1.2724 - val_accuracy: 0.8767\n",
      "Epoch 146/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.7156e-04 - accuracy: 1.0000 - val_loss: 1.2747 - val_accuracy: 0.8783\n",
      "Epoch 147/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.7074e-04 - accuracy: 1.0000 - val_loss: 1.2783 - val_accuracy: 0.8767\n",
      "Epoch 148/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.6817e-04 - accuracy: 1.0000 - val_loss: 1.2856 - val_accuracy: 0.8767\n",
      "Epoch 149/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.6364e-04 - accuracy: 1.0000 - val_loss: 1.2878 - val_accuracy: 0.8783\n",
      "Epoch 150/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.5462e-04 - accuracy: 1.0000 - val_loss: 1.2906 - val_accuracy: 0.8767\n",
      "Epoch 151/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.5822e-04 - accuracy: 1.0000 - val_loss: 1.2978 - val_accuracy: 0.8750\n",
      "Epoch 152/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.4272e-04 - accuracy: 1.0000 - val_loss: 1.2976 - val_accuracy: 0.8767\n",
      "Epoch 153/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.3866e-04 - accuracy: 1.0000 - val_loss: 1.3017 - val_accuracy: 0.8767\n",
      "Epoch 154/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.4385e-04 - accuracy: 1.0000 - val_loss: 1.3050 - val_accuracy: 0.8767\n",
      "Epoch 155/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.4323e-04 - accuracy: 1.0000 - val_loss: 1.3161 - val_accuracy: 0.8767\n",
      "Epoch 156/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2770e-04 - accuracy: 1.0000 - val_loss: 1.3132 - val_accuracy: 0.8767\n",
      "Epoch 157/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3213e-04 - accuracy: 1.0000 - val_loss: 1.3181 - val_accuracy: 0.8767\n",
      "Epoch 158/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2426e-04 - accuracy: 1.0000 - val_loss: 1.3219 - val_accuracy: 0.8767\n",
      "Epoch 159/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2361e-04 - accuracy: 1.0000 - val_loss: 1.3254 - val_accuracy: 0.8767\n",
      "Epoch 160/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.1655e-04 - accuracy: 1.0000 - val_loss: 1.3328 - val_accuracy: 0.8767\n",
      "Epoch 161/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.0845e-04 - accuracy: 1.0000 - val_loss: 1.3306 - val_accuracy: 0.8767\n",
      "Epoch 162/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.1474e-04 - accuracy: 1.0000 - val_loss: 1.3361 - val_accuracy: 0.8767\n",
      "Epoch 163/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1255e-04 - accuracy: 1.0000 - val_loss: 1.3410 - val_accuracy: 0.8767\n",
      "Epoch 164/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0152e-04 - accuracy: 1.0000 - val_loss: 1.3433 - val_accuracy: 0.8767\n",
      "Epoch 165/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0407e-04 - accuracy: 1.0000 - val_loss: 1.3451 - val_accuracy: 0.8767\n",
      "Epoch 166/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 9.4779e-05 - accuracy: 1.0000 - val_loss: 1.3531 - val_accuracy: 0.8767\n",
      "Epoch 167/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0019e-04 - accuracy: 1.0000 - val_loss: 1.3531 - val_accuracy: 0.8767\n",
      "Epoch 168/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 9.6425e-05 - accuracy: 1.0000 - val_loss: 1.3567 - val_accuracy: 0.8767\n",
      "Epoch 169/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 9.3159e-05 - accuracy: 1.0000 - val_loss: 1.3611 - val_accuracy: 0.8767\n",
      "Epoch 170/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 9.0249e-05 - accuracy: 1.0000 - val_loss: 1.3626 - val_accuracy: 0.8767\n",
      "Epoch 171/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 9.3099e-05 - accuracy: 1.0000 - val_loss: 1.3669 - val_accuracy: 0.8767\n",
      "Epoch 172/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 8.9383e-05 - accuracy: 1.0000 - val_loss: 1.3658 - val_accuracy: 0.8767\n",
      "Epoch 173/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 9.5469e-05 - accuracy: 1.0000 - val_loss: 1.3753 - val_accuracy: 0.8767\n",
      "Epoch 174/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 8.5542e-05 - accuracy: 1.0000 - val_loss: 1.3738 - val_accuracy: 0.8767\n",
      "Epoch 175/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 7.9097e-05 - accuracy: 1.0000 - val_loss: 1.3810 - val_accuracy: 0.8767\n",
      "Epoch 176/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 7.7999e-05 - accuracy: 1.0000 - val_loss: 1.3830 - val_accuracy: 0.8767\n",
      "Epoch 177/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 8.1001e-05 - accuracy: 1.0000 - val_loss: 1.3889 - val_accuracy: 0.8783\n",
      "Epoch 178/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 7.3651e-05 - accuracy: 1.0000 - val_loss: 1.3864 - val_accuracy: 0.8767\n",
      "Epoch 179/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 7.6123e-05 - accuracy: 1.0000 - val_loss: 1.3921 - val_accuracy: 0.8783\n",
      "Epoch 180/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 7.3262e-05 - accuracy: 1.0000 - val_loss: 1.3952 - val_accuracy: 0.8767\n",
      "Epoch 181/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 6.9997e-05 - accuracy: 1.0000 - val_loss: 1.3981 - val_accuracy: 0.8767\n",
      "Epoch 182/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 7.3339e-05 - accuracy: 1.0000 - val_loss: 1.4009 - val_accuracy: 0.8767\n",
      "Epoch 183/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 7.1583e-05 - accuracy: 1.0000 - val_loss: 1.4069 - val_accuracy: 0.8767\n",
      "Epoch 184/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 6.3517e-05 - accuracy: 1.0000 - val_loss: 1.4042 - val_accuracy: 0.8767\n",
      "Epoch 185/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 6.6988e-05 - accuracy: 1.0000 - val_loss: 1.4112 - val_accuracy: 0.8767\n",
      "Epoch 186/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 7.0331e-05 - accuracy: 1.0000 - val_loss: 1.4127 - val_accuracy: 0.8767\n",
      "Epoch 187/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 6.2988e-05 - accuracy: 1.0000 - val_loss: 1.4139 - val_accuracy: 0.8767\n",
      "Epoch 188/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 5.9248e-05 - accuracy: 1.0000 - val_loss: 1.4183 - val_accuracy: 0.8767\n",
      "Epoch 189/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 5.7134e-05 - accuracy: 1.0000 - val_loss: 1.4209 - val_accuracy: 0.8767\n",
      "Epoch 190/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 6.0714e-05 - accuracy: 1.0000 - val_loss: 1.4261 - val_accuracy: 0.8767\n",
      "Epoch 191/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 5.6716e-05 - accuracy: 1.0000 - val_loss: 1.4269 - val_accuracy: 0.8767\n",
      "Epoch 192/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 5.5864e-05 - accuracy: 1.0000 - val_loss: 1.4298 - val_accuracy: 0.8767\n",
      "Epoch 193/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 5.4552e-05 - accuracy: 1.0000 - val_loss: 1.4327 - val_accuracy: 0.8767\n",
      "Epoch 194/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 5.2568e-05 - accuracy: 1.0000 - val_loss: 1.4354 - val_accuracy: 0.8767\n",
      "Epoch 195/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 5.1952e-05 - accuracy: 1.0000 - val_loss: 1.4391 - val_accuracy: 0.8767\n",
      "Epoch 196/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 4.9732e-05 - accuracy: 1.0000 - val_loss: 1.4425 - val_accuracy: 0.8767\n",
      "Epoch 197/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 5.1121e-05 - accuracy: 1.0000 - val_loss: 1.4439 - val_accuracy: 0.8767\n",
      "Epoch 198/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 4.7874e-05 - accuracy: 1.0000 - val_loss: 1.4464 - val_accuracy: 0.8767\n",
      "Epoch 199/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 4.6307e-05 - accuracy: 1.0000 - val_loss: 1.4477 - val_accuracy: 0.8767\n",
      "Epoch 200/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 4.5829e-05 - accuracy: 1.0000 - val_loss: 1.4524 - val_accuracy: 0.8767\n",
      "Epoch 201/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 4.6109e-05 - accuracy: 1.0000 - val_loss: 1.4540 - val_accuracy: 0.8767\n",
      "Epoch 202/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 4.6028e-05 - accuracy: 1.0000 - val_loss: 1.4568 - val_accuracy: 0.8767\n",
      "Epoch 203/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 4.3297e-05 - accuracy: 1.0000 - val_loss: 1.4590 - val_accuracy: 0.8767\n",
      "Epoch 204/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 4.2200e-05 - accuracy: 1.0000 - val_loss: 1.4634 - val_accuracy: 0.8767\n",
      "Epoch 205/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 4.1574e-05 - accuracy: 1.0000 - val_loss: 1.4657 - val_accuracy: 0.8767\n",
      "Epoch 206/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 4.1408e-05 - accuracy: 1.0000 - val_loss: 1.4681 - val_accuracy: 0.8767\n",
      "Epoch 207/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 4.0182e-05 - accuracy: 1.0000 - val_loss: 1.4689 - val_accuracy: 0.8783\n",
      "Epoch 208/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.9801e-05 - accuracy: 1.0000 - val_loss: 1.4731 - val_accuracy: 0.8808\n",
      "Epoch 209/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.8869e-05 - accuracy: 1.0000 - val_loss: 1.4750 - val_accuracy: 0.8767\n",
      "Epoch 210/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.9552e-05 - accuracy: 1.0000 - val_loss: 1.4784 - val_accuracy: 0.8767\n",
      "Epoch 211/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.7674e-05 - accuracy: 1.0000 - val_loss: 1.4796 - val_accuracy: 0.8767\n",
      "Epoch 212/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.8321e-05 - accuracy: 1.0000 - val_loss: 1.4862 - val_accuracy: 0.8767\n",
      "Epoch 213/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 3.5529e-05 - accuracy: 1.0000 - val_loss: 1.4850 - val_accuracy: 0.8767\n",
      "Epoch 214/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 3.6745e-05 - accuracy: 1.0000 - val_loss: 1.4876 - val_accuracy: 0.8767\n",
      "Epoch 215/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.4325e-05 - accuracy: 1.0000 - val_loss: 1.4900 - val_accuracy: 0.8783\n",
      "Epoch 216/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.5347e-05 - accuracy: 1.0000 - val_loss: 1.4909 - val_accuracy: 0.8783\n",
      "Epoch 217/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 3.3480e-05 - accuracy: 1.0000 - val_loss: 1.4967 - val_accuracy: 0.8767\n",
      "Epoch 218/300\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 3.2001e-05 - accuracy: 1.0000 - val_loss: 1.4978 - val_accuracy: 0.8783\n",
      "Epoch 219/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 3.4032e-05 - accuracy: 1.0000 - val_loss: 1.4981 - val_accuracy: 0.8783\n",
      "Epoch 220/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.1923e-05 - accuracy: 1.0000 - val_loss: 1.5064 - val_accuracy: 0.8792\n",
      "Epoch 221/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 3.3408e-05 - accuracy: 1.0000 - val_loss: 1.5041 - val_accuracy: 0.8783\n",
      "Epoch 222/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.1636e-05 - accuracy: 1.0000 - val_loss: 1.5088 - val_accuracy: 0.8808\n",
      "Epoch 223/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 2.9740e-05 - accuracy: 1.0000 - val_loss: 1.5120 - val_accuracy: 0.8808\n",
      "Epoch 224/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 2.8612e-05 - accuracy: 1.0000 - val_loss: 1.5107 - val_accuracy: 0.8800\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 11ms/step - loss: 2.8657e-05 - accuracy: 1.0000 - val_loss: 1.5151 - val_accuracy: 0.8783\n",
      "Epoch 226/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 2.8910e-05 - accuracy: 1.0000 - val_loss: 1.5198 - val_accuracy: 0.8808\n",
      "Epoch 227/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 2.7546e-05 - accuracy: 1.0000 - val_loss: 1.5202 - val_accuracy: 0.8808\n",
      "Epoch 228/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 2.7690e-05 - accuracy: 1.0000 - val_loss: 1.5228 - val_accuracy: 0.8783\n",
      "Epoch 229/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 2.6853e-05 - accuracy: 1.0000 - val_loss: 1.5266 - val_accuracy: 0.8808\n",
      "Epoch 230/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 2.8294e-05 - accuracy: 1.0000 - val_loss: 1.5245 - val_accuracy: 0.8800\n",
      "Epoch 231/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 2.9239e-05 - accuracy: 1.0000 - val_loss: 1.5348 - val_accuracy: 0.8792\n",
      "Epoch 232/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 2.7066e-05 - accuracy: 1.0000 - val_loss: 1.5305 - val_accuracy: 0.8800\n",
      "Epoch 233/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 2.5201e-05 - accuracy: 1.0000 - val_loss: 1.5353 - val_accuracy: 0.8808\n",
      "Epoch 234/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 2.3620e-05 - accuracy: 1.0000 - val_loss: 1.5364 - val_accuracy: 0.8800\n",
      "Epoch 235/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 2.3578e-05 - accuracy: 1.0000 - val_loss: 1.5394 - val_accuracy: 0.8808\n",
      "Epoch 236/300\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 2.2966e-05 - accuracy: 1.0000 - val_loss: 1.5414 - val_accuracy: 0.8800\n",
      "Epoch 237/300\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 2.3992e-05 - accuracy: 1.0000 - val_loss: 1.5402 - val_accuracy: 0.8800\n",
      "Epoch 238/300\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 2.1329e-05 - accuracy: 1.0000 - val_loss: 1.5496 - val_accuracy: 0.8808\n",
      "Epoch 239/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 2.2473e-05 - accuracy: 1.0000 - val_loss: 1.5482 - val_accuracy: 0.8800\n",
      "Epoch 240/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 2.1902e-05 - accuracy: 1.0000 - val_loss: 1.5524 - val_accuracy: 0.8808\n",
      "Epoch 241/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 2.1410e-05 - accuracy: 1.0000 - val_loss: 1.5532 - val_accuracy: 0.8825\n",
      "Epoch 242/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 2.1294e-05 - accuracy: 1.0000 - val_loss: 1.5579 - val_accuracy: 0.8808\n",
      "Epoch 243/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 2.0254e-05 - accuracy: 1.0000 - val_loss: 1.5582 - val_accuracy: 0.8800\n",
      "Epoch 244/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 2.0831e-05 - accuracy: 1.0000 - val_loss: 1.5583 - val_accuracy: 0.8800\n",
      "Epoch 245/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 2.0024e-05 - accuracy: 1.0000 - val_loss: 1.5645 - val_accuracy: 0.8808\n",
      "Epoch 246/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.9212e-05 - accuracy: 1.0000 - val_loss: 1.5648 - val_accuracy: 0.8825\n",
      "Epoch 247/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.9681e-05 - accuracy: 1.0000 - val_loss: 1.5679 - val_accuracy: 0.8808\n",
      "Epoch 248/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.9650e-05 - accuracy: 1.0000 - val_loss: 1.5691 - val_accuracy: 0.8800\n",
      "Epoch 249/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.8584e-05 - accuracy: 1.0000 - val_loss: 1.5735 - val_accuracy: 0.8808\n",
      "Epoch 250/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.7549e-05 - accuracy: 1.0000 - val_loss: 1.5728 - val_accuracy: 0.8825\n",
      "Epoch 251/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.8668e-05 - accuracy: 1.0000 - val_loss: 1.5780 - val_accuracy: 0.8808\n",
      "Epoch 252/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.7692e-05 - accuracy: 1.0000 - val_loss: 1.5793 - val_accuracy: 0.8825\n",
      "Epoch 253/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.8191e-05 - accuracy: 1.0000 - val_loss: 1.5792 - val_accuracy: 0.8800\n",
      "Epoch 254/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.8339e-05 - accuracy: 1.0000 - val_loss: 1.5869 - val_accuracy: 0.8808\n",
      "Epoch 255/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.6586e-05 - accuracy: 1.0000 - val_loss: 1.5844 - val_accuracy: 0.8825\n",
      "Epoch 256/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 1.6120e-05 - accuracy: 1.0000 - val_loss: 1.5877 - val_accuracy: 0.8825\n",
      "Epoch 257/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.5870e-05 - accuracy: 1.0000 - val_loss: 1.5909 - val_accuracy: 0.8825\n",
      "Epoch 258/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.5445e-05 - accuracy: 1.0000 - val_loss: 1.5939 - val_accuracy: 0.8825\n",
      "Epoch 259/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 1.5722e-05 - accuracy: 1.0000 - val_loss: 1.5960 - val_accuracy: 0.8825\n",
      "Epoch 260/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.6048e-05 - accuracy: 1.0000 - val_loss: 1.5971 - val_accuracy: 0.8800\n",
      "Epoch 261/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.5219e-05 - accuracy: 1.0000 - val_loss: 1.5987 - val_accuracy: 0.8825\n",
      "Epoch 262/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.4500e-05 - accuracy: 1.0000 - val_loss: 1.6014 - val_accuracy: 0.8825\n",
      "Epoch 263/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.4072e-05 - accuracy: 1.0000 - val_loss: 1.6026 - val_accuracy: 0.8800\n",
      "Epoch 264/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.4058e-05 - accuracy: 1.0000 - val_loss: 1.6053 - val_accuracy: 0.8825\n",
      "Epoch 265/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3703e-05 - accuracy: 1.0000 - val_loss: 1.6098 - val_accuracy: 0.8825\n",
      "Epoch 266/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.4062e-05 - accuracy: 1.0000 - val_loss: 1.6099 - val_accuracy: 0.8825\n",
      "Epoch 267/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.3499e-05 - accuracy: 1.0000 - val_loss: 1.6125 - val_accuracy: 0.8800\n",
      "Epoch 268/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.3089e-05 - accuracy: 1.0000 - val_loss: 1.6147 - val_accuracy: 0.8825\n",
      "Epoch 269/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.2977e-05 - accuracy: 1.0000 - val_loss: 1.6181 - val_accuracy: 0.8825\n",
      "Epoch 270/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2265e-05 - accuracy: 1.0000 - val_loss: 1.6196 - val_accuracy: 0.8825\n",
      "Epoch 271/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2421e-05 - accuracy: 1.0000 - val_loss: 1.6236 - val_accuracy: 0.8825\n",
      "Epoch 272/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.1912e-05 - accuracy: 1.0000 - val_loss: 1.6228 - val_accuracy: 0.8825\n",
      "Epoch 273/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2090e-05 - accuracy: 1.0000 - val_loss: 1.6275 - val_accuracy: 0.8825\n",
      "Epoch 274/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.2117e-05 - accuracy: 1.0000 - val_loss: 1.6274 - val_accuracy: 0.8800\n",
      "Epoch 275/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.1779e-05 - accuracy: 1.0000 - val_loss: 1.6296 - val_accuracy: 0.8800\n",
      "Epoch 276/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.1095e-05 - accuracy: 1.0000 - val_loss: 1.6347 - val_accuracy: 0.8825\n",
      "Epoch 277/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1.1053e-05 - accuracy: 1.0000 - val_loss: 1.6363 - val_accuracy: 0.8825\n",
      "Epoch 278/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0712e-05 - accuracy: 1.0000 - val_loss: 1.6367 - val_accuracy: 0.8800\n",
      "Epoch 279/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0739e-05 - accuracy: 1.0000 - val_loss: 1.6401 - val_accuracy: 0.8825\n",
      "Epoch 280/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1.0688e-05 - accuracy: 1.0000 - val_loss: 1.6397 - val_accuracy: 0.8825\n",
      "Epoch 281/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.0302e-05 - accuracy: 1.0000 - val_loss: 1.6437 - val_accuracy: 0.8825\n",
      "Epoch 282/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 1.0223e-05 - accuracy: 1.0000 - val_loss: 1.6467 - val_accuracy: 0.8825\n",
      "Epoch 283/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 9.8921e-06 - accuracy: 1.0000 - val_loss: 1.6473 - val_accuracy: 0.8800\n",
      "Epoch 284/300\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 9.9897e-06 - accuracy: 1.0000 - val_loss: 1.6516 - val_accuracy: 0.8825\n",
      "Epoch 285/300\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 9.9270e-06 - accuracy: 1.0000 - val_loss: 1.6509 - val_accuracy: 0.8825\n",
      "Epoch 286/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 9.3466e-06 - accuracy: 1.0000 - val_loss: 1.6541 - val_accuracy: 0.8783\n",
      "Epoch 287/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 9.2656e-06 - accuracy: 1.0000 - val_loss: 1.6571 - val_accuracy: 0.8825\n",
      "Epoch 288/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 9.0375e-06 - accuracy: 1.0000 - val_loss: 1.6592 - val_accuracy: 0.8825\n",
      "Epoch 289/300\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 9.1376e-06 - accuracy: 1.0000 - val_loss: 1.6619 - val_accuracy: 0.8783\n",
      "Epoch 290/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 8.7702e-06 - accuracy: 1.0000 - val_loss: 1.6641 - val_accuracy: 0.8825\n",
      "Epoch 291/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 8.4819e-06 - accuracy: 1.0000 - val_loss: 1.6648 - val_accuracy: 0.8783\n",
      "Epoch 292/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 8.5807e-06 - accuracy: 1.0000 - val_loss: 1.6677 - val_accuracy: 0.8783\n",
      "Epoch 293/300\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 8.3858e-06 - accuracy: 1.0000 - val_loss: 1.6703 - val_accuracy: 0.8808\n",
      "Epoch 294/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 8.4583e-06 - accuracy: 1.0000 - val_loss: 1.6717 - val_accuracy: 0.8783\n",
      "Epoch 295/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 8.4370e-06 - accuracy: 1.0000 - val_loss: 1.6730 - val_accuracy: 0.8783\n",
      "Epoch 296/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 8.2700e-06 - accuracy: 1.0000 - val_loss: 1.6776 - val_accuracy: 0.8808\n",
      "Epoch 297/300\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 7.8053e-06 - accuracy: 1.0000 - val_loss: 1.6781 - val_accuracy: 0.8783\n",
      "Epoch 298/300\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 7.8404e-06 - accuracy: 1.0000 - val_loss: 1.6801 - val_accuracy: 0.8783\n",
      "Epoch 299/300\n",
      "27/27 [==============================] - 1s 21ms/step - loss: 7.7085e-06 - accuracy: 1.0000 - val_loss: 1.6847 - val_accuracy: 0.8808\n",
      "Epoch 300/300\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 7.6649e-06 - accuracy: 1.0000 - val_loss: 1.6819 - val_accuracy: 0.8758\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.9255\n",
      "\n",
      "accuracy: 92.55%\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "The new predection is: [[1.]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "The new predection is: [[5.484031e-13]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "The new predection is: [[1.5958825e-05]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "The new predection is: [[1.]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "The new predection is: [[3.1257157e-05]]\n",
      "train_accuracy: 1.0\n",
      "train_error: 7.077058398863301e-06)\n",
      "test_accuracy: 0.8758333325386047\n",
      "test_error: 1.6819207668304443\n"
     ]
    }
   ],
   "source": [
    "#overfiting\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputVariables, outputVariables, test_size=0.6, random_state=42)\n",
    "model11 = Sequential()\n",
    "model11.add(Dense(320,input_dim=8, activation='relu'))\n",
    "model11.add(Dense(160, activation='relu'))\n",
    "model11.add(Dense(80, activation='relu'))\n",
    "model11.add(Dense(20, activation='relu'))\n",
    "model11.add(Dense(1, activation='sigmoid'))\n",
    "model11.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "history11=model11.fit(x_train,y_train,epochs=300,batch_size=30,validation_data=(x_test,y_test))\n",
    "scores = model11.evaluate(inputVariables,outputVariables)\n",
    "print(\"\\n%s: %.2f%%\" % (model11.metrics_names[1],scores[1]*100))\n",
    "print(\"The new predection is:\",model11.predict(np.array([z_score([6,142,72,45,0,38.6,0.627,50])])))\n",
    "print(\"The new predection is:\",model11.predict(np.array([z_score([1,109,30,38,83,53.3,0.193,33])])))\n",
    "print(\"The new predection is:\",model11.predict(np.array([z_score([2,112,68,22,94,34.1,0.315,26])])))\n",
    "print(\"The new predection is:\",model11.predict(np.array([z_score([2,197,70,45,543,30.5,0.158,53])])))\n",
    "print(\"The new predection is:\",model11.predict(np.array([z_score([3,180,64,25,70,34,0.271,26])])))\n",
    "tr_eval_res = model11.evaluate(x_train,y_train,verbose=0)\n",
    "eval_res= model11.evaluate(x_test,y_test,verbose=0)\n",
    "print(f'train_accuracy: {tr_eval_res[1]}')\n",
    "print(f'train_error: {tr_eval_res[0]})')\n",
    "print(f'test_accuracy: {eval_res[1]}')\n",
    "print(f'test_error: {eval_res[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dd0ca1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 49ms/step - loss: 0.5736 - accuracy: 0.7425 - val_loss: 0.5198 - val_accuracy: 0.7094\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.4789 - accuracy: 0.7600 - val_loss: 0.4527 - val_accuracy: 0.7744\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.4461 - accuracy: 0.7825 - val_loss: 0.4551 - val_accuracy: 0.7775\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.4175 - accuracy: 0.8050 - val_loss: 0.4455 - val_accuracy: 0.7794\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.3970 - accuracy: 0.8050 - val_loss: 0.4472 - val_accuracy: 0.7912\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.3867 - accuracy: 0.8150 - val_loss: 0.4453 - val_accuracy: 0.7856\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.3626 - accuracy: 0.8275 - val_loss: 0.4465 - val_accuracy: 0.7881\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.3543 - accuracy: 0.8375 - val_loss: 0.4480 - val_accuracy: 0.7819\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.3274 - accuracy: 0.8425 - val_loss: 0.4654 - val_accuracy: 0.7919\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.3083 - accuracy: 0.8575 - val_loss: 0.4702 - val_accuracy: 0.7925\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.2817 - accuracy: 0.8925 - val_loss: 0.4934 - val_accuracy: 0.7881\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.2778 - accuracy: 0.8575 - val_loss: 0.5106 - val_accuracy: 0.7931\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.2873 - accuracy: 0.8850 - val_loss: 0.5115 - val_accuracy: 0.7956\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.2622 - accuracy: 0.8875 - val_loss: 0.5160 - val_accuracy: 0.7900\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.2255 - accuracy: 0.9100 - val_loss: 0.5447 - val_accuracy: 0.8025\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.2002 - accuracy: 0.9225 - val_loss: 0.5631 - val_accuracy: 0.7987\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.1682 - accuracy: 0.9350 - val_loss: 0.5926 - val_accuracy: 0.7969\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.1573 - accuracy: 0.9500 - val_loss: 0.6383 - val_accuracy: 0.7975\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.1538 - accuracy: 0.9450 - val_loss: 0.6848 - val_accuracy: 0.7937\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.1473 - accuracy: 0.9400 - val_loss: 0.6924 - val_accuracy: 0.8112\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.1204 - accuracy: 0.9550 - val_loss: 0.7553 - val_accuracy: 0.8012\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.1047 - accuracy: 0.9600 - val_loss: 0.7762 - val_accuracy: 0.8056\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0912 - accuracy: 0.9700 - val_loss: 0.7980 - val_accuracy: 0.8056\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0750 - accuracy: 0.9675 - val_loss: 0.8632 - val_accuracy: 0.8012\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0881 - accuracy: 0.9725 - val_loss: 0.8982 - val_accuracy: 0.8069\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.1089 - accuracy: 0.9575 - val_loss: 0.9232 - val_accuracy: 0.8056\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.1095 - accuracy: 0.9625 - val_loss: 0.9815 - val_accuracy: 0.8031\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0664 - accuracy: 0.9750 - val_loss: 0.9529 - val_accuracy: 0.8050\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0915 - accuracy: 0.9775 - val_loss: 1.0269 - val_accuracy: 0.8163\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0582 - accuracy: 0.9800 - val_loss: 1.0308 - val_accuracy: 0.8156\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0455 - accuracy: 0.9850 - val_loss: 1.0359 - val_accuracy: 0.8144\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.0352 - accuracy: 0.9950 - val_loss: 1.1042 - val_accuracy: 0.8100\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.0252 - accuracy: 0.9975 - val_loss: 1.1728 - val_accuracy: 0.8094\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0262 - accuracy: 0.9925 - val_loss: 1.2581 - val_accuracy: 0.8056\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0257 - accuracy: 0.9925 - val_loss: 1.2344 - val_accuracy: 0.8037\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0433 - accuracy: 0.9800 - val_loss: 1.2474 - val_accuracy: 0.8025\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0364 - accuracy: 0.9950 - val_loss: 1.2883 - val_accuracy: 0.8062\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 1.3108 - val_accuracy: 0.8156\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0202 - accuracy: 0.9950 - val_loss: 1.2825 - val_accuracy: 0.8125\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0468 - accuracy: 0.9825 - val_loss: 1.3497 - val_accuracy: 0.7875\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.0245 - accuracy: 0.9975 - val_loss: 1.3001 - val_accuracy: 0.8050\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0221 - accuracy: 0.9950 - val_loss: 1.3964 - val_accuracy: 0.8169\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 1.3566 - val_accuracy: 0.8181\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.3916 - val_accuracy: 0.8094\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.4241 - val_accuracy: 0.8181\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.4438 - val_accuracy: 0.8175\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.4816 - val_accuracy: 0.8144\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.4973 - val_accuracy: 0.8156\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.5237 - val_accuracy: 0.8156\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.5362 - val_accuracy: 0.8131\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5607 - val_accuracy: 0.8156\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.5816 - val_accuracy: 0.8156\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6000 - val_accuracy: 0.8138\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6164 - val_accuracy: 0.8138\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6278 - val_accuracy: 0.8156\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6544 - val_accuracy: 0.8138\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6692 - val_accuracy: 0.8138\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6793 - val_accuracy: 0.8138\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6937 - val_accuracy: 0.8138\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7077 - val_accuracy: 0.8138\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7379 - val_accuracy: 0.8175\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7285 - val_accuracy: 0.8125\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7521 - val_accuracy: 0.8138\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7631 - val_accuracy: 0.8138\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 9.8980e-04 - accuracy: 1.0000 - val_loss: 1.7745 - val_accuracy: 0.8138\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 9.9694e-04 - accuracy: 1.0000 - val_loss: 1.7809 - val_accuracy: 0.8138\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 8.9356e-04 - accuracy: 1.0000 - val_loss: 1.8001 - val_accuracy: 0.8138\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 8.5937e-04 - accuracy: 1.0000 - val_loss: 1.8065 - val_accuracy: 0.8138\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 8.4674e-04 - accuracy: 1.0000 - val_loss: 1.8205 - val_accuracy: 0.8138\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 7.7983e-04 - accuracy: 1.0000 - val_loss: 1.8263 - val_accuracy: 0.8138\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 7.3891e-04 - accuracy: 1.0000 - val_loss: 1.8353 - val_accuracy: 0.8125\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 7.3432e-04 - accuracy: 1.0000 - val_loss: 1.8477 - val_accuracy: 0.8138\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 7.3274e-04 - accuracy: 1.0000 - val_loss: 1.8566 - val_accuracy: 0.8138\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8892 - val_accuracy: 0.8163\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.0389 - accuracy: 0.9900 - val_loss: 1.7373 - val_accuracy: 0.8050\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.0471 - accuracy: 0.9825 - val_loss: 1.8342 - val_accuracy: 0.8087\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.1631 - accuracy: 0.9600 - val_loss: 2.1381 - val_accuracy: 0.7575\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.1892 - accuracy: 0.9475 - val_loss: 1.2470 - val_accuracy: 0.8012\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.1387 - accuracy: 0.9550 - val_loss: 1.0756 - val_accuracy: 0.7937\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0940 - accuracy: 0.9600 - val_loss: 1.0146 - val_accuracy: 0.8006\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0738 - accuracy: 0.9850 - val_loss: 1.1944 - val_accuracy: 0.7856\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0773 - accuracy: 0.9825 - val_loss: 1.3502 - val_accuracy: 0.7994\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0540 - accuracy: 0.9775 - val_loss: 1.3036 - val_accuracy: 0.7981\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0336 - accuracy: 0.9900 - val_loss: 1.2547 - val_accuracy: 0.8050\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.3857 - val_accuracy: 0.8094\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.4245 - val_accuracy: 0.8069\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.4872 - val_accuracy: 0.8031\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.5202 - val_accuracy: 0.7969\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5674 - val_accuracy: 0.7962\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.5992 - val_accuracy: 0.7994\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6312 - val_accuracy: 0.8012\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6564 - val_accuracy: 0.7981\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6793 - val_accuracy: 0.7994\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7046 - val_accuracy: 0.7994\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7300 - val_accuracy: 0.7981\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7494 - val_accuracy: 0.7962\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7600 - val_accuracy: 0.7994\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.7904 - val_accuracy: 0.7981\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.8056 - val_accuracy: 0.7944\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 9.6431e-04 - accuracy: 1.0000 - val_loss: 1.8222 - val_accuracy: 0.7925\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4579 - accuracy: 0.8340\n",
      "\n",
      "accuracy: 83.40%\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "The new predection is: [[0.9999622]]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "The new predection is: [[1.6363518e-16]]\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "The new predection is: [[0.00661867]]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "The new predection is: [[3.1753912e-05]]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "The new predection is: [[0.00091559]]\n",
      "train_accuracy: 1.0\n",
      "train_error: 0.0008888947777450085)\n",
      "test_accuracy: 0.7925000190734863\n",
      "test_error: 1.822212815284729\n"
     ]
    }
   ],
   "source": [
    "#overfiting\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputVariables, outputVariables, test_size=0.8, random_state=42)\n",
    "model12 = Sequential()\n",
    "model12.add(Dense(320,input_dim=8, activation='relu'))\n",
    "model12.add(Dense(160, activation='relu'))\n",
    "model12.add(Dense(80, activation='relu'))\n",
    "model12.add(Dense(20, activation='relu'))\n",
    "model12.add(Dense(1, activation='sigmoid'))\n",
    "model12.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "history12=model12.fit(x_train,y_train,epochs=100,batch_size=30,validation_data=(x_test,y_test))\n",
    "scores = model12.evaluate(inputVariables,outputVariables)\n",
    "print(\"\\n%s: %.2f%%\" % (model12.metrics_names[1],scores[1]*100))\n",
    "print(\"The new predection is:\",model12.predict(np.array([z_score([6,142,72,45,0,38.6,0.627,50])])))\n",
    "print(\"The new predection is:\",model12.predict(np.array([z_score([1,109,30,38,83,53.3,0.193,33])])))\n",
    "print(\"The new predection is:\",model12.predict(np.array([z_score([2,112,68,22,94,34.1,0.315,26])])))\n",
    "print(\"The new predection is:\",model12.predict(np.array([z_score([2,197,70,45,543,30.5,0.158,53])])))\n",
    "print(\"The new predection is:\",model12.predict(np.array([z_score([3,180,64,25,70,34,0.271,26])])))\n",
    "tr_eval_res = model12.evaluate(x_train,y_train,verbose=0)\n",
    "eval_res= model12.evaluate(x_test,y_test,verbose=0)\n",
    "print(f'train_accuracy: {tr_eval_res[1]}')\n",
    "print(f'train_error: {tr_eval_res[0]})')\n",
    "print(f'test_accuracy: {eval_res[1]}')\n",
    "print(f'test_error: {eval_res[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87a453f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 1s 31ms/step - loss: 1.2342 - accuracy: 0.3398 - val_loss: 1.0081 - val_accuracy: 0.3719\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.9274 - accuracy: 0.3992 - val_loss: 0.7371 - val_accuracy: 0.5312\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6689 - accuracy: 0.6016 - val_loss: 0.5941 - val_accuracy: 0.6969\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5497 - accuracy: 0.7352 - val_loss: 0.5471 - val_accuracy: 0.7125\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5059 - accuracy: 0.7609 - val_loss: 0.5329 - val_accuracy: 0.7344\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4884 - accuracy: 0.7617 - val_loss: 0.5266 - val_accuracy: 0.7281\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.7633 - val_loss: 0.5223 - val_accuracy: 0.7281\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.7625 - val_loss: 0.5193 - val_accuracy: 0.7250\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7586 - val_loss: 0.5171 - val_accuracy: 0.7219\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7711 - val_loss: 0.5146 - val_accuracy: 0.7250\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7742 - val_loss: 0.5132 - val_accuracy: 0.7281\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7773 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4633 - accuracy: 0.7766 - val_loss: 0.5108 - val_accuracy: 0.7375\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4624 - accuracy: 0.7797 - val_loss: 0.5096 - val_accuracy: 0.7375\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.5093 - val_accuracy: 0.7375\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4612 - accuracy: 0.7812 - val_loss: 0.5087 - val_accuracy: 0.7344\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4606 - accuracy: 0.7812 - val_loss: 0.5080 - val_accuracy: 0.7375\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7828 - val_loss: 0.5078 - val_accuracy: 0.7375\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.7828 - val_loss: 0.5074 - val_accuracy: 0.7375\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4596 - accuracy: 0.7828 - val_loss: 0.5069 - val_accuracy: 0.7375\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.7820 - val_loss: 0.5070 - val_accuracy: 0.7344\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4592 - accuracy: 0.7820 - val_loss: 0.5070 - val_accuracy: 0.7344\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4592 - accuracy: 0.7820 - val_loss: 0.5071 - val_accuracy: 0.7344\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7805 - val_loss: 0.5068 - val_accuracy: 0.7344\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4587 - accuracy: 0.7805 - val_loss: 0.5067 - val_accuracy: 0.7344\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7805 - val_loss: 0.5067 - val_accuracy: 0.7375\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4587 - accuracy: 0.7797 - val_loss: 0.5063 - val_accuracy: 0.7344\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.7828 - val_loss: 0.5064 - val_accuracy: 0.7344\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4585 - accuracy: 0.7844 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7852 - val_loss: 0.5064 - val_accuracy: 0.7406\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4585 - accuracy: 0.7852 - val_loss: 0.5064 - val_accuracy: 0.7406\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7852 - val_loss: 0.5065 - val_accuracy: 0.7406\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7852 - val_loss: 0.5062 - val_accuracy: 0.7406\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7852 - val_loss: 0.5062 - val_accuracy: 0.7406\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7852 - val_loss: 0.5060 - val_accuracy: 0.7406\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4584 - accuracy: 0.7852 - val_loss: 0.5065 - val_accuracy: 0.7406\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7852 - val_loss: 0.5065 - val_accuracy: 0.7406\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7844 - val_loss: 0.5064 - val_accuracy: 0.7406\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7844 - val_loss: 0.5063 - val_accuracy: 0.7406\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7852 - val_loss: 0.5062 - val_accuracy: 0.7406\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7844 - val_loss: 0.5063 - val_accuracy: 0.7406\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7844 - val_loss: 0.5063 - val_accuracy: 0.7406\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7844 - val_loss: 0.5062 - val_accuracy: 0.7406\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7836 - val_loss: 0.5061 - val_accuracy: 0.7406\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7836 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7844 - val_loss: 0.5062 - val_accuracy: 0.7406\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7836 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7836 - val_loss: 0.5062 - val_accuracy: 0.7406\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7836 - val_loss: 0.5061 - val_accuracy: 0.7406\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7836 - val_loss: 0.5058 - val_accuracy: 0.7375\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7828 - val_loss: 0.5064 - val_accuracy: 0.7375\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5065 - val_accuracy: 0.7375\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7836 - val_loss: 0.5061 - val_accuracy: 0.7375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7836 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7820 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4581 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7805 - val_loss: 0.5057 - val_accuracy: 0.7375\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5064 - val_accuracy: 0.7375\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4583 - accuracy: 0.7820 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4583 - accuracy: 0.7836 - val_loss: 0.5060 - val_accuracy: 0.7406\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5058 - val_accuracy: 0.7375\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7836 - val_loss: 0.5061 - val_accuracy: 0.7406\n",
      "Epoch 116/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7820 - val_loss: 0.5058 - val_accuracy: 0.7375\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7820 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 125/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5064 - val_accuracy: 0.7375\n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7805 - val_loss: 0.5057 - val_accuracy: 0.7375\n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7805 - val_loss: 0.5058 - val_accuracy: 0.7406\n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7805 - val_loss: 0.5058 - val_accuracy: 0.7406\n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7820 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4581 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7828 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 138/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.5057 - val_accuracy: 0.7375\n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.7805 - val_loss: 0.5058 - val_accuracy: 0.7375\n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4581 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.7836 - val_loss: 0.5060 - val_accuracy: 0.7406\n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7836 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 155/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7820 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 158/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7820 - val_loss: 0.5058 - val_accuracy: 0.7406\n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 164/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5064 - val_accuracy: 0.7406\n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7836 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 168/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7836 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5058 - val_accuracy: 0.7375\n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5058 - val_accuracy: 0.7375\n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7820 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 180/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4583 - accuracy: 0.7836 - val_loss: 0.5064 - val_accuracy: 0.7375\n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 186/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4582 - accuracy: 0.7805 - val_loss: 0.5058 - val_accuracy: 0.7375\n",
      "Epoch 187/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 188/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 189/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 190/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4581 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 191/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4583 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 192/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5060 - val_accuracy: 0.7375\n",
      "Epoch 193/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5058 - val_accuracy: 0.7375\n",
      "Epoch 194/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5061 - val_accuracy: 0.7375\n",
      "Epoch 195/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7828 - val_loss: 0.5062 - val_accuracy: 0.7375\n",
      "Epoch 196/200\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 197/200\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 198/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4581 - accuracy: 0.7820 - val_loss: 0.5059 - val_accuracy: 0.7375\n",
      "Epoch 199/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7828 - val_loss: 0.5064 - val_accuracy: 0.7375\n",
      "Epoch 200/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7828 - val_loss: 0.5063 - val_accuracy: 0.7375\n",
      "train_accuracy: 0.7737500071525574\n",
      "train_error: 0.4676712453365326)\n",
      "test_accuracy: 0.7699999809265137\n",
      "test_error: 0.49619603157043457\n"
     ]
    }
   ],
   "source": [
    "model13 = Sequential()\n",
    "model13.add(Dense(1, input_dim=8, activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model13.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history13=model13.fit(x_train, y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "tr_eval_res = model13.evaluate(x_train,y_train,verbose=0)\n",
    "eval_res= model13.evaluate(x_test,y_test,verbose=0)\n",
    "print(f'train_accuracy: {tr_eval_res[1]}')\n",
    "print(f'train_error: {tr_eval_res[0]})')\n",
    "print(f'test_accuracy: {eval_res[1]}')\n",
    "print(f'test_error: {eval_res[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6230aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=history13 # name of history of model to draw learning curve for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3d65ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHFCAYAAAAaD0bAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABzkklEQVR4nO3dd3xUVfrH8c9k0jskpAAhAQHpSJGOiAVEUVkLrKso1rWtILbFLuuKuj97wdVVWVdXWHtjXVEERXovQZpAKAmhpfeZ+/vjZiaZNFImMynf9+s1r5m598zNmQuah+c85xyLYRgGIiIiIq2Ij7c7ICIiIuJpCoBERESk1VEAJCIiIq2OAiARERFpdRQAiYiISKujAEhERERaHQVAIiIi0uooABIREZFWRwGQiIiItDoKgETEo/bt24fFYmHevHl1/uySJUuwWCwsWbLE7f0SkdZFAZCIiIi0OgqARES8LD8/H23LKOJZCoBEWpnHH38ci8XC5s2bufLKK4mIiKBt27bMnDmTkpISduzYwQUXXEBYWBhJSUk8++yzla6RkpLCNddcQ0xMDAEBAfTs2ZPnnnsOu93u0u7w4cNMnjyZsLAwIiIimDJlCmlpaVX2a+3atVxyySW0bduWwMBABgwYwH/+8596fcejR49y++2306tXL0JDQ4mJieGcc87h559/rtS2sLCQ2bNn07NnTwIDA4mKimLs2LEsX77c2cZut/PKK69wxhlnEBQURGRkJMOGDePLL790trFYLDz++OOVrp+UlMS0adOc7+fNm4fFYuG7777jhhtuoF27dgQHB1NYWMju3bu5/vrr6datG8HBwXTo0IGLL76YLVu2VLpuRkYG99xzD126dCEgIICYmBguvPBCfv31VwzDoFu3bowfP77S53JycoiIiOCOO+6o410VaVl8vd0BEfGOyZMnc8011/DHP/6RRYsW8eyzz1JcXMz333/P7bffzr333su///1vHnjgAbp27cpll10GmMHFiBEjKCoq4i9/+QtJSUl8/fXX3HvvvezZs4fXX38dMLMa5513HocPH2bOnDl0796db775hilTplTqy48//sgFF1zA0KFDeeONN4iIiGD+/PlMmTKFvLw8lwCiNk6cOAHAY489RlxcHDk5OXz22WecffbZ/PDDD5x99tkAlJSUMGHCBH7++WdmzJjBOeecQ0lJCStXriQlJYURI0YAMG3aNN5//31uvPFGZs+ejb+/P+vXr2ffvn31u/nADTfcwEUXXcS//vUvcnNz8fPz4/Dhw0RFRfH000/Trl07Tpw4wT//+U+GDh3Khg0bOP300wHIzs5m1KhR7Nu3jwceeIChQ4eSk5PDTz/9RGpqKj169OBPf/oTM2bMYNeuXXTr1s35c9977z2ysrIUAIkYItKqPPbYYwZgPPfccy7HzzjjDAMwPv30U+ex4uJio127dsZll13mPPbnP//ZAIxVq1a5fP62224zLBaLsWPHDsMwDGPu3LkGYHzxxRcu7W6++WYDMN59913nsR49ehgDBgwwiouLXdpOnDjRiI+PN2w2m2EYhvHjjz8agPHjjz/W6TuXlJQYxcXFxrnnnmv87ne/cx5/7733DMB46623qv3sTz/9ZADGQw89VOPPAIzHHnus0vHExETjuuuuc75/9913DcC49tpra9XvoqIio1u3bsbdd9/tPD579mwDMBYtWlTtZ7OysoywsDBj+vTpLsd79epljB079pQ/W6Sl0xCYSCs1ceJEl/c9e/bEYrEwYcIE5zFfX1+6du3K/v37nccWL15Mr169GDJkiMvnp02bhmEYLF68GDCzOmFhYVxyySUu7f7whz+4vN+9eze//vorV199NWBmZRyPCy+8kNTUVHbs2FHn7/fGG28wcOBAAgMD8fX1xc/Pjx9++IHt27c72/z3v/8lMDCQG264odrr/Pe//wVwe8bk8ssvr3SspKSEp556il69euHv74+vry/+/v7s2rWrUr+7d+/OeeedV+31w8LCuP7665k3bx65ubmA+WeXnJzMnXfe6dbvItIcKQASaaXatm3r8t7f35/g4GACAwMrHS8oKHC+P378OPHx8ZWu1759e+d5x3NsbGyldnFxcS7vjxw5AsC9996Ln5+fy+P2228H4NixY3X6bs8//zy33XYbQ4cO5ZNPPmHlypWsWbOGCy64gPz8fGe7o0eP0r59e3x8qv9f4dGjR7FarZX63VBV3cOZM2fyyCOPMGnSJL766itWrVrFmjVr6N+/f6V+d+zY8ZQ/409/+hPZ2dl88MEHALz66qt07NiRSy+91H1fRKSZUg2QiNRJVFQUqamplY4fPnwYgOjoaGe71atXV2pXsQja0X7WrFnOOqOKHLUvtfX+++9z9tlnM3fuXJfj2dnZLu/btWvHsmXLsNvt1QZB7dq1w2azkZaWVmXQ4hAQEEBhYWGl446AsCKLxVJlv6+99lqeeuopl+PHjh0jMjLSpU8HDx6sti8OXbt2ZcKECbz22mtMmDCBL7/8kieeeAKr1XrKz4q0dMoAiUidnHvuuSQnJ7N+/XqX4++99x4Wi4WxY8cCMHbsWLKzs11mSgH8+9//dnl/+umn061bNzZt2sTgwYOrfISFhdWpjxaLhYCAAJdjmzdvZsWKFS7HJkyYQEFBQY2LMjqGBCsGUxUlJSWxefNml2OLFy8mJyenQf3+5ptvOHToUKU+7dy50zncWJPp06ezefNmrrvuOqxWKzfffHOt+yPSkikDJCJ1cvfdd/Pee+9x0UUXMXv2bBITE/nmm294/fXXue222+jevTsA1157LS+88ALXXnstf/3rX+nWrRsLFy7kf//7X6Vr/v3vf2fChAmMHz+eadOm0aFDB06cOMH27dtZv349H330UZ36OHHiRP7yl7/w2GOPMWbMGHbs2MHs2bPp3LkzJSUlznZXXXUV7777Lrfeeis7duxg7Nix2O12Vq1aRc+ePfn973/P6NGjmTp1Kk8++SRHjhxh4sSJBAQEsGHDBoKDg/nTn/4EwNSpU3nkkUd49NFHGTNmDMnJybz66qtERETUqd/z5s2jR48e9OvXj3Xr1vG3v/2t0nDXjBkzWLBgAZdeeil//vOfGTJkCPn5+SxdupSJEyc6g1CA888/n169evHjjz86ly4QETQLTKS1ccwCO3r0qMvx6667zggJCanUfsyYMUbv3r1dju3fv9/4wx/+YERFRRl+fn7G6aefbvztb39zztZyOHjwoHH55ZcboaGhRlhYmHH55Zcby5cvrzQLzDAMY9OmTcbkyZONmJgYw8/Pz4iLizPOOecc44033nC2qe0ssMLCQuPee+81OnToYAQGBhoDBw40Pv/8c+O6664zEhMTXdrm5+cbjz76qNGtWzfD39/fiIqKMs455xxj+fLlzjY2m8144YUXjD59+hj+/v5GRESEMXz4cOOrr75y+Zn333+/kZCQYAQFBRljxowxNm7cWO0ssDVr1lTq98mTJ40bb7zRiImJMYKDg41Ro0YZP//8szFmzBhjzJgxldpOnz7d6NSpk+Hn52fExMQYF110kfHrr79Wuu7jjz9uAMbKlStrvG8irYnFMLT8qIhISzZ48GAsFgtr1qzxdldEmgwNgYmItEBZWVls3bqVr7/+mnXr1vHZZ595u0siTYoCIBGRFmj9+vWMHTuWqKgoHnvsMSZNmuTtLok0KRoCExERkVZH0+BFRESk1VEAJCIiIq2OAiARERFpdVQEXQW73c7hw4cJCwurcrl6ERERaXoMwyA7O/uUe/yBAqAqHT58mISEBG93Q0REROrhwIEDp9wwWAFQFRz7Dh04cIDw8HAv90ZERERqIysri4SEhFrtH6gAqAqOYa/w8HAFQCIiIs1MbcpXVAQtIiIirY4CIBEREWl1FACJiIhIq6MaoAaw2WwUFxd7uxvNkp+fH1ar1dvdEBGRVkoBUD0YhkFaWhoZGRne7kqzFhkZSVxcnNZaEhERj1MAVA+O4CcmJobg4GD9Aq8jwzDIy8sjPT0dgPj4eC/3SEREWhsFQHVks9mcwU9UVJS3u9NsBQUFAZCenk5MTIyGw0RExKNUBF1Hjpqf4OBgL/ek+XPcQ9VRiYiIpykAqicNezWc7qGIiHiLAiARERFpdbwaAP30009cfPHFtG/fHovFwueff37KzyxdupRBgwYRGBhIly5deOONNyq1+eSTT+jVqxcBAQH06tWLzz77rBF637olJSXx4osversbIiIi9eLVACg3N5f+/fvz6quv1qr93r17ufDCCxk9ejQbNmzgwQcf5K677uKTTz5xtlmxYgVTpkxh6tSpbNq0ialTpzJ58mRWrVrVWF+j2Tj77LOZMWOGW661Zs0abrnlFrdcS0RExNO8OgtswoQJTJgwodbt33jjDTp16uTMPPTs2ZO1a9fyf//3f1x++eUAvPjii5x//vnMmjULgFmzZrF06VJefPFFPvzwQ7d/h5bEMAxsNhu+vqf+a9GuXTsP9EgaW2Z+MdkFKkKviZ/Vh9jwQG93o0b6c5TmyN/Xh5gw7/231aymwa9YsYJx48a5HBs/fjxvv/02xcXF+Pn5sWLFCu6+++5KbWoariksLKSwsND5Pisry639bgqmTZvG0qVLWbp0KS+99BIA7777Ltdffz3ffvstDz30EJs3b+Z///sfnTp1YubMmaxcuZLc3Fx69uzJnDlzOO+885zXS0pKYsaMGc6MksVi4a233uKbb77hf//7Hx06dOC5557jkksu8cbXlRoUltj4YXs6H609wNKdR7Eb3u5R03fb2afxwAU9vN2NKv1z+T6e/CaZYpv+IKV5Gdgpkk9vH+m1n9+sAqC0tDRiY2NdjsXGxlJSUsKxY8eIj4+vtk1aWlq1150zZw5PPPFEvftlGAb5xbZ6f74hgvystZpN9dJLL7Fz50769OnD7NmzAdi2bRsA999/P//3f/9Hly5diIyM5ODBg1x44YU8+eSTBAYG8s9//pOLL76YHTt20KlTp2p/xhNPPMGzzz7L3/72N1555RWuvvpq9u/fT9u2bd3zZaXeDMNg2+EsPl53kM83HiIjryxbEOCruRDVMQwostn539a0JhkAvfbjbv72vx2A+a9pzauU5sTP6t3/9zSrAAgqT502DKPS8ara1BQkzJo1i5kzZzrfZ2VlkZCQUOs+5Rfb6PXo/2rd3p2SZ48n2P/Uf4wRERH4+/sTHBxMXFwcAL/++isAs2fP5vzzz3e2jYqKon///s73Tz75JJ999hlffvkld955Z7U/Y9q0aVx11VUAPPXUU7zyyiusXr2aCy64oF7fTRrueE4hn288zEdrD/BrWrbzeGx4AJcP7MgVgzrSpV2oF3vYtJ3MLWLAXxbx27FcMvOKiQj283aXAPP/ac98u4M3lu4BYPq53ZhxXjctLSFSB80qAIqLi6uUyUlPT8fX19e5KnN1bSpmhcoLCAggICDA/R1uJgYPHuzyPjc3lyeeeIKvv/6aw4cPU1JSQn5+PikpKTVep1+/fs7XISEhhIWFObe7EM8pttlZuuMoH607wOJf051DI/5WH87vHcuVgzoyuls7rD76ZXkqbUL8SYoKZt/xPDYdzOCs7t6vfbPbDR79civvrzT/e3zowp7cfFYXL/dKpPlpVgHQ8OHD+eqrr1yOfffddwwePBg/Pz9nm0WLFrnUAX333XeMGDGi0foV5Gclefb4Rrv+qX52Q4WEhLi8v++++/jf//7H//3f/9G1a1eCgoK44oorKCoqqvE6jj8DB4vFgt1ub3D/pHZ2Hsnmo7UH+GzDYY7llNW09esYwRWDOnJJ//ZEBvt7sYfNU/+ESDMAOuCdAMhuN9h7PJfkw1lsO5zF6r3HWZ+SgcUCf53Ulz8MrX5YWkSq59UAKCcnh927dzvf7927l40bN9K2bVs6derErFmzOHToEO+99x4At956K6+++iozZ87k5ptvZsWKFbz99tsus7umT5/OWWedxTPPPMOll17KF198wffff8+yZcsa7XtYLJZaDUN5m7+/PzbbqWuVfv75Z6ZNm8bvfvc7wPxz2rdvXyP3rmVJPpzFA59sZnS3aO5vxNqRzLxivtx8mI/XHmDTwUzn8ehQfyad0YErBnekR1x4o/381qB/x0i+2HiYTQczGvXn7D2WywMfb2bb4UyX48U2gyKb6z8krD4Wnp/cn0vP6NCofRJpybz6W3vt2rWMHTvW+d5Rh3Pdddcxb948UlNTXYZdOnfuzMKFC7n77rt57bXXaN++PS+//LJzCjzAiBEjmD9/Pg8//DCPPPIIp512GgsWLGDo0KGe+2JNVFJSEqtWrWLfvn2EhoZWm53p2rUrn376KRdffDEWi4VHHnlEmZw6WLf/JNe/u5qsghK2HMpkdLd2DD/NfRvnGobBst3HWLDmAN8lH6GoxPyz8fWxcE6PGK4Y1JGxPWK8XmDYUvRPiARg44HMU9YT1tfXmw/z50+2kFNYUuX5QD8fesSF07t9OL3ahzO8S5Rqt0QayKsB0Nlnn+0sYq7KvHnzKh0bM2YM69evr/G6V1xxBVdccUVDu9fi3HvvvVx33XX06tWL/Px83n333SrbvfDCC9xwww2MGDGC6OhoHnjggRa5NEBj+GX3MW5+by15RTZC/K3kFtl44qttfP2nUfi6KSD5dP0h7vlok/N9j7gwrhjUkUkDOhAd2npr2RpL7/bh+PpYOJZTyOHMAjpEBrnt2oUlNp76Zjv/XLEfgCFJbXni0t6ElMso+/hAfESQarZE3Kzpj9uI23Tv3p0VK1a4HJs2bVqldklJSSxevNjl2B133OHyvuKQWFWBbEZGRr362dTlFZXwxcbD+Fl96N0+nK4xofhZffg++Qi3/3s9RSV2RneL5pnL+3Hhyz/za1o2/16dwrXDk9zy85fvOQ7AWd3bcd+40+nTIVyzfxpRoJ+VHvFhbD2UxaYDGW4LgFIz8/njv9axuXTo8vazT2Pm+d3dFiiLSM0UAInUwe70bG57fz270nOcx/ytPnSNCWXnkWxK7Abje8fy8lUDCPC1cs+403nk8608991OJvZrT9uQhhchO2pEpg5LpG/HiAZfT06tf8dIth7KYuOBDC7sG9/g6xmGwYz5G9l8MJPIYD9emHwGY3vEuKGnIlJb+qeGSC19tuEgF7/yC7vSc2gXFsDQzm0JC/SlyGYnOTWLErvB7wZ04LU/DCTA15yd94chnegZH05mfjH/992OBvehoNjmDL76dlDw4ylldUAZbrneN1tSWbX3BIF+Pnx++0gFPyJeoAyQyCkUFJt1PB+uPgDAyK5RvDhlAO3CAjAMg4Mn89l2OIsim52JfePxKVerYfWx8MQlvZn89xV8uDqFPwzpRJ8GBC6/pmVjsxtEh/oTG656H08ZUBoAbTmYSYnN3qBhqryiEv76zXYAbhvTlaTokFN8QkQagzJAIqfwx3+t48PVB7BYYMZ53XjvhqG0CzODD4vFQkLbYC7oE8cl/du7BD8OQzq35ZL+7TEMeOzLbTUW/p/KlkPm8Ffv9hGq+/GgLu1CCQ3wJb/Yxu6jOaf+QA3mLtlDamYBHdsE8ccxWsBQxFsUAInUYN+xXJbuPIrVx8J7Nwxhxnnd6zUbZ9aFPQjys7Ju/0l+2F7/1bG3lQZAfTpobR9PsvpYnEOOmxowDJZyPI+///QbAA9f1ItANyxkKiL1owBIpAYLt6YCMLxLFKO71X8V4PiIIK4Y1BGAX/Ycq/d1tpYWQPdpr/ofTyu/HlB9/eWbZIpK7IzqGs343tVvzyMijU8BkEgN/rvF3FduQt+4Bl9rcFIbANanZNTr80UldnaUbmjakDoiqZ8zEhqWAVq68yiLko/g62PhsYt7aQhTxMsUAIlUI+V4HlsOZeJjgfG9Gx4ADUgwA6Dkw5kUFJ96S5KKdh7JpthmEBHkR8c27luMT2rHkQHacSSb/KK6/fmV2Ow88dU2AK4bkUS32DB3d09E6kgBkEg1HMNfw7pEuWWF5YS2QUSH+lNsM9h2uO4razvW/9HCh94RFx5ITFgANrvhHIqsreTULH47mktYoC/Tz+vWSD0UkbpQACRSjf9uMQOgCW5Y+A7MGWNnlGaBNqScrPPntx4ygybV/3iHxWJxZoHqOgy2p3TmWK/4cMID/dzcMxGpDwVArcjZZ5/NjBkz3Ha9adOmMWnSJLddryk5cCKPTQczsVjgAjcMfzkM6BQJwIZ61AE5p8Cr/sdrzqjngoh70nMBOC1GG5iKNBUKgESq8O1Ws/h5SFJb55o/7jCwk6MQum4ZoBKbne2pZgaob4wfbP4Icuo/nV7qxxEAbTqYUafPOTJAp2kHd5EmQwFQKzFt2jSWLl3KSy+9hMViwWKxsG/fPpKTk7nwwgsJDQ0lNjaWqVOncuxY2TTtjz/+mL59+xIUFERUVBTnnXceubm5PP744/zzn//kiy++cF5vyZIl3vuCbvZN6fDXRf3cM/zl0K9jBD4WSM0sIDUzv9af23M0l8ISOyH+VhJTPoNPb4K5I+C3pW7tn9TMsffagRP5HM8prPXnygIgrfos0lQoAHIHw4CiXO88armq8EsvvcTw4cO5+eabSU1NJTU1FT8/P8aMGcMZZ5zB2rVr+fbbbzly5AiTJ08GIDU1lauuuoobbriB7du3s2TJEi677DIMw+Dee+9l8uTJXHDBBc7rjRgxojHvssccyshn44EMtw9/AYQE+NIjzlzEcGMdhsG2llsB2idjv3kw9yi8dykseQbsdZ9VJnUXHuhH59KtKxxLEpyKzW6w71geoAyQSFOivcDcoTgPnmrvnZ/94GHwP/W/KiMiIvD39yc4OJi4OPOX+qOPPsrAgQN56qmnnO3eeecdEhIS2LlzJzk5OZSUlHDZZZeRmJgIQN++fZ1tg4KCKCwsdF6vpXAUP5+Z2JaY8EC3X39Ap0iSU7NYn3Ky1gXWjllHvTuEQ25phi6yE2SkwJKnIGUFXPYWhNZ/sUapnehQf/YeyyUjv7hW7Q+ezKPIZifA14cOkVq+QKSpUADUiq1bt44ff/yR0NDK/yrds2cP48aN49xzz6Vv376MHz+ecePGccUVV9CmTRsv9NZzFpYGQBc2ZPHDrFT41++g+3g4/wmXUwM6teGDVSl1KoTeVjoDrG+HCEguDYDG/BksPvDNTPjtR/i/rvXvr1TPxw8umANDbgZwzuLKqmUA5Bj+6hwdUuVecSLiHQqA3MEv2MzEeOtn15Pdbufiiy/mmWeeqXQuPj4eq9XKokWLWL58Od999x2vvPIKDz30EKtWraJz584N6XWTlZqZ71yp+YI+Daj/WfEqHN1uDlNVCIAGls4E23Iok6ISO/6+NY9E2+1GuTWAImBNaQAUEm0GWO3PgI9vgPTk+vdXqmcvhu1fOgOgiKDSAKiglgGQZoCJNEkKgNzBYqnVMJS3+fv7Y7OV1YoMHDiQTz75hKSkJHx9q/6rYLFYGDlyJCNHjuTRRx8lMTGRzz77jJkzZ1a6Xkvw3bYjAAxObENcRD2HvwqzYf2/zNd5xyD/JASVZc06R4cQGexHRl4x21OznGvLVGfv8Vxyi2wE+vnQJToE8o6bJ4KjzeeYnnDb8rKhMXGfvUvhkxshP8N5KLw0AMqsYwZI9T8iTYsCoFYkKSmJVatWsW/fPkJDQ7njjjt46623uOqqq7jvvvuIjo5m9+7dzJ8/n7feeou1a9fyww8/MG7cOGJiYli1ahVHjx6lZ8+ezuv973//Y8eOHURFRREREYGfX/Ne5O2X3WYQMbZHTP0vsvHfUFhupeDjv0HHQc63FouFAQmR/LjjKBtSTp4yAHIUQPeMD8fXx2JmlQBCosoaWSyq/2kMkZ3M54IM56HwQPN/m1n5JbW6hNtngP26EPb/4p5riXhTRAIMu9VrP14BUCty7733ct1119GrVy/y8/PZu3cvv/zyCw888ADjx4+nsLCQxMRELrjgAnx8fAgPD+enn37ixRdfJCsri8TERJ577jkmTJgAwM0338ySJUsYPHgwOTk5/Pjjj5x99tne/ZINYLcbrNp7AoDhp0WdonV1F7HByrnma4sPGHY4scclAAKzDujHHUdZn5LBtJE1X9KxbUaf9hHmzL+SAvOEIwMkjScw0nzOLwtow+s4BPbb0dIhsIZmgIrzYeF9sOFfDbuOSFPRcYgCIPGM7t27s2LFikrHP/300yrb9+zZk2+//bba67Vr147vvvvObf2rrcMZ+Tzy+VaGnxbFTaO7uO26v6Zlk5lfTIi/1Sw2ro+d38LJvRAYAV3Ph60fw/HdlZo5V4Q+cOoFER0ZoD4dws0hNQDfwGYx7NrsBUWaz4VZYLeDj0+dhsBO5hZxPLcIwDl9vl6O7YaProMjWwELDLgGgusZpIs0FREdvfrjFQBJs7LvWC5X/2MVhzLyWbrzKBf0iaNjm9oVgv+w/QiPfrGN5yb3Z1iXyr88Vvxm1tYMTmqLn7WeS2SteN18HjTN/AVVTQDUPyESi8VcUO9odmG1q02X2OwuawCRW3qtkHbmsJc0LkcGCMMc1gxqU6dZYL8dM4e/2kcEEhJQz//dbv0EvrwLinLMP/fL/wFdzq7ftUTESQshSrOxIy2bK/++gkMZ5grKJXaDvy/9rdaff37RTg5l5PP3pXuqPL+yNACq9/BX6ibYvwwsVhhyC0SVTks/XvnnhQf60a10VlBNG6N+vO4gWQUltA3xp3tsWFkGSP/69wxf/7KZlqWF0OFBpTVABaeuAWrQDLCSQvjmHnOGX1EOJI6CW5cp+BFxEwVA0ixsOpDBlDdXcDS7kB5xYbz0+zMAWLD2AOlZBaf8fPLhLGctzbLdxyoNX9jsBqtKA6CqskO14qj96T3JTO22Pc18f3xPlSt2O/YF21DNxpoFxTZe+mEXALeffZo5XT633BR48QxHFqi0ENo5Db4WGaB6zwA7sRfeHgdr/mG+HzUTrv0CwlrWoqMi3qQASJq8tftOcPU/VpGRV8wZCZEsuGU4l/Rvz4BOkRSV2PnHsr2nvMZH6w44XxfbDL5PPuJyfntqFlkFJYQG+NKnfXjdO5mdBls+Nl8Pu8N8btsZsEBRdtnMrXIcdUDr91edAXp/5X5SMwtoHxHINcPMlbid11EBtOcEltaDOTJAgbWvAXIEQF3qMgNs+9fw9zGQutFcPuHqj+G8x8CqigURd1IAVE9GLffgkurV9h4+8VUyOYUlDO8Sxfs3DSUi2A+LxcKdY80hpvdX7udkaaFpVYpK7Hyx0Vyo0rEIoWO1ZwfH8NeZSW3wrU/9z/JXzAXzEoaWzfjyDYDIBPN1FXVAgxLbArBm3wkW/+oakGUXFPPaj+ZnZpzXnUA/q3kiTxkgj3MUQpdmgBxF0IUldgqKa14Hq84zwBY/CQuuNuuNOg4xh7y6nV+fXovIKSgAqiPHOjd5eXle7knz57iHNa0dlFtY4lwF+YUpZxBarpD0nB4x9IwPJ6/IxrvL91V7jcW/pnMit4iYsAD++jtzL7Ofdx1zmca8sr7DX8X58MWd5srPAMPvcD3vrAOqHAB1jQll8uCO2A2444MNbD6Y4Tz31s97OZlXzGntQrhsYIeyD+U6FkFUDZDHOKfCZwAQFuDrrD/PrqEOqKjEzv4TddgE9fge+Olv5uvhd8L1C70+S0akJVNOtY6sViuRkZGkp6cDEBwcjEWzcerEMAzy8vJIT08nMjISq9VabdtNBzOwG9AhMqjSysyOLNAd/17PvF/2cvPozoQFVg6mPi4d/vrdwA70jA+na0wou9Nz+GH7EX43oKNZ/1Of9X8qTk0+exb0vMS1TVRX2LO4ykJogL/+ri+pmQX8vOsYN8xbw6e3jSQ4wMrbP5vF3feMO901I6UMkOdVyAD5+FgIC/Alq6CEzPziamfwpZzIxWY3CPG3EhtedRsX2z4zn087B8b/teH9FpEaKQCqB8fu544gSOonMjLylDvJOzYMPaN06KqiC/rE0aVdCL8dzeX9lSncdvZpLufTswv4cYdZN3PlIPNf0xf2iePlxbv5ZnMavxvQkeTDWWQXlBAW4Euv+Crqfwqy4Ngu12NHt8N/Hzj11GRnIXTlDBCAn9WH168eyJS/ryQ5NYtp765mQKc25BbZ6Nshggl9KtwfZxG0Vn32mAoZIDCHwbIKSmpcDHF3uRlgFosF8k6A1R8CqskGJX9hPvea1PA+i8gpKQCqB4vFQnx8PDExMRQX1241WHHl5+dXY+bHwTFFfEA120VYfSzcfnZX7v1oE28v+43rRyaV1csAX2w4jM1ucEZCJF1jwgC4sF88Ly/ezU+7jpJdUOwc/hrSuW3l+p+iXHhrbLUBDImj4Iq3q5+d4xgCO1H9dP2wQD/evf5MLnt9Ob8dy+W3Y+YvzvsvOL1ydtE5DV4ZII+pkAECcybYwZP5Nc4EcxZAR4eYgevLA6FNJ7hlKfhU+Lt/4jdI22wuodBjopu/gIhURQFQA1it1lr9Epf6MQzDmQEamNim2naXntGeF7/fycGT+Ux7dzUv/34AMeGBGIbhnP115eCyWorTY8PoEh3Cb8dyWfxrunMBxCrrf374ixn8+AW7Djv5+ELfyXDWfTXPzokqXan6+B7nSsJViQ0P5N3rz+SKucvJKjALvkd1rSLIcdQAhagGyGOqygDVYiaYyxT4A6vNwua0LbBjIfS82LXxts/N585n6c9WxEMUAEmTdeBEPsdzi/C3+tC7hqnpflYf/vq7vtz2/jpW/naCC19exstXnUGIvy87j+QQ4OvDxH7tne0tFgsX9o3n1R9389Wmw6yprv4nZSWsesN8Pflf0O28un+JiE7g4we2Qsg6WLa5ZhW6x4bxzxuG8Payvcw8v3vl7E9RHhSb2SFlgDyoigxQbRZDdM4Aiwk1szsOK+dWDoCcw1+XNrS3IlJLmgUmTdb60uGv3h3CCfCtOdM2pns7vrxzFKfHhnEsp5Br/rGKez/aBMD43nHm4nXpv8JH0+DkPib0NYesvt+eTnZhCeGBvvQsX/9TnA9f3AEYcMY19Qt+wMwOte1svq6mELq8AZ3a8OofBtKlqllDjuEvqz8EhNWvP1J3VWSATrUYomEYrhmgtC1lJ/f/Aoc3lr0/sddc88fiUzkwEpFGowBImqyy+p/qh7/K6xoTyud3jOTKQebU8l3p5i8g5/DXT38zZ9r88jK94sNJiirbQ2xI5yisPuUyLj/+1Rz6Cotv+IycUxRC11puufofzTz0HGcGqNyO8KfYD+xoTiHZBSX4WCAxKrgsA9SmNBhe+XpZY0f2J2mUZveJeJACIGmyHFtEDKhmBlhVgvyt/O3K/vztin4E+Zm7uo84rfSXysE1zmfHMJjDsC5tyy5ycC2seM18PfHFsl+A9RVVGgDVUAhdK3mq//GKClthQNliiNXNAnPsAdaxTTCBJVmQkWKemPiC+bz1E8gqXYxTs79EvEIBkDRJBcU2kkv37qqpALo6Vw5OYONj5/PRrcPNzE5OOmTsN08e2QZFuS4BkLP+p7gAPr8dDDv0mwKnX9Dg7+IMgNyVAdIUeM8qnwGy2wEIDyytAcqvugaobPgrBNK2mgcjO8FpY6HTcLCXmPt8ndwPh9dr+EvEC1QELU3SlkOZlNgNYsICaF9hAcTacqkbcmR/AAwbHN5A78SRTBmcQJHNTs+40vqfDf+CYzsgJAYueLoB36CcGlaDrhNNgfcORwbIsJv7ugVGEBF8igyQS/3PWvNgXD/zedjtkLIC1r5jbpcCkDgSQmMa6xuISBUUAEmT5Kj/GdipjXtW2j6wutJ7S9Ionrmin+vxXYvM5xF3QnBb3MIRAJ3cD7ZisFa/9UeNHBuhqk7Es/wCwRpgzuTLz4DAiFNOg99XupZTl3ahcLi0/ifO3IaFHhdBZKKZkXRsfaHZXyIepyEwaZLW788A6lb/U6ODpf8Kb9fD9X15tmLYt8x8fdo57vm5YBZS+wWbmaeT++t/He0D5j3VbIhaXRF0WlYhAPGRgWUzwBwZIB8rDL3VfG0rAiyVt1ARkUanAEiaHMMwnFPgB3Sqe/1PJbYSs84CzOEHMIfEKu5Gf3Ctuc5OcBTE9G74z3WwWMpmgp049VT4amkfMO+pMBXeOQ2+mnWAjmabAVBMEHD0V/OgIwMEMOAa8C9dyiBxBITFurnDInIqCoCkyTmcWUB6diG+Phb6doho+AXTt0FxHgREQN8rzYUJc8sVRTvsXWo+dx5T7YrN9eZcEboBdUC5qgHymooZoHJDYEaFQLrEZud4bmkGqGifWfAcGOm6s3tgOAwvDcYHTWu0botI9RQASZPjqP/pGR9OkL8bthpxFEB3HAT+wWX/Eq84DPbbEvO5qk1NG8odhdDKAHlPhQyQYyVom90gr8jm0vREbhGGAT4WiMwszf7E96u8dtPZs2DGVug3uRE7LiLVUQAkTY5z/y931/90PNN8ThhSerzczLDC7LL3Xca45+eW5wyAGjAE5twHTNPgPa5CBijIz4qf1QxoKs4ESy8d/ooKDcDnSOkU+LgKxfZgBkSRCY3RWxGpBQVA0uS4tf4HymaAdSwNfByBUPmZYfuXm0MVbZLMh7s5V4OuZwBUXGBOwQYVQXtDhQyQxWKpdiZYenYBADFhAWUrQFcVAImIVykAkialsMTGtkPmAohumQGWd6Ks8LjDQPO542DzOW2zuecXwG+l9T+NMfwFZRmgrIPmpqZ15Rj+8vGDQDfURUndVLkhqmMmmGshtLMAOtSvbBHE8gXQItIkKACSJiX5cBZFNjtRIf50aht86g+cimP4K6pb2bo+kYnmQof2Ekg1N0x11v90boThLzB/tiNwObm37p93FkBHaR8wb3Buh1FuP7BqpsKnl06BPz3ghJm1swZAdDePdFNEak8BkDQpK34z61wGJpZbAPGn/4NXz4SjO+t+wYOlw1yOuh8wAwjHMNjBNeY2GenbzPeNFQBZLGVZoGO76v55FUB7lyMDVG5HeMd2GBWHwI7mmAFQL8s+80Bsr/ovfikijUYBkDQpP+00Vzs+q1u5X/Qb/w3HdsIXt4PdVs0nq+GcATbY9XhCuQBo70/m67h+jbvRaLue5rNjYby60CKI3lWHDVEdGaCk4tLNbzX8JdIkKQCSJiOnsIS1+8wC6LO6l850stsh86D5+uAaWPl67S9ot8HBdeZrR8bHwVkIvQZ++9F83Rizv1x+ZmkQVn72WW0pA+RdVWaAqqkBKs0AxeWXZixVAC3SJCkAkiZjxZ7jlNgNEqOCSYwKMQ/mHjX3YHJY/CQcq+VaOkd3mDUYfiEQ08v1XPsBYLFC9mHY/pV5rLEKoB0cQdehdXXPZGkneO+qIgMUUV0GqHQWWGSWYwVoBUAiTZECIGkyyoa/yv2SzzxgPofFm/tzlRTAF3fULoBwZFo6DDT3XyrPPwRiS7e7KMgEqz90Gt7Ab3AKMT3BPxSKcsq2R6gtx0aoWgXaOxwF7PkZzi1UHIshlq8BMgyD9KxCosjEP+8IYCn7eyYiTYoCIGkylpYGQGO6VxEARXaCi182A4gDK2H1m6e+YFUF0OWVHxbrOMQMihqTj7VsKn7F3elPJc+xCKJqgLzCMQRm2MwAlvJDYGUBUHZhCYUldnr5lG6zEnUaBIR6sqciUksKgKRJ2Hcsl5QTefhZLQw/rdwv+YzSACgiwVw19/zZ5vvvnzj1ooIVV4CuqHxg1NjDXw7O2WdV7EZfE+0D5l1+weYaTFDFhqhlAZCjAHqAX+nfWxVAizRZCoCkSfhpl5n9GZTYhpAA37ITzgxQ6ZYBg66HpNFQkg9f/skskq5K1mGzBgigw+Cq25QPjDwWAFWxDUdtqAjauyyWyhuiBjlWgi4rgnYsgthfAZBIk6cASJoEZ/1P9wpFvs4MUOlO2j4+cMkr5r/I9/8Ca9+ufDHDgK9nAgYkDIXQagqH23aB0y8ya4vaD3DPFzkVx0ywYzsg/2TtP+ecBq8AyGsqbohaug5Q+SEwRwF0nI/ZhshED3VOROpKAZB4XVGJneV7zF/wLgXQUDYFPqJT2bG2neG8x83Xix6Dk/tcP7PlI9j5X7OweeKL1f9giwWu+jdM/QysvtW3c6eQaDPwAnM2WG2UFEFhZtnnxTsqZICqGgJzZIDCLGYgpG1LRJouBUDidWv3nyCvyEZ0qD+94sNdT2ammM8Vd80+82boNAKKc82hsNKZOWQfgYX3ma/H3G+uwtvU1FQHdHIffPug+T0cHMNfFmtZFkI8r2IGqDQAyi4owWY3//45AqAQSveY81cBtEhT5fUA6PXXX6dz584EBgYyaNAgfv755xrbv/baa/Ts2ZOgoCBOP/103nvvPZfz8+bNw2KxVHoUFBQ05teQBvhpp/kL/qxu7fDxKbfPVUFW2d5LjiEwBx8fuPRV8A0yV3Je964ZBH0z0/wXelw/GDnDI/2vs6p2o3f4+m5Y+Rp891DZsfL7gPl4/T/Z1qtiDVBg2fYWOQVmHVB6aQAUaJQGQAFhnuqdiNSRV/9vumDBAmbMmMFDDz3Ehg0bGD16NBMmTCAlJaXK9nPnzmXWrFk8/vjjbNu2jSeeeII77riDr776yqVdeHg4qampLo/AwEBPfCWph6XV1f84CqADI6v+RRJ1Gpz7iPn6u0dh+Svw69fg4wuTXm+6+y85F0Rc61rEnb4d9iw2X2/7zCzkBhVANxUVNkT19/UhyM9cX8oxDObIAAXYcs22mgIv0mR5NQB6/vnnufHGG7npppvo2bMnL774IgkJCcydO7fK9v/617/44x//yJQpU+jSpQu///3vufHGG3nmmWdc2lksFuLi4lwe0jSlZxewPTULgFHdKvyCz6gwA6wqQ281Z1YVZcOi0mDorPua9uyb2N5m5qogE46XW9W6/DYf9hJY/Zb5WvuANQ1VbYdRYTHE9OwCrNjwtTkyQBWGdEWkyfBaAFRUVMS6desYN26cy/Fx48axfPnyKj9TWFhYKZMTFBTE6tWrKS4uK0TMyckhMTGRjh07MnHiRDZs2FBjXwoLC8nKynJ5iGf8XDr81adDONGhAa4nHRmg8gXQFflYS7M9pZ+N7QOjZjZCT93I6le2IKJjscbcY7Bpgfl6+J3m87p3oShPGaCmoqoNUSsshpieXUgI5YbbVQMk0mR5LQA6duwYNpuN2NhYl+OxsbGkpaVV+Znx48fzj3/8g3Xr1mEYBmvXruWdd96huLiYY8fMXxI9evRg3rx5fPnll3z44YcEBgYycuRIdu3aVW1f5syZQ0REhPORkFBDxkHcyrH+T6XZX1B5DaDqRHeDi1+E+DPgsjfB19+tfWwUFTdGXfuOuedZ+wHmYo9tksxp8ps+1CKITUUVGaDyM8EKS2xk5BUT6iiAtgY0j7+LIq2U1ysqLRaLy3vDMCodc3jkkUeYMGECw4YNw8/Pj0svvZRp06YBYLWaY/HDhg3jmmuuoX///owePZr//Oc/dO/enVdeeaXaPsyaNYvMzEzn48CBA+75clIjwzD4ZXfp9PeK9T9QeQ2gmpzxB/jj0uaz71L5mWAlhbDmH+b7YXeYWa2ht5rvV86F3HTztTJA3lVVBsi5GGIxx3KKAIiwlmaAVP8j0qR5LQCKjo7GarVWyvakp6dXygo5BAUF8c4775CXl8e+fftISUkhKSmJsLAwoqOr/uXg4+PDmWeeWWMGKCAggPDwcJeHNL5DGfkcyynE18fCGQmRlRtkltsGo6VxBEDpybD+Pcg5AmHtofck8/iAa8z6keO74NdvzGMKgLyr/IaopcoWQyxxFkAnBJdu1KsZYCJNmtcCIH9/fwYNGsSiRYtcji9atIgRI0bU+Fk/Pz86duyI1Wpl/vz5TJw4EZ9qpgcbhsHGjRuJj493W9/FPTYeyACgZ3w4gX7Wyg0ciyCeagisOQqLM2ubDDt8/7h5bMjNZTPXAsJg4LXm6zytAt0kVJgGD2UZoKyCYtKzzMxPvCMA8lcAJNKUeWj526rNnDmTqVOnMnjwYIYPH86bb75JSkoKt95qpv9nzZrFoUOHnGv97Ny5k9WrVzN06FBOnjzJ888/z9atW/nnP//pvOYTTzzBsGHD6NatG1lZWbz88sts3LiR1157zSvfUaq3qTQA6p9QxWq5JUWQXZodrKkIujlLONNc6LEox5wVNmia6/kht5gzw4zSqfLKAHlX+YUQDQMslrIaoPxi5xpAcQHmUJgyQCJNm1cDoClTpnD8+HFmz55Namoqffr0YeHChSQmmvvnpKamuqwJZLPZeO6559ixYwd+fn6MHTuW5cuXk5SU5GyTkZHBLbfcQlpaGhEREQwYMICffvqJIUOGVPzx4mWbDpjrqfTvGFn5ZNZBwADfwJb7i7/jmbD1E/P1GVdBcFvX820SocdE2P6l+V4ZIO9yZIDsxVCcB/4hzllgmfnFziGwdgGlM1JVAyTSpHk1AAK4/fbbuf3226s8N2/ePJf3PXv2POWU9hdeeIEXXnjBXd2TRlJis7PlkBkAVVn/U74Aupqi+Gav/G70w6r+b4Dhd5QFQCHVbOoqnuEfam5HYtjMLJB/iHMdoKyCEmcGKNrXfFYGSKRp83oAJK3TrvQc8otthAb40qVdFf9SbskF0A7tB5qBT3h7cyp/VRKGwpg/m0FgiBZC9CqLxcwC5R0364AiOrgMgfmUBuptfEuHwLQGkEiTpgBIvMJR/9O3QwRWnyoyPC25ANrBxwcumFNzG4sFxs7yTH/k1AIjzQDIsSFquSGwYptZqxXh45gGrwyQSFOmAEi8YtPBDADO6BRZdYOMWqwCLeJpzplg5vBt+VlgOYXmhqihFkcApOU0RJoyBUDiFRtrKoAGc3YU1G4RRBFPqbAYomMILCOvGLthABBs5JltVAQt0qQpABKPyysqYeeRbKCaAmio3UaoIp5WYTsMxxBYYYnd2STQ7giANAQm0pR5fSsMaX22HsrCZjeIDQ8gLiKwcgO7HbIOma9bchG0ND8VMkChga7/hmwT7IdPUY75RkXQIk2aAiDxOOcCiNUNf+Wmg60ILD7mDCmRpqJCBsjqYyGsXBAUExYIhVnmG9UAiTRpCoDE4zaWFkD3P9XwV1h82dYQIk2BYz+w8tthBJb9HY0JDzBX9gbVAIk0cQqAxOMcGaAB1QVAzgJoDX9JE1N+O4xSjplgAO1CA6DQrG9TDZBI06YASDzqWE4hB0/mY7FAn45V7AEGKoCWpquqDVHLDYG1Cw+AQtUAiTQHCoDEozaXDn+d1i7UZejAhWMRRGWApKmpIgMUUS4DFBNshZJ8840yQCJNmgIg8ahTrv8D5bbB0BpA0sRUlQEqFwC1D7aVtVUAJNKkKQASj3LU/5yRUM3wF5QbAtMq0NLEVFUDVC6TGevYCd43UAX8Ik2cAiDxGMMwnFtgVDsDDFrHRqjSPDkyQLZCKDaHusoPgbXz10aoIs2FAiDxmP3H88jIK8bf14cecdWskVKQWbaOiobApKnxDzPXp4Ky1aCDyoqg2/oWmi80/CXS5CkAEo/ZWDr81bt9OP6+1fzVcwx/BbXROirS9Pj4lFsLqHRD1NIhsCA/K8GGowBaf3dFmjoFQOIx325NA2BIUtvqG2n4S5q6ajZEbRcWgKXIsQaQVoEWaeoUAIlHnMgt4odfjwDwu4Edqm94fLf53LazB3olUg/BpQF83nEAzugUSfuIQC7sG1+2BpCGwESaPO0GLx7x+YZDFNsM+naIqL7+ByD9V/O5XU/PdEykroKjzefcYwBEhwbwy5/PwWKxwIrF5jkVQYs0ecoAiUd8vM5c3PCKQacobD7qCIBOb+QeidRTSGkAlHfMechisZgvipQBEmkuFABJo9t2OJPk1Cz8rT5cekYNu7sbBhzdYb5u18MznROpq+Ao8zn3eOVzzp3glQESaeoUAEmj+2itmf05v1cskcH+1TfMOgxF2WCxQlRXD/VOpI6qyAA5FaoIWqS5UAAkjaqoxM4XGw8BtRn+2m4+R50GvjUESiLe5KwBOlr5nDZCFWk2FABJo1r86xFO5hUTExbA6G7RNTd2Dn+p/keasJB25nNuTRkg1QCJNHUKgKRROYa/LhvYEV/rKf66HdUMMGkGQkprgPKqqAFyFkErAyTS1CkAkkaTnl3Akp3mMMEph7+g3BR4ZYCkCSs/Dd4wXM85i6CVARJp6hQASaP5fMMhbHaDAZ0i6Rpzin8RawaYNBeOImhbYVnGx8FZA6QASKSpUwAkjcIwDOfaP1cOqsW2FtlpUJhpbjQZ3a2ReyfSAP4h4Btkvq5YB6QaIJFmQwGQNIpth7PYeSQHf18fJvaPP/UHHPU/bbuAb0Djdk6koUJcV4N2Ug2QSLOhAEgaxZebDgNwXs8Y527ZGAakbQVbSeUPOAugNfwlzYBjMcTyawHZiqGkwHytDJBIk6cASNzObjf4cqMZAF3Sv9zGp8mfwxsj4fvHKn9IW2BIc1LVVHjH8BeoBkikGVAAJG63et8J0rIKCAv0ZWyPdmUnUlaZz5s+rJwFchZAawq8NANVrQbtCIB8g8CqfaZFmjoFQOJ2jpWfL+wTT4CvtezEyX3mc95x2L+s7LhhQHrpKtDKAElz4NwPrFwApI1QRZoVBUDiVoUlNhZuSQOovPGpIwAC2PZ52eucdCjI0AwwaT6cGaByiyE6Z4CpAFqkOVAAJG71085jZOabW18M7RJVdsIwXAOg7V+B3Wa+dtT/tEkCvyBPdVWk/oKrmAVWqAyQSHOiAEjcyjH8dUn/9lh9LGUnctKhJN/M8gRGmrUT+38xz2kBRGluQqrYENWxCrQKoEWaBQVA4jY5hSV8v/0IAJee0cH1pCP7E94Rek40Xyd/YT5rBpg0N8FVDIGpBkikWVEAJG7z3bY0CortdIkOoU+HcNeTGfvN5zaJ0GuS+Tr5S3MYTJugSnNT1UKIqgESaVYUAInbfOFY++eM9lgsFteTjgxQm0ToPAYCIyA3HVJWKgMkzY8jACrJh6Jc87W2wRBpVhQAiVscyylk2W7zX8OVhr+gXACUBL7+0KN0GGzNP0qHESwQ3d0TXRVpOP9QsJZu2eLIAjkCIH9lgESaAwVA4hYLt6Risxv07xhB5+iQyg2cAVBn87nXpebzts/M58hO4B/c6P0UcQuLpfJiiM4MUHjVnxGRJkUBkLjFkh3mbJgL+1az8Wn5DBBAl7MhIAIwzPcxqv+RZqbiYojaCFWkWVEAJA1WYrOzZu8JAEZ2ja6iQSFkmfVBzgDINwBOn1DWRvU/0txULIRWDZBIs6IASBosOTWL7MISwgN96RlfRfo/4wBggF9I2b+aAXpPKnutNYCkuQmuOARWmgFSDZBIs6AASBpsxR5zLZQhnaNcFz90KD/8VX52WJexpcNgQFzfRu2jiNtV3BFeGSCRZkVbFkuDrfzNDICGdWlbdYOTe81nx/CXg18gXPWheV4BkDQ3IaXZTMdiiEUKgESaEwVA0iAlNjtr9p0EYPhpUVU3qlgAXV7SSPMh0txU3A9MGSCRZkVDYNIgWw9nkVNYQkSQHz3jqpn+W1MAJNJcVZoGr60wRJoTBUDSIGX1P23xqar+B8ptg5HkmU6JeEJwuQ1RS4rAVmi+VxG0SLOgAEgaxFH/M7xLNcNfhgEny+0DJtJSOKfBHy9bAwiUARJpJhQASb0V2+ys3Weu/zOsugAo/yQUZpmvIzt5qGciHuBY0qE4F3LSzdd+weBj9V6fRKTWFABJvW05lElukY3IYD96xFXzr17HDLCwePAL8lznRBpbYAT4+JmvHXVuyv6INBsKgKTeHMNfQ2uq/1EBtLRU5fcDcwT6qv8RaTYUAEm9OQqgq63/AQVA0rI5CqFPlAZAygCJNBsKgKRezPofc/2fYdWt/wNlBdCRKoCWFsixGOJJBUAizY0CIKmXzQczyC+20TbEn+4xNfxPXxkgackcGSDVAIk0OwqA5JT2HcvllR92sW7/CQzDAGDlb+bsrxrrf0ABkLRszhqg0kynaoBEmg2vB0Cvv/46nTt3JjAwkEGDBvHzzz/X2P61116jZ8+eBAUFcfrpp/Pee+9VavPJJ5/Qq1cvAgIC6NWrF5999lljdb9VePKbZJ5btJPL567g3OeX8vqS3fyw/QhQw/R3AFsxZB40XysAkpbIkQFyLIKoDJBIs+HVAGjBggXMmDGDhx56iA0bNjB69GgmTJhASkpKle3nzp3LrFmzePzxx9m2bRtPPPEEd9xxB1999ZWzzYoVK5gyZQpTp05l06ZNTJ06lcmTJ7Nq1SpPfa0WxTAM1u43a338rT78djSXZ7/dwfqUDKCG/b/ADH4MG/gGQmisB3or4mGODJBDgDJAIs2FxXCMaXjB0KFDGThwIHPnznUe69mzJ5MmTWLOnDmV2o8YMYKRI0fyt7/9zXlsxowZrF27lmXLlgEwZcoUsrKy+O9//+tsc8EFF9CmTRs+/PDDWvUrKyuLiIgIMjMzCQ+vZn+rVuK3ozmc89xSAnx9WPXguXyXfISP1x5k9b4TdIsJ5bu7z8JiqWYIbM+P8K9JEH063Lnao/0W8YjtX8GCa8ren/MwnHWf9/oj0srV5fe313aDLyoqYt26dfz5z392OT5u3DiWL19e5WcKCwsJDAx0ORYUFMTq1aspLi7Gz8+PFStWcPfdd7u0GT9+PC+++KJb+99aODI9fTtEEBnsz+TBCUwenEB6VgFB/tbqgx8otweYZoBJCxVcIQPkryEwkebCa0Ngx44dw2azERvrOjQSGxtLWlpalZ8ZP348//jHP1i3bp05NLN2Le+88w7FxcUcO2buyJyWllana4IZWGVlZbk8xLQhxRz+GtAp0uV4THggYYF+NX9YBdDS0lUaAlMAJNJceL0IumIGwTCMarMKjzzyCBMmTGDYsGH4+flx6aWXMm3aNACs1rL9d+pyTYA5c+YQERHhfCQkJNTz27Q8G0ozQAM7tan7hxUASUsXXKEGTgGQSLNRrwBoyZIlDf7B0dHRWK3WSpmZ9PT0Shkch6CgIN555x3y8vLYt28fKSkpJCUlERYWRnS0+S+xuLi4Ol0TYNasWWRmZjofBw4caOC3axlyC0v4Nc3Mhg1QACRSWWAkWMptfqoiaJFmo14B0AUXXMBpp53Gk08+We9gwd/fn0GDBrFo0SKX44sWLWLEiBE1ftbPz4+OHTtitVqZP38+EydOxMfH/CrDhw+vdM3vvvuuxmsGBAQQHh7u8hDYfDATuwHxEYHERQTW3PjgWnjrHHhtWNkjbYt5TgGQtFQ+Pq5ZoAD9v0OkuahXEfThw4d5//33mTdvHo8//jjnnnsuN954I5MmTcLf37/W15k5cyZTp05l8ODBDB8+nDfffJOUlBRuvfVWwMzMHDp0yLnWz86dO1m9ejVDhw7l5MmTPP/882zdupV//vOfzmtOnz6ds846i2eeeYZLL72UL774gu+//945S0xqb31p/U+thr/W/xMOrat8PKgNtO3i5p6JNCEh7SA33XythRBFmo16BUBt27blrrvu4q677mLjxo2888473HHHHdx2221cffXV3HjjjfTv3/+U15kyZQrHjx9n9uzZpKam0qdPHxYuXEhiojlrKDU11WVNIJvNxnPPPceOHTvw8/Nj7NixLF++nKSkJGebESNGMH/+fB5++GEeeeQRTjvtNBYsWMDQoUPr81VbNUf9T8UC6CpllGYCR82ELmeXHW93OvgFubtrIk1HSPkMkGqARJoLt6wDdPjwYd58802efvppfH19KSgoYPjw4bzxxhv07t3bHf30KK0DZBaOn/nX7zmWU8Qnt41gUOIpskCvDILju+G6r6DzWZ7ppEhT8NH1sO1T8/WfUyAwwrv9EWnF6vL7u96zwIqLi/n444+58MILSUxM5H//+x+vvvoqR44cYe/evSQkJHDllVfW9/LiZQdO5HMspwg/q4Xe7U8RBBpG2ZYXEZpBJ61M+anwGgITaTbqNQT2pz/9ybmq8jXXXMOzzz5Lnz59nOdDQkJ4+umnXYampHnZcMCs/+nVPoJAP2vNjXOPQkkBYIHwDo3fOZGmxLEYol8I+JzivxURaTLqFQAlJyfzyiuvcPnll1db9Ny+fXt+/PHHBnVOvGf9fkcBdOSpG2eW1v+ExYNv7YvgRVoERw2Q6n9EmpV6BUA//PDDqS/s68uYMWPqc3lpAjYcyABquf6PowA6omPjdUikqXJkgLQGkEizUq8aoDlz5vDOO+9UOv7OO+/wzDPPNLhT4l0FxTaSD5sLINYpAxSp+h9phdoPAGsAdBjs7Z6ISB3UKwD6+9//To8ePSod7927N2+88UaDOyXeteVQJiV2g3ZhAXSIrMUUdmcGSAGQtEJtEuG+3TBprrd7IiJ1UK8hsLS0NOLj4ysdb9euHampqQ3ulHiXcwPUhMiad3t3cMwAUwZIWqvA1rlchkhzVq8MUEJCAr/88kul47/88gvt27dvcKfEu9bvzwBg4KnW/nHILF2sUhkgERFpJuqVAbrpppuYMWMGxcXFnHPOOYBZGH3//fdzzz33uLWD4lmGYTi3wBiQEFm7D2kITEREmpl6BUD3338/J06c4Pbbb6eoqAiAwMBAHnjgAWbNmuXWDopnpWYWkJ5diNXHQr+Okaf+QGE2FGSYrzUEJiIizUS9AiCLxcIzzzzDI488wvbt2wkKCqJbt24EBAS4u3/iYbvTcwA4rV0IQf61WNTNkf0JjNQ6KCIi0mzUKwByCA0N5cwzz3RXX6QJSMssAKB9bWZ/gQqgRUSkWap3ALRmzRo++ugjUlJSnMNgDp9++mmDOybekVoaAMVHBNbuAyqAFhGRZqhes8Dmz5/PyJEjSU5O5rPPPqO4uJjk5GQWL15MRIR2Qm7OUjPzAYgLr2UGSAXQIiLSDNUrAHrqqad44YUX+Prrr/H39+ell15i+/btTJ48mU6dOrm7j+JBzgxQZG0zQFoFWkREmp96BUB79uzhoosuAiAgIIDc3FwsFgt33303b775pls7KJ6VVuchsNIaIGWARESkGalXANS2bVuys7MB6NChA1u3bgUgIyODvLw89/VOPM4xBFbrAEhDYCIi0gzVqwh69OjRLFq0iL59+zJ58mSmT5/O4sWLWbRoEeeee667+ygekltYQlZBCQBxEbWoASopguzSrU80BCYiIs1IvQKgV199lYICc6hk1qxZ+Pn5sWzZMi677DIeeeQRt3ZQPMdR/xMW4EtoQC3+amQdAgzwDYSQdo3bORERETeqcwBUUlLCV199xfjx4wHw8fHh/vvv5/7773d758SzHPU/cXWu/+kItdk0VUREpImocw2Qr68vt912G4WFhY3RH/EiZ/1PrRdBdNT/dGykHomIiDSOehVBDx06lA0bNri7L+Jlzhlg4SqAFhGRlq1eNUC3334799xzDwcPHmTQoEGEhIS4nO/Xr59bOieedbjOQ2Clq0BHau0nERFpXuoVAE2ZMgWAu+66y3nMYrFgGAYWiwWbzeae3olHpWkKvIiItBL1CoD27t3r7n5IE5DakCJoERGRZqReAVBiYqK7+yFNQFpWHXaCt9u1E7yIiDRb9QqA3nvvvRrPX3vttfXqjHhPfpGNjLxioJYZoNyjYCsEiw+Ed2jk3omIiLhXvQKg6dOnu7wvLi4mLy8Pf39/goODFQA1Q44p8CH+VsJqswiiYwp8WDxY/RqxZyIiIu5Xr2nwJ0+edHnk5OSwY8cORo0axYcffujuPooHlF8E0VKbRQ0zVQAtIiLNV70CoKp069aNp59+ulJ2SJqHVOcu8LVcBDFDiyCKiEjz5bYACMBqtXL48GF3XlI8xFEAXesp8I4MkAqgRUSkGapXDdCXX37p8t4wDFJTU3n11VcZOXKkWzomnpWqNYBERKQVqVcANGnSJJf3FouFdu3acc455/Dcc8+5o1/iYakZjhqgOu4DplWgRUSkGapXAGS3293dD/GyshqgOg6BqQZIRESaIbfWAEnz5agBqtUaQEeSoSDTfK0hMBERaYbqFQBdccUVPP3005WO/+1vf+PKK69scKfEswqKbZzILQJqkQHa/B/4x3nm6/j+EBDayL0TERFxv3oFQEuXLuWiiy6qdPyCCy7gp59+anCnxLOOlGZ/gvysRARVs6hhcQF8NR0+vRmKcyFpNPzhIw/2UkRExH3qVQOUk5ODv79/peN+fn5kZWU1uFPiWYczyup/qlwE8fge+Og6SNsCWGDM/TDmAfCxerajIiIiblKvDFCfPn1YsGBBpePz58+nV69eDe6UeFZaljkFvsr6n22fw9/HmMFPcDRc8wmMfVDBj4iINGv1ygA98sgjXH755ezZs4dzzjkHgB9++IEPP/yQjz7SsEhzk5pZRQF0SSF89wis/rv5vtNwuOIdCG/vhR6KiIi4V70CoEsuuYTPP/+cp556io8//pigoCD69evH999/z5gxY9zdR2lkaRWnwJ/cDx9Ng8PrzfcjZ8A5j4C1Xn9dREREmpx6/0a76KKLqiyElubHZR+w3GPw1ljIOw6BkXDZm9B9vHc7KCIi4mb1CoDWrFmD3W5n6NChLsdXrVqF1Wpl8ODBbumceIbLNhi7vzeDnzZJcN1XWulZRERapHoVQd9xxx0cOHCg0vFDhw5xxx13NLhT4llp5WuADq4xD55+kYIfERFpseoVACUnJzNw4MBKxwcMGEBycnKDOyWNo9hm5/Ulu9l2ONN5rLDExrEcxyKIQXBgtXki4UxvdFFERMQj6hUABQQEcOTIkUrHU1NT8fVVoWxTtXBLKs9+u4Or/7GKQxnmsFd6ViEAAb4+tPEtgiPbzMYdFQCJiEjLVa8A6Pzzz2fWrFlkZpZlEjIyMnjwwQc5//zz3dY5ca+th8w/r4y8Yu7893qKSuwum6BaUjeBYYOw9trkVEREWrR6pWuee+45zjrrLBITExkwYAAAGzduJDY2ln/9619u7aC4z/bUbOfrDSkZPPvtr/TtGAE46n9Wmic7qohdRERatnoFQB06dGDz5s188MEHbNq0iaCgIK6//nquuuoq/Pyq2UtKvO7XNHObkjvGnsZrP+7hH8v2MqxLW6C0/ufgWrOhhr9ERKSFq3fBTkhICKNGjaJTp04UFZlFtP/9738Bc6FEaVrSsws4llOEjwXuHNuNgmI7by/by8rfTgAQFx4A20pngCUM8WJPRUREGl+9AqDffvuN3/3ud2zZsgWLxYJhGC6baNpsNrd1UNzDMfyVFB1CkL+VBy7owfqUk2xIyQCga8AJyDkCPr4Q39+LPRUREWl89SqCnj59Op07d+bIkSMEBwezdetWli5dyuDBg1myZImbuyju8GuqOfzVMy4cAH9fH179w0Aig80hy14lO82Gcf3AL8grfRQREfGUemWAVqxYweLFi2nXrh0+Pj5YrVZGjRrFnDlzuOuuu9iwYYO7+ykNtN0RAMWHOY91iAxiwS3DWbPvBD1OvGYeVP2PiIi0AvXKANlsNkJDQwGIjo7m8OHDACQmJrJjxw739U7cxjEE1jM+3OX46XFhXDMsEcshFUCLiEjrUa8MUJ8+fdi8eTNdunRh6NChPPvss/j7+/Pmm2/SpUsXd/dRGqiwxMaeozkA9KgQAAFQXACpm83XWgFaRERagXoFQA8//DC5ubkAPPnkk0ycOJHRo0cTFRXFggUL3NpBabjd6TmU2A3CA31pHxFYuUHqJrAXQ0g7iEz0fAdFREQ8rF4B0Pjx452vu3TpQnJyMidOnKBNmzYus8GkaSg//FXln49jA9SOQ0B/fiIi0gq4beOutm3buutS4mbOGWBVDX8BHCzdAFUrQIuISCtRryJod3r99dfp3LkzgYGBDBo0iJ9//rnG9h988AH9+/cnODiY+Ph4rr/+eo4fP+48P2/ePCwWS6VHQUFBY3+VJmt7WuUZYC60ArSIiLQyXg2AFixYwIwZM3jooYfYsGEDo0ePZsKECaSkpFTZftmyZVx77bXceOONbNu2jY8++og1a9Zw0003ubQLDw8nNTXV5REYWEXtSytgGEa1M8AAyDwEWYfA4gMdBnq4dyIiIt7h1QDo+eef58Ybb+Smm26iZ8+evPjiiyQkJDB37twq269cuZKkpCTuuusuOnfuzKhRo/jjH//I2rVrXdpZLBbi4uJcHq1VenYhJ3LNLTC6x1aRAXLU/8T2Bv8Qz3ZORETES7wWABUVFbFu3TrGjRvncnzcuHEsX768ys+MGDGCgwcPsnDhQgzD4MiRI3z88cdcdNFFLu1ycnJITEykY8eOTJw4sVUvzOhYALFzdAiBftbKDcoXQIuIiLQSXguAjh07hs1mIzY21uV4bGwsaWlpVX5mxIgRfPDBB0yZMgV/f3/i4uKIjIzklVdecbbp0aMH8+bN48svv+TDDz8kMDCQkSNHsmvXrmr7UlhYSFZWlsujpahx+AsgZYX5rAJoERFpRbxeBF1xWnbFjVXLS05O5q677uLRRx9l3bp1fPvtt+zdu5dbb73V2WbYsGFcc8019O/fn9GjR/Of//yH7t27uwRJFc2ZM4eIiAjnIyEhwT1frgnYXtMMsMyDcGgdYIEuYz3bMRERES/yWgAUHR2N1WqtlO1JT0+vlBVymDNnDiNHjuS+++6jX79+jB8/ntdff5133nmH1NTUKj/j4+PDmWeeWWMGaNasWWRmZjofBw4cqP8Xa2J+rWkGWPKX5nOnYRAe78FeiYiIeJfXAiB/f38GDRrEokWLXI4vWrSIESNGVPmZvLw8fHxcu2y1mnUthmFU+RnDMNi4cSPx8dX/gg8ICCA8PNzl0RIUFNvYc9RcsbvKDFDy5+Zzr0ke65OIiEhT4LaFEOtj5syZTJ06lcGDBzN8+HDefPNNUlJSnENas2bN4tChQ7z33nsAXHzxxdx8883MnTuX8ePHk5qayowZMxgyZAjt27cH4IknnmDYsGF069aNrKwsXn75ZTZu3Mhrr73mte/pLbvTc7DZDSKC/IgLr7AMQNZhOLDKfN3rEs93TkRExIu8GgBNmTKF48ePM3v2bFJTU+nTpw8LFy4kMdHcjyo1NdVlTaBp06aRnZ3Nq6++yj333ENkZCTnnHMOzzzzjLNNRkYGt9xyC2lpaURERDBgwAB++uknhgxpfbOcyup/wirXVTmGvxKGQnh7D/dMRETEuyxGdWNHrVhWVhYRERFkZmY26+Gwuf/5mtUbN5I0bBKPXdLH9eQ7EyBlOYyfA8Nv904HRURE3Kguv7+9mgGSRmQYXLHjbm7zT2eF0Q4oFwBlp5VNf9fwl4iItEJenwYvjSR9O+1s6QCcmTwHco6WnUv+EjDMvb8iOnqnfyIiIl6kAKiFKti52Pnat/AkLLyn7GTyF+azZn+JiEgrpQCohSoqDYD+axkFFqsZ9Gz7HLKPwP5fzEYa/hIRkVZKAVBLZCsmONWs8VncZgqMuts8/s09sP6fgAEdBkFkJ+/1UURExIsUALVEh9bjW5LHCSMUI7YvjLkf2vWEvGPw41/NNr0u9W4fRUREvEgBUEv02xIAltt7k9QuFHwDYNJrYCn3x60ASEREWjEFQC1RaQD0i70PiVEh5rEOg2DEXebr9gOhTZJXuiYiItIUaB2glqYwBw6uAWCZvQ9XR4eUnTvnYWjbGRJHealzIiIiTYMCoJYmZQXYizlgb8cBI5bEqOCyc1Y/GDTNa10TERFpKjQE1tKUDn8ts/chOtSfsEA/7/ZHRESkCVIA1NL8thQw63+SokJO0VhERKR1UgDUkuQchSNbAHMGWKICIBERkSopAGpJ9prZn0MBXTlBOJ2jg0/xARERkdZJAVBLUhoArbX2A1AGSEREpBoKgFoKw4A9SwD4vqAHAJ2jFQCJiIhURQFQS3FyL2SmYPj48UNeVwDXKfAiIiLipACopdj7MwB5MQPII1BT4EVERGqgAKilOLkPgCPB3QA0BV5ERKQGCoBaiuw0ANLsbQAVQIuIiNREAVBLkZ0KwL6iMABNgRcREamBAqCWojQDtCvPDICUARIREameAqCWojQDtCUrCNAUeBERkZooAGoJivOhIAOAnXmhgKbAi4iI1EQBUEtQOvxltwaSRbCmwIuIiJyCAqCWoDQAyg+MASyaAi8iInIKCoBagtL6nwxrFKACaBERkVNRANQSlGaA0jHXANIUeBERkZopAGoJSjNAB0siAGWARERETkUBUEtQmgHak2/OANMUeBERkZopAGoOCrJg80dQmFP1+dIM0G+F4YCmwIuIiJyKAqDmYOXr8OlNsHJu1efL1QBpCryIiMipKQBqDjJSzOe0zVWfLw2AjhhtNAVeRESkFhQANQf5J83n43sqnyvMhqJsANKNSLrHhXmwYyIiIs2TAqDmwBEAnfgN7HbXc9lHzCcjiGJrCLeM7uLhzomIiDQ/CoCag/wM87kkH7IPu5wqyjgEmNmfG0d3JkkzwERERE5JAVBz4MgAARzf7XJqyVqzLuikNYo7x3b1ZK9ERESaLQVATZ1hVAiAyuqADmfkszH5VwBiOyQREuDr6d6JiIg0SwqAmrrifLAVlr0vFwA9tXA7be3HAejYSbU/IiIitaUAqKkrn/0BOGEGQCt/O87Xm1OJtZjnLWHxnu6ZiIhIs6UAqKkryHB9f3w3hmEw+6tkAPqG55vHw+I82y8REZFmTAFQU+fIAPmb+3xxch97jmSQnJqFv68PCX6Z5nFlgERERGpNAVBT5wiAYnqCbyDYS1i/2Zz5NTSpDdYccx0gZYBERERqTwFQU+cIgIKjoK1Z6HxglxkAndc5yFwbCBQAiYiI1IECoKbOEQAFtYGo0wAoSNsJwJj2Jea5wEjwC/JC50RERJonLRzT1DlWgQ6MdGZ5EoxU4sIDSfTPMs+p/kdERKROlAFq6spngNqaGaDOllTO6h6NpXQXeA1/iYiI1I0CoKbOZQjM3Oqis08aZ3VvB9mp5jllgEREROpEAVBTVy4ASvPrAEB7jjMqKRSUARIREakXBUBNXbkAaOlBgywjCB+LQWTBIWWARERE6kkBUFPnKIIOiuSnXcfZa5QGO8d3KwMkIiJSTwqAmrrSrTBK/CNYtvsY+4zSYMclAFIGSEREpC4UADVltmIoNKe6bz1pJTO/mMPW9ua547vLDYEpAyQiIlIXCoCasoJM58sl+wsBCIg93TxwYA3Yi83XCoBERETqRAFQU+YogA6IYOnuEwAkdO1jHju2w3wOaQdWPy90TkREpPlSANSUlQZAtsBINh3IAKBvv4GubZT9ERERqTMFQE1Z6QywbEsodgO6xYQSFxtnZn0cVAAtIiJSZwqAmrLSDND+vAAAxnQvDXxKt8QAlAESERGpB68HQK+//jqdO3cmMDCQQYMG8fPPP9fY/oMPPqB///4EBwcTHx/P9ddfz/Hjx13afPLJJ/Tq1YuAgAB69erFZ5991phfoWG2fwX/OA+O76l8rjQASsn3J9DPh+tHdTaPl26JASgDJCIiUg9eDYAWLFjAjBkzeOihh9iwYQOjR49mwoQJpKSkVNl+2bJlXHvttdx4441s27aNjz76iDVr1nDTTTc526xYsYIpU6YwdepUNm3axNSpU5k8eTKrVq3y1Neqm1V/h4NrYPuXlU4V55iBXaYRwu1nd6VDZJB5IqpLWSNlgEREROrMqwHQ888/z4033shNN91Ez549efHFF0lISGDu3LlVtl+5ciVJSUncdddddO7cmVGjRvHHP/6RtWvXOtu8+OKLnH/++cyaNYsePXowa9Yszj33XF588UUPfas6MAxI22y+zjhQ6fTm3fsAsAdGcstZ5YIeZYBEREQaxGsBUFFREevWrWPcuHEux8eNG8fy5cur/MyIESM4ePAgCxcuxDAMjhw5wscff8xFF13kbLNixYpK1xw/fny11/SqjJSytX4yXQOg/cdzOXj4MABDenUl0M9adtIlAFIGSEREpK68FgAdO3YMm81GbGysy/HY2FjS0tKq/MyIESP44IMPmDJlCv7+/sTFxREZGckrr7zibJOWllanawIUFhaSlZXl8vCItC1lrzMPupz6y9fbCTNyADg9KcH1c227gKU0IArv0Jg9FBERaZG8XgRtsVhc3huGUemYQ3JyMnfddRePPvoo69at49tvv2Xv3r3ceuut9b4mwJw5c4iIiHA+EhISqm3rVuUDoIwD5pAYsGRHOt9vP0IbSy4AluC2rp/zC4JLXoELnobQGM/0VUREpAXx9dYPjo6Oxmq1VsrMpKenV8rgOMyZM4eRI0dy3333AdCvXz9CQkIYPXo0Tz75JPHx8cTFxdXpmgCzZs1i5syZzvdZWVmeCYIc9T8ARdlQkEGJfwSzv04GoFNwIRQAgZGVPzvg6sbvn4iISAvltQyQv78/gwYNYtGiRS7HFy1axIgRI6r8TF5eHj4+rl22Ws2hIKM0ezJ8+PBK1/zuu++qvSZAQEAA4eHhLg+PKJ8BAsg4wPfb0/ntaC5tQ/ydGSCC2nimPyIiIq2E1zJAADNnzmTq1KkMHjyY4cOH8+abb5KSkuIc0po1axaHDh3ivffeA+Diiy/m5ptvZu7cuYwfP57U1FRmzJjBkCFDaN/e3CV9+vTpnHXWWTzzzDNceumlfPHFF3z//fcsW7bMa9+zSnknygqf254GJ/ZA5kE+WJUPwO8Hd8RndYZ5XgGQiIiIW3k1AJoyZQrHjx9n9uzZpKam0qdPHxYuXEhiYiIAqampLmsCTZs2jezsbF599VXuueceIiMjOeecc3jmmWecbUaMGMH8+fN5+OGHeeSRRzjttNNYsGABQ4cO9fj3q5Ej+9MmCWJ7wYk9nDi8m593GVgs8Icz2sIqm9kmKNJbvRQREWmRLIZj7EicsrKyiIiIIDMzs/GGw5a/Ct89BD0vhohOsPI1VsX9gSn7JnL26e2YNykWXuoHvkHwcPUz2ERERMRUl9/fXs0AtWqOAui4/hAQCkBW2m8AXD00EfJTzfPK/oiIiLid16fBt1qOIbC4vhBhzjhrZ08nPiKQsae3c+4DpvofERER91MGyBuKC+DoDvN1XF/IPQpAB8txfn9mJ3ytPgqAREREGpEyQN6QngyGDYKjILw9e4rNhQ7bWTKZMqCd2aYgw3xWACQiIuJ2CoC8ofzwl8XCvzZmkWsEmIeMY+Y5ZwYo0vP9ExERaeEUAHlDuQAor6iETzYc4pARbR7LLJ327wiAqloFWkRERBpEAZA3lJsB9vWmVLILSjjhV7pVh2NTVNUAiYiINBoFQJ5mt0PaVvN1XF8W/5oOQGhMknkso3R16PwM81kBkIiIiNspAPK0k3uhONdc4DC6G2lZBQD4RyWZ5zMVAImIiDQ2BUCelrrJfI7tBT5WjmYXAuAXZW7/UZYB0hCYiIhIY1EA5GnlCqANw3AGQCGOIbCKRdCaBSYiIuJ2CoA8zVkA3Y+MvGKKbHYAIuI6m8ezDoPdpgyQiIhII1IA5GnODFA/0kuzP22C/Qho0xF8fMFeAif3QUm+2U4BkIiIiNspAPKk7COQcwSwQGwv0rPNAuiYsEDwsUJ4e7OdI0iyWCGgkXajFxERacUUAHmSI7CJ7gb+IaRnmRmgmHBzFWgiOpW2Kx0mC4oEi8WzfRQREWkFtBmqJ3UcDH/4CGxm4HOkNAPULswRAHU0nx2BklaBFhERaRQKgDwpKBK6j3O+dWaAwgLNA5EJ5nOqIwOk+h8REZHGoCEwL3JMgY9xZoBKA6CcNPNZAZCIiEijUADkRc4iaEcNkCMD5KAASEREpFEoAPKi9OwKQ2ARCoBEREQ8QQGQlxiGUa4GqEIRtINWgRYREWkUCoC8JKewhPxiG1BuCMwvCELalTVSBkhERKRRKADyEsfwV2iAL8H+5SbjlR8GUwAkIiLSKBQAeUml4S+HSAVAIiIijU0BkJekV1wE0aF8BkgLIYqIiDQKBUBe4lwDKDzQ9YSGwERERBqdAiAvSa+4CKKDhsBEREQanQIgL0nPcuwEX8MQmKbBi4iINArtBeYlzgxQeIUAKLobhHeE8Hiw+nmhZyIiIi2fAiAvcQRAsWEVaoD8guCu9eCjPxoREZHGot+yXuIcAquYAQLwreKYiIiIuI1qgLygoNhGVkEJAO0qZoBERESk0SkA8gLHIogBvj6EByoJJyIi4mkKgLzAsQhiTHgAFovFy70RERFpfRQAeUHZGkAa/hIREfEGBUBeUO0aQCIiIuIRCoC8oNpVoEVERMQjFAB5QXp1+4CJiIiIRygA8gJHAFRpJ3gRERHxCAVAXqAaIBEREe9SAOQFRzULTERExKsUAHlYsc3O8dwioJptMERERKTRKQDysGM5ZvbH18dC22B/L/dGRESkdVIA5GGObTCiQwPw8dEq0CIiIt6gAMjDyqbAa/hLRETEWxQAeZhzHzDNABMREfEaBUAe5hgC0yKIIiIi3qMAyMOUARIREfE+BUAe5swAaQ0gERERr1EA5GHaCFVERMT7FAB5mHMITLPAREREvEYBkAfZ7AbHckpXgdYQmIiIiNcoAPKgE7lF2OwGFgtEh2oVaBEREW9RAORBjuGvqBB/fK269SIiIt6i38IelFNQQligL+00/CUiIuJVvt7uQGsytEsUWx4fT7HN7u2uiIiItGrKAHmBn4a/REREvEq/iUVERKTV8XoA9Prrr9O5c2cCAwMZNGgQP//8c7Vtp02bhsViqfTo3bu3s828efOqbFNQUOCJryMiIiLNgFcDoAULFjBjxgweeughNmzYwOjRo5kwYQIpKSlVtn/ppZdITU11Pg4cOEDbtm258sorXdqFh4e7tEtNTSUwUIXHIiIiYvJqAPT8889z4403ctNNN9GzZ09efPFFEhISmDt3bpXtIyIiiIuLcz7Wrl3LyZMnuf76613aWSwWl3ZxcXGe+DoiIiLSTHgtACoqKmLdunWMGzfO5fi4ceNYvnx5ra7x9ttvc95555GYmOhyPCcnh8TERDp27MjEiRPZsGGD2/otIiIizZ/XpsEfO3YMm81GbGysy/HY2FjS0tJO+fnU1FT++9//8u9//9vleI8ePZg3bx59+/YlKyuLl156iZEjR7Jp0ya6detW5bUKCwspLCx0vs/KyqrHNxIREZHmwutF0BaLxeW9YRiVjlVl3rx5REZGMmnSJJfjw4YN45prrqF///6MHj2a//znP3Tv3p1XXnml2mvNmTOHiIgI5yMhIaFe30VERESaB68FQNHR0Vit1krZnvT09EpZoYoMw+Cdd95h6tSp+PvXvKeWj48PZ555Jrt27aq2zaxZs8jMzHQ+Dhw4UPsvIiIiIs2O1wIgf39/Bg0axKJFi1yOL1q0iBEjRtT42aVLl7J7925uvPHGU/4cwzDYuHEj8fHx1bYJCAggPDzc5SEiIiItl1e3wpg5cyZTp05l8ODBDB8+nDfffJOUlBRuvfVWwMzMHDp0iPfee8/lc2+//TZDhw6lT58+la75xBNPMGzYMLp160ZWVhYvv/wyGzdu5LXXXvPIdxIREZGmz6sB0JQpUzh+/DizZ88mNTWVPn36sHDhQuesrtTU1EprAmVmZvLJJ5/w0ksvVXnNjIwMbrnlFtLS0oiIiGDAgAH89NNPDBkypNG/j4iIiDQPFsMwDG93oqnJysoiIiKCzMxMDYeJiIg0E3X5/e31WWAiIiIinubVIbCmypEU03pAIiIizYfj93ZtBrcUAFUhOzsbQOsBiYiINEPZ2dlERETU2EY1QFWw2+0cPnyYsLCwWi3KWBdZWVkkJCRw4MAB1Rc1Mt1rz9G99hzda8/RvfYcd91rwzDIzs6mffv2+PjUXOWjDFAVfHx86NixY6P+DK035Dm6156je+05uteeo3vtOe6416fK/DioCFpERERaHQVAIiIi0uooAPKwgIAAHnvsMQICArzdlRZP99pzdK89R/fac3SvPccb91pF0CIiItLqKAMkIiIirY4CIBEREWl1FACJiIhIq6MASERERFodBUAe9Prrr9O5c2cCAwMZNGgQP//8s7e71OzNmTOHM888k7CwMGJiYpg0aRI7duxwaWMYBo8//jjt27cnKCiIs88+m23btnmpxy3HnDlzsFgszJgxw3lM99p9Dh06xDXXXENUVBTBwcGcccYZrFu3znle99o9SkpKePjhh+ncuTNBQUF06dKF2bNnY7fbnW10r+vvp59+4uKLL6Z9+/ZYLBY+//xzl/O1ubeFhYX86U9/Ijo6mpCQEC655BIOHjzY8M4Z4hHz5883/Pz8jLfeestITk42pk+fboSEhBj79+/3dteatfHjxxvvvvuusXXrVmPjxo3GRRddZHTq1MnIyclxtnn66aeNsLAw45NPPjG2bNliTJkyxYiPjzeysrK82PPmbfXq1UZSUpLRr18/Y/r06c7jutfuceLECSMxMdGYNm2asWrVKmPv3r3G999/b+zevdvZRvfaPZ588kkjKirK+Prrr429e/caH330kREaGmq8+OKLzja61/W3cOFC46GHHjI++eQTAzA+++wzl/O1ube33nqr0aFDB2PRokXG+vXrjbFjxxr9+/c3SkpKGtQ3BUAeMmTIEOPWW291OdajRw/jz3/+s5d61DKlp6cbgLF06VLDMAzDbrcbcXFxxtNPP+1sU1BQYERERBhvvPGGt7rZrGVnZxvdunUzFi1aZIwZM8YZAOleu88DDzxgjBo1qtrzutfuc9FFFxk33HCDy7HLLrvMuOaaawzD0L12p4oBUG3ubUZGhuHn52fMnz/f2ebQoUOGj4+P8e233zaoPxoC84CioiLWrVvHuHHjXI6PGzeO5cuXe6lXLVNmZiYAbdu2BWDv3r2kpaW53PuAgADGjBmje19Pd9xxBxdddBHnnXeey3Hda/f58ssvGTx4MFdeeSUxMTEMGDCAt956y3le99p9Ro0axQ8//MDOnTsB2LRpE8uWLePCCy8EdK8bU23u7bp16yguLnZp0759e/r06dPg+6/NUD3g2LFj2Gw2YmNjXY7HxsaSlpbmpV61PIZhMHPmTEaNGkWfPn0AnPe3qnu/f/9+j/exuZs/fz7r169nzZo1lc7pXrvPb7/9xty5c5k5cyYPPvggq1ev5q677iIgIIBrr71W99qNHnjgATIzM+nRowdWqxWbzcZf//pXrrrqKkB/rxtTbe5tWloa/v7+tGnTplKbhv7+VADkQRaLxeW9YRiVjkn93XnnnWzevJlly5ZVOqd733AHDhxg+vTpfPfddwQGBlbbTve64ex2O4MHD+app54CYMCAAWzbto25c+dy7bXXOtvpXjfcggULeP/99/n3v/9N79692bhxIzNmzKB9+/Zcd911zna6142nPvfWHfdfQ2AeEB0djdVqrRStpqenV4p8pX7+9Kc/8eWXX/Ljjz/SsWNH5/G4uDgA3Xs3WLduHenp6QwaNAhfX198fX1ZunQpL7/8Mr6+vs77qXvdcPHx8fTq1cvlWM+ePUlJSQH099qd7rvvPv785z/z+9//nr59+zJ16lTuvvtu5syZA+heN6ba3Nu4uDiKioo4efJktW3qSwGQB/j7+zNo0CAWLVrkcnzRokWMGDHCS71qGQzD4M477+TTTz9l8eLFdO7c2eV8586diYuLc7n3RUVFLF26VPe+js4991y2bNnCxo0bnY/Bgwdz9dVXs3HjRrp06aJ77SYjR46stJzDzp07SUxMBPT32p3y8vLw8XH9VWi1Wp3T4HWvG09t7u2gQYPw8/NzaZOamsrWrVsbfv8bVEItteaYBv/2228bycnJxowZM4yQkBBj37593u5as3bbbbcZERERxpIlS4zU1FTnIy8vz9nm6aefNiIiIoxPP/3U2LJli3HVVVdpCqublJ8FZhi61+6yevVqw9fX1/jrX/9q7Nq1y/jggw+M4OBg4/3333e20b12j+uuu87o0KGDcxr8p59+akRHRxv333+/s43udf1lZ2cbGzZsMDZs2GAAxvPPP29s2LDBuQRMbe7trbfeanTs2NH4/vvvjfXr1xvnnHOOpsE3N6+99pqRmJho+Pv7GwMHDnRO1Zb6A6p8vPvuu842drvdeOyxx4y4uDgjICDAOOuss4wtW7Z4r9MtSMUASPfafb766iujT58+RkBAgNGjRw/jzTffdDmve+0eWVlZxvTp041OnToZgYGBRpcuXYyHHnrIKCwsdLbRva6/H3/8scr/R1933XWGYdTu3ubn5xt33nmn0bZtWyMoKMiYOHGikZKS0uC+WQzDMBqWQxIRERFpXlQDJCIiIq2OAiARERFpdRQAiYiISKujAEhERERaHQVAIiIi0uooABIREZFWRwGQiIiItDoKgEREamHJkiVYLBYyMjK83RURcQMFQCIiItLqKAASERGRVkcBkIg0C4Zh8Oyzz9KlSxeCgoLo378/H3/8MVA2PPXNN9/Qv39/AgMDGTp0KFu2bHG5xieffELv3r0JCAggKSmJ5557zuV8YWEh999/PwkJCQQEBNCtWzfefvttlzbr1q1j8ODBBAcHM2LEiEq7totI86AASESahYcffph3332XuXPnsm3bNu6++26uueYali5d6mxz33338X//93+sWbOGmJgYLrnkEoqLiwEzcJk8eTK///3v2bJlC48//jiPPPII8+bNc37+2muvZf78+bz88sts376dN954g9DQUJd+PPTQQzz33HOsXbsWX19fbrjhBo98fxFxL22GKiJNXm5uLtHR0SxevJjhw4c7j990003k5eVxyy23MHbsWObPn8+UKVMAOHHiBB07dmTevHlMnjyZq6++mqNHj/Ldd985P3///ffzzTffsG3bNnbu3Mnpp5/OokWLOO+88yr1YcmSJYwdO5bvv/+ec889F4CFCxdy0UUXkZ+fT2BgYCPfBRFxJ2WARKTJS05OpqCggPPPP5/Q0FDn47333mPPnj3OduWDo7Zt23L66aezfft2ALZv387IkSNdrjty5Eh27dqFzWZj48aNWK1WxowZU2Nf+vXr53wdHx8PQHp6eoO/o4h4lq+3OyAicip2ux2Ab775hg4dOricCwgIcAmCKrJYLIBZQ+R47VA+AR4UFFSrvvj5+VW6tqN/ItJ8KAMkIk1er169CAgIICUlha5du7o8EhISnO1WrlzpfH3y5El27txJjx49nNdYtmyZy3WXL19O9+7dsVqt9O3bF7vd7lJTJCItlzJAItLkhYWFce+993L33Xdjt9sZNWoUWVlZLF++nNDQUBITEwGYPXs2UVFRxMbG8tBDDxEdHc2kSZMAuOeeezjzzDP5y1/+wpQpU1ixYgWvvvoqr7/+OgBJSUlcd9113HDDDbz88sv079+f/fv3k56ezuTJk7311UWkkSgAEpFm4S9/+QsxMTHMmTOH3377jcjISAYOHMiDDz7oHIJ6+umnmT59Ort27aJ///58+eWX+Pv7AzBw4ED+85//8Oijj/KXv/yF+Ph4Zs+ezbRp05w/Y+7cuTz44IPcfvvtHD9+nE6dOvHggw964+uKSCPTLDARafYcM7ROnjxJZGSkt7sjIs2AaoBERESk1VEAJCIiIq2OhsBERESk1VEGSERERFodBUAiIiLS6igAEhERkVZHAZCIiIi0OgqAREREpNVRACQiIiKtjgIgERERaXUUAImIiEirowBIREREWp3/B4ScrUqy1zw0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d3f10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98       253\n",
      "         1.0       0.96      0.99      0.97       147\n",
      "\n",
      "    accuracy                           0.98       400\n",
      "   macro avg       0.98      0.98      0.98       400\n",
      "weighted avg       0.98      0.98      0.98       400\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Confusion Matrix')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)# name of model you want to draw Confusion Matrix amd ROC curve for it\n",
    "\n",
    "for i in range(len(y_pred)) :\n",
    "    if y_pred[i]<0.5 :\n",
    "        y_pred[i]=0\n",
    "    else :\n",
    "        y_pred[i]=1\n",
    "print(classification_report(y_test, y_pred))\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)    \n",
    "\n",
    "categories  = ['Negative','Positive']\n",
    "group_names = ['True Neg','False Pos', 'False Neg','True Pos']\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
    "\n",
    "labels = [f'{v1}\\n{v2}' for v1, v2 in zip(group_names,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "sns.heatmap(cf_matrix, annot = labels, cmap = 'Blues',fmt = '',\n",
    "                xticklabels = categories, yticklabels = categories)\n",
    "\n",
    "plt.xlabel(\"Predicted values\", fontdict = {'size':14}, labelpad = 10)\n",
    "plt.ylabel(\"Actual values\"   , fontdict = {'size':14}, labelpad = 10)\n",
    "plt.title (\"Confusion Matrix\", fontdict = {'size':18}, pad = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8a3a211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds =roc_curve(y_test,y_pred)\n",
    "plt.plot([0,1], [0,1], '--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c90ba92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621d8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
